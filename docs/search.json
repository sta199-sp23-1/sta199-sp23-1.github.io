[
  {
    "objectID": "labs/lab-7.html",
    "href": "labs/lab-7.html",
    "title": "Lab 7 - Logistic regression",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Monday, March 27 at 5:00pm."
  },
  {
    "objectID": "labs/lab-7.html#packages",
    "href": "labs/lab-7.html#packages",
    "title": "Lab 7 - Logistic regression",
    "section": "Packages",
    "text": "Packages\nYou’ll need the following packages for today’s lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "labs/lab-7.html#data",
    "href": "labs/lab-7.html#data",
    "title": "Lab 7 - Logistic regression",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package.\nIf you would like to explicitly load the data into your environment so you can view it, you can do so by running this code.\n\ngss16 <- gss16\n\nYou can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "labs/lab-7.html#exercise-1---data-wrangling",
    "href": "labs/lab-7.html#exercise-1---data-wrangling",
    "title": "Lab 7 - Logistic regression",
    "section": "Exercise 1 - Data wrangling",
    "text": "Exercise 1 - Data wrangling\n\n\n\n\n\n\nImportant\n\n\n\nRemember: For each exercise, you should choose one person to type. All others should contribute to the discussion, but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame.\nTransform the advfront variable such that it has two levels: \"Strongly agree\" and \"Agree\" should both be mapped to \"Agree\" and the remaining levels should all be relabeled \"Not agree\". Make sure the resulting levels are in the following order: \"Agree\" and \"Not agree\".\n\nHint: use the factor() function inside a mutate() statement to relabel the original levels. Be sure to list the levels in order so that they are correctly ordered after relabeling.\n\nSimilarly to part b, combine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word “conservative” in them are lumped into a level called \"Conservative\". Make sure the levels are in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\n\nHint: be careful if you manually type out the levels in the original polviews variable to note that there are typos in two of the original levels “slightly conservative” and “extremely conservative” are both misspelled, and so you will need to match those misspellings in your call to factor().\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, all other team members should pull. Then, choose a new team member to write the answer to Exercise 2. (And so on for the remaining exercises.)"
  },
  {
    "objectID": "labs/lab-7.html#exercise-2---train-and-test-sets",
    "href": "labs/lab-7.html#exercise-2---train-and-test-sets",
    "title": "Lab 7 - Logistic regression",
    "section": "Exercise 2 - Train and test sets",
    "text": "Exercise 2 - Train and test sets\nNow, let’s split the data into training and test sets so that we can evaluate the models we’re going to fit by how well they predict outcomes on data that wasn’t used to fit the models.\nSpecify a random seed of 1234 (i.e., include set.seed(1234) at the beginning of your code chunk), and then split gss16_advfront randomly into a training set train_data and a test set test_data. Do this so that the training set contains 80% of the rows of the original data."
  },
  {
    "objectID": "labs/lab-7.html#exercise-3---logistic-regression",
    "href": "labs/lab-7.html#exercise-3---logistic-regression",
    "title": "Lab 7 - Logistic regression",
    "section": "Exercise 3 - Logistic Regression",
    "text": "Exercise 3 - Logistic Regression\n\nUsing the training data, fit a logistic regression model that predicts advfront using educ. In particular, the model should predict the probability that advfront has value \"Not agree\". Name this model model1. Report the tidy model output.\nWrite out the fitted model equation in proper notation. State the meaning of any variables in the context of the data.\nUsing your fitted model, report the estimated probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years."
  },
  {
    "objectID": "labs/lab-7.html#exercise-4---another-model",
    "href": "labs/lab-7.html#exercise-4---another-model",
    "title": "Lab 7 - Logistic regression",
    "section": "Exercise 4 - Another model",
    "text": "Exercise 4 - Another model\n\nAgain using the training data, fit a new logistic regression model that adds the additional explanatory variable of polviews. Name this model model2. Report the tidy output.\nNow, report the estimated probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years and are Conservative."
  },
  {
    "objectID": "labs/lab-7.html#exercise-5---evaluating-models-with-aic",
    "href": "labs/lab-7.html#exercise-5---evaluating-models-with-aic",
    "title": "Lab 7 - Logistic regression",
    "section": "Exercise 5 - Evaluating models with AIC",
    "text": "Exercise 5 - Evaluating models with AIC\n\nReport the AIC values for each of model1 and model2.\nBased on your results in part a, does it appear that including political views in addition to years of education is useful for modeling whether employees agree with the statement “Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government”? Explain."
  },
  {
    "objectID": "labs/lab-7.html#exercise-6---evaluating-models-using-test-data",
    "href": "labs/lab-7.html#exercise-6---evaluating-models-using-test-data",
    "title": "Lab 7 - Logistic regression",
    "section": "Exercise 6 - Evaluating models using test data",
    "text": "Exercise 6 - Evaluating models using test data\n\nFor each of model1 and model2, report the number of false positive and false negatives when making predictions on the test_data with a decision boundary of 0.5.\nDo these results provide much information about which model you would prefer for a prediction task? If so, which model would you choose?\nDo you think a decision boundary of 0.5 makes sense here or would you adjust it?\n\nThe ROC curve provides a way to compare predictive performance of binary classifiers across the full range of decision boundaries. Notes about the ROC curve can be found here https://sta199-s23-2.github.io/ae-sa/ae-16-A.html."
  },
  {
    "objectID": "prepare/prep21.html",
    "href": "prepare/prep21.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch Central limit theorem\nRead (optional): 13.1, 13.2, 13.3: inference with mathematical models"
  },
  {
    "objectID": "prepare/prep20.html",
    "href": "prepare/prep20.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch Bootstrapping\nRead (optional): section 12"
  },
  {
    "objectID": "prepare/prep22.html",
    "href": "prepare/prep22.html",
    "title": "Prepare",
    "section": "",
    "text": "Read 13.6 Case Study (interval): Stents\nRead 19.2 Mathematical model for a mean"
  },
  {
    "objectID": "prepare/prep23.html",
    "href": "prepare/prep23.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch Hypothesis testing\nRead (optional): chapter 11: hypothesis testing with randomization"
  },
  {
    "objectID": "teaching-resources/GitHubClassroomManagement.html",
    "href": "teaching-resources/GitHubClassroomManagement.html",
    "title": "GitHub Classroom Management",
    "section": "",
    "text": "# $ git clone ghclass\n# $ git checkout artifacts\n\n#devtools::install(\"/path/to/ghclass\")\nEach code chunk below is designed to be self-contained (no dependency between chunks)."
  },
  {
    "objectID": "teaching-resources/GitHubClassroomManagement.html#to-make-new-repos",
    "href": "teaching-resources/GitHubClassroomManagement.html#to-make-new-repos",
    "title": "GitHub Classroom Management",
    "section": "To make new repos",
    "text": "To make new repos\n\n\n\n\nCreate a new repo in the organization called “lab1” with a README.md\nPush to “lab1”: lab1.qmd, data/any_relevant_data.csv and optionally lab1.Rproj.\nSelect the repository, click “Settings” and check “Template repository”.\nFollow the code below.\n\n\n# initial assignment creation\norg = \"sta199-sp23-1\"\nusernames = ghclass::org_members(org)\n\n## edit this:\nassignment_template_repo = \"lab0_template\"\n\nghclass::org_create_assignment(\n  org = org,\n  repo = paste0(assignment_template_repo, \"-\", usernames),\n  user = usernames,\n  source_repo = paste0(org, \"/\", assignment_template_repo)\n)\n\n\n\n\nFeel free to test lab creation on my dummy account “fishswish” or on your own account with the code below\n\norg = \"sta199-sp23-1\"\nusernames = \"fishswish\"\nassignment_template_repo = \"lab0_template\"\nghclass::org_create_assignment(\n  org = org,\n  repo = paste0(assignment_template_repo, \"-\", usernames),\n  user = usernames,\n  source_repo = paste0(org, \"/\", assignment_template_repo)\n)\n\nIt’s possible some people are not in the organization and will need to be have additional repos created manually following the steps below:\n\ngo to template repo and click the green “Use this template” -> “Create a new repository” -> name it “lab-x-their_github_username” -> leave “Private” selected and click “Create repository from template”\nnext in the new repo go to “Settings” -> “Collaborators and Teams” -> click the green “Add people” button and type in their GitHub username.\nnext make sure to go to the “People” section of the organization and select “Invite member” so they join the organization too. Owning a repo in the org just makes them an outside collaborator. They still have to actually join the org"
  },
  {
    "objectID": "teaching-resources/GitHubClassroomManagement.html#oops.-file-management-after-you-create-repos",
    "href": "teaching-resources/GitHubClassroomManagement.html#oops.-file-management-after-you-create-repos",
    "title": "GitHub Classroom Management",
    "section": "Oops. File management after you create repos",
    "text": "Oops. File management after you create repos\nThe magic happens in repo_add_file(). Be sure to edit/check each item below, specifically:\n\norg as appropriate\nrepos_to_modify object\narguments to repo_add_file()\n\n\norg = \"sta199-sp23-1\"\nusernames = ghclass::org_members(org)\n\n# get all existing labX repos\nrepos_to_modify = org_repos(org, filter = \"practice1-\") # edit this \"filter\"\n\nghclass::repo_add_file(repo = repos_to_modify,\n                       branch = \"main\",\n                       repo_folder = \"\", # edit this to be path to folder in repo\n                       message = \"update README\", # update to be a meaningful commit message\n                       file = \"~/Desktop/README.md\", # update local path to the file you want to add\n                       overwrite = TRUE) # if you want to overwrite or not"
  },
  {
    "objectID": "teaching-resources/GitHubClassroomManagement.html#creating-team-assignments",
    "href": "teaching-resources/GitHubClassroomManagement.html#creating-team-assignments",
    "title": "GitHub Classroom Management",
    "section": "Creating team assignments",
    "text": "Creating team assignments\n\n# example data frame for demo purposes\n# you will need to format your data frame to look like this\nroster = data.frame(\n  github = c(\"fishswish\", \"athos00\"),\n  lab1 = rep(\"lab1-team1\", 2)\n)\n\n# edit each item below\norg_create_assignment(\n  org = \"sta199-sp23-1\",\n  user = roster$github,\n  repo = roster$lab1,\n  team = roster$lab1,\n  source_repo = \"sta199-sp23-1/lab1_template\",\n  private = TRUE\n)\n\n\nroster = data.frame(\n  github = c(\"devinjohnson7\", \"athos00\"),\n  lab1 = rep(\"lab1-team-awesome\", 2)\n)\n\n# edit each item below\norg_create_assignment(\n  org = \"sta323-sp23\",\n  user = roster$github,\n  repo = roster$lab1,\n  team = roster$lab1,\n  source_repo = \"sta323-sp23/lab-1\", # template file\n  private = TRUE\n)\n\n\norg = \"sta323-sp23\"\nrepos = ghclass::org_repos(org, filter = \"lab-2\")\n\n\n# repos = \"sta323-sp23/lab-1\"\nghclass::action_artifact_delete(repos, ids=action_artifacts(repos, which=\"all\"))"
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6 - Logistic regression",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Monday, March 27 at 5:00pm."
  },
  {
    "objectID": "labs/lab-6.html#packages",
    "href": "labs/lab-6.html#packages",
    "title": "Lab 6 - Logistic regression",
    "section": "Packages",
    "text": "Packages\nYou’ll need the following packages for today’s lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "labs/lab-6.html#data",
    "href": "labs/lab-6.html#data",
    "title": "Lab 6 - Logistic regression",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the data set is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package.\nIf you would like to explicitly load the data into your environment so you can view it, you can do so by running this code.\n\ngss16 <- gss16\n\nYou can find out more about the data set by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "labs/lab-6.html#exercise-1---data-wrangling",
    "href": "labs/lab-6.html#exercise-1---data-wrangling",
    "title": "Lab 6 - Logistic regression",
    "section": "Exercise 1 - Data wrangling",
    "text": "Exercise 1 - Data wrangling\n\n\n\n\n\n\nImportant\n\n\n\nRemember: For each exercise, you should choose one person to type. All others should contribute to the discussion, but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame.\nTransform the advfront variable such that it has two levels: \"Strongly agree\" and \"Agree\" should both be mapped to \"Agree\" and the remaining levels should all be relabeled \"Not agree\". Make sure the resulting levels are in the following order: \"Agree\" and \"Not agree\".\n\nHint: use the factor() function inside a mutate() statement to relabel the original levels. Be sure to list the levels in order so that they are correctly ordered after relabeling.\n\nSimilarly to part b, combine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word “conservative” in them are lumped into a level called \"Conservative\". Make sure the levels are in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\n\nHint: be careful if you manually type out the levels in the original polviews variable to note that there are typos in two of the original levels “slightly conservative” and “extremely conservative” are both misspelled, and so you will need to match those misspellings in your call to factor().\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, all other team members should pull. Then, choose a new team member to write the answer to Exercise 2. (And so on for the remaining exercises.)"
  },
  {
    "objectID": "labs/lab-6.html#exercise-2---train-and-test-sets",
    "href": "labs/lab-6.html#exercise-2---train-and-test-sets",
    "title": "Lab 6 - Logistic regression",
    "section": "Exercise 2 - Train and test sets",
    "text": "Exercise 2 - Train and test sets\nNow, let’s split the data into training and test sets so that we can evaluate the models we’re going to fit by how well they predict outcomes on data that wasn’t used to fit the models.\nSpecify a random seed of 1234 (i.e., include set.seed(1234) at the beginning of your code chunk), and then split gss16_advfront randomly into a training set train_data and a test set test_data. Do this so that the training set contains 80% of the rows of the original data."
  },
  {
    "objectID": "labs/lab-6.html#exercise-3---logistic-regression",
    "href": "labs/lab-6.html#exercise-3---logistic-regression",
    "title": "Lab 6 - Logistic regression",
    "section": "Exercise 3 - Logistic Regression",
    "text": "Exercise 3 - Logistic Regression\n\nUsing the training data, fit a logistic regression model that predicts advfront using educ. In particular, the model should predict the probability that advfront has value \"Not agree\". Name this model model1. Report the tidy model output.\nWrite out the fitted model equation in proper notation. State the meaning of any variables in the context of the data.\nUsing your fitted model, report the estimated probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years."
  },
  {
    "objectID": "labs/lab-6.html#exercise-4---another-model",
    "href": "labs/lab-6.html#exercise-4---another-model",
    "title": "Lab 6 - Logistic regression",
    "section": "Exercise 4 - Another model",
    "text": "Exercise 4 - Another model\n\nAgain using the training data, fit a new logistic regression model that adds the additional explanatory variable of polviews. Name this model model2. Report the tidy output.\nNow, report the estimated probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years and are Conservative."
  },
  {
    "objectID": "labs/lab-6.html#exercise-5---evaluating-models-with-aic",
    "href": "labs/lab-6.html#exercise-5---evaluating-models-with-aic",
    "title": "Lab 6 - Logistic regression",
    "section": "Exercise 5 - Evaluating models with AIC",
    "text": "Exercise 5 - Evaluating models with AIC\n\nReport the AIC values for each of model1 and model2.\nBased on your results in part a, does it appear that including political views in addition to years of education is useful for modeling whether employees agree with the statement “Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government”? Explain."
  },
  {
    "objectID": "labs/lab-6.html#exercise-6---evaluating-models-using-test-data",
    "href": "labs/lab-6.html#exercise-6---evaluating-models-using-test-data",
    "title": "Lab 6 - Logistic regression",
    "section": "Exercise 6 - Evaluating models using test data",
    "text": "Exercise 6 - Evaluating models using test data\n\nFor each of model1 and model2, report the number of false positive and false negatives when making predictions on the test_data with a decision boundary of 0.5.\nDo these results provide much information about which model you would prefer for a prediction task? If so, which model would you choose?\nDo you think a decision boundary of 0.5 makes sense here or would you adjust it?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199: Introduction to Data Science",
    "section": "",
    "text": "week\n      dow\n      date\n      what\n      topic\n      prepare\n      slides\n      ae\n      hw\n      lab\n      exam\n      project\n      notes\n    \n  \n  \n    0\nW\nJan 11\nLab 0\nHello R!\n\n\n\n\n\n\n\n\n    \nF\nJan 13\nLec 1\nWelcome to STA 199\n\n\n\n\n\n\n\n\n    1\nM\nJan 16\n\nNo class -- Martin Luther King Jr. Day\n\n\n\n\n\n\n\n\n    \nW\nJan 18\nLec 2\nIntro to statistics and plotting\n\n\n\n\n\n\n\n\n    \nF\nJan 20\nLec 3\nVisualizing various types of data\n\n\n\n\n\n\n\n\n    2\nM\nJan 23\nLab 1\nData visualization\n\n\n\n\n\n\n\n\n    \nW\nJan 25\nLec 4\nGrammar of data wrangling\n\n\n\n\n\n\n\nHomework 1 released\n    \nF\nJan 27\nLec 5\nWorking with multiple data frames\n\n\n\n\n\n\n\n\n    3\nM\nJan 30\nLab 2\nData wrangling\n\n\n\n\n\n\n\n\n    \nW\nFeb 1\nLec 6\nTidy data\n\n\n\n\n\n\n\n\n    \nF\nFeb 3\nLec 7\nData types and classes\n\n\n\n\n\n\n\nHomework 1 due\n    4\nM\nFeb 6\nLab 3\nData tidying\n\n\n\n\n\n\n\n\n    \nW\nFeb 8\nLec 8\nSpatial data\n\n\n\n\n\n\n\n\n    \nF\nFeb 10\nLec 9\nTroubleshooting / Review\n\n\n\n\n\n\n\nExam 1 released! Due Feb 14 5:00pm\n    5\nM\nFeb 13\nLab\nNo lab: exam 1\n\n\n\n\n\n\n\n\n    \nW\nFeb 15\nLec 10\nIntro to probability\n\n\n\n\n\n\n\n\n    \nF\nFeb 17\nLec 11\nConditional probability\n\n\n\n\n\n\n\nHomework 2 released\n    6\nM\nFeb 20\nLab 4\nMerge conflicts\n\n\n\n\n\n\n\n\n    \nW\nFeb 22\nLec 12\nSimple regression\n\n\n\n\n\n\n\n\n    \nF\nFeb 24\nLec 13\nMultiple regression I\n\n\n\n\n\n\n\nHomework 2 due\n    7\nM\nFeb 27\nLab 5\nPredicting a numerical outcome\n\n\n\n\n\n\n\n\n    \nW\nMar 1\nLec 14\nMultiple regression II\n\n\n\n\n\n\n\nHomework 3 released; project announced\n    \nF\nMar 3\nLec 15\nModel selection\n\n\n\n\n\n\n\n\n    8\nM\nMar 6\nLab\nWork on project proposal\n\n\n\n\n\n\n\n\n    \nW\nMar 8\nLec 16\nLogistic regression\n\n\n\n\n\n\n\nHomework 3 due; statistics experience released\n    \nF\nMar 10\nLec 17\nPrediction\n\n\n\n\n\n\n\nProject proposal due\n    9\nM\nMar 13\n\nNo class -- Spring Break\n\n\n\n\n\n\n\n\n    \nW\nMar 15\n\nNo class -- Spring Break\n\n\n\n\n\n\n\n\n    \nF\nMar 17\n\nNo class -- Spring Break\n\n\n\n\n\n\n\n\n    10\nM\nMar 20\nLab\nLogistic regression (lab)\n\n\n\n\n\n\n\n\n    \nW\nMar 22\nLec 18\nBootstrap\n\n\n\n\n\n\n\nHomework 4 released\n    \nF\nMar 24\nLec 19\nCentral limit theorem I\n\n\n\n\n\n\n\n\n    11\nM\nMar 27\nLab\nProject work day\n\n\n\n\n\n\n\n\n    \nW\nMar 29\nLec 20\nCentral limit theorem II\n\n\n\n\n\n\n\n\n    \nF\nMar 31\nLec 21\nHypothesis testing I\n\n\n\n\n\n\n\nHomework 4 due\n    12\nM\nApr 3\nLab\nHypothesis testing lab\n\n\n\n\n\n\n\n\n    \nW\nApr 5\nLec 22\nHypothesis testing II\n\n\n\n\n\n\n\n\n    \nF\nApr 7\nLec 23\nHypothesis testing III\n\n\n\n\n\n\n\n\n    13\nM\nApr 10\nLab\nProject peer review\n\n\n\n\n\n\n\n\n    \nW\nApr 12\nLec 24\nProject tips\n\n\n\n\n\n\n\n\n    \nF\nApr 14\nLec 25\nEthics\n\n\n\n\n\n\n\nExam 2 released! Due Tue April 18 5:00pm\n    14\nM\nApr 17\nLab\nNo lab: exam 2\n\n\n\n\n\n\n\n\n    \nW\nApr 19\nLec 26\nSpecial topic\n\n\n\n\n\n\n\n\n    \nF\nApr 21\nLec 27\nSpecial topic\n\n\n\n\n\n\n\n\n    15\nM\nApr 24\nLab\nProject presentations\n\n\n\n\n\n\n\n\n    \nW\nApr 26\nLec 28\nSpecial topic"
  },
  {
    "objectID": "ae/ae-18.html",
    "href": "ae/ae-18.html",
    "title": "Bootstrap",
    "section": "",
    "text": "this ae is due for grade. Push your completed ae to GitHub within 48 hours to receive credit\nproject proposal feedback\nhomework 4 released"
  },
  {
    "objectID": "ae/ae-18.html#getting-started",
    "href": "ae/ae-18.html#getting-started",
    "title": "Bootstrap",
    "section": "Getting started",
    "text": "Getting started\nClone your ae18-username repo from the GitHub organization."
  },
  {
    "objectID": "ae/ae-18.html#today",
    "href": "ae/ae-18.html#today",
    "title": "Bootstrap",
    "section": "Today",
    "text": "Today\nBy the end of today you will…\n\nbe able to draw a bootstrap sample and calculate a bootstrap statistic\nuse infer to obtain a bootstrap distribution\ncalculate a confidence interval from the bootstrap distribution\ninterpret a confidence interval in context of the data"
  },
  {
    "objectID": "ae/ae-18.html#load-packages",
    "href": "ae/ae-18.html#load-packages",
    "title": "Bootstrap",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-18.html#load-data",
    "href": "ae/ae-18.html#load-data",
    "title": "Bootstrap",
    "section": "Load data",
    "text": "Load data\n\nmanhattan = read_csv(\n  \"https://sta101-fa22.netlify.app/static/appex/data/manhattan.csv\"\n  )"
  },
  {
    "objectID": "ae/ae-18.html#notes-for-reference",
    "href": "ae/ae-18.html#notes-for-reference",
    "title": "Bootstrap",
    "section": "Notes (for reference)",
    "text": "Notes (for reference)\nBootstrapping is a re-sampling technique. The key idea is you have already collected a sample of size \\(N\\) from the population. To create a bootstrap sample, you sample with replacement from your original sample \\(N\\) times.\nLet’s say you measure the height of five Duke students in meters:\n\nheights = c(1.51, 1.62, 1.89, 2.01, 1.78)\n\nstudents = data.frame(heights)\n\nThere are many ways to create a bootstrap sample in R. We will focus on the tidy way below. which uses the infer package that loads with tidymodels.\n\nExample\n\nset.seed(2)\nstudents %>%\n  specify(response = heights) %>%\n  generate(reps = 1, type = \"bootstrap\")\n\nResponse: heights (numeric)\n# A tibble: 5 × 2\n# Groups:   replicate [1]\n  replicate heights\n      <int>   <dbl>\n1         1    1.78\n2         1    1.51\n3         1    1.78\n4         1    1.51\n5         1    2.01\n\n\n\n\n\n\n\n\nNote\n\n\n\nSampling is random. Notice the seed above ensures we get the same bootstrap sample.\n\n\nFrom here, we can compute a bootstrap statistic. E.g.\n\nset.seed(2)\nstudents %>%\n  specify(response = heights) %>%\n  generate(reps = 1, type = \"bootstrap\") %>%\n  calculate(stat = \"median\")\n\nResponse: heights (numeric)\n# A tibble: 1 × 1\n   stat\n  <dbl>\n1  1.78"
  },
  {
    "objectID": "ae/ae-18.html#example-rent-in-manhattan",
    "href": "ae/ae-18.html#example-rent-in-manhattan",
    "title": "Bootstrap",
    "section": "Example: rent in Manhattan",
    "text": "Example: rent in Manhattan\nOn a given day in 2018, twenty one-bedroom apartments were randomly selected on Craigslist Manhattan from apartments listed as “by owner”. The data are in the manhattan data frame. We will use this sample to conduct inference on the typical rent of 1 bedroom apartments in Manhattan.\n\nPart 1: Drawing a bootstrap sample\nLet’s start by using bootstrapping to estimate the mean rent of one-bedroom apartments in Manhattan.\n\nExercise 1\nWhat is a point estimate (i.e. single number summary) of the typical rent?\n\n\nExercise 2\nLet’s bootstrap!\n\nTo bootstrap we will sample with replacement by drawing a value from the box.\nHow many draws do we need for our bootstrap sample?\n\nFill in the values from the bootstrap sample conducted in class. Once the values are filled in, un-comment the code.\n\n# class_bootstrap = c()\n\n\n\nExercise 3\n\nAbout what value do you expect the bootstrap statistic to take?\nCalculate the statistic from the bootstrap sample.\n\n\n# add code\n\n\n\n\nPart 2: Bootstrap confidence interval\nWe will calculate a 95% confidence interval for the mean rent of one-bedroom apartments in Manhattan.\nWe start by setting a seed to ensure our analysis is reproducible.\n\nGenerating the bootstrap distribution\nWe can use R to take many bootstrap samples, compute a statistic and then view the bootstrap distribution of that statistic.\nUn-comment the lines and fill in the blanks to create the bootstrap distribution of sample means and save the results in the data frame boot_dist.\nUse 1000 reps for the in-class activity. (You will use about 10,000 reps for assignments outside of class.)\n\nset.seed(7182022)\n\nboot_dist = manhattan #%>%\n  #specify(______) %>%\n  #generate(______) %>%\n  #calculate(______)\n\n\nHow many rows are in boot_dist?\nWhat does each row represent?\nWhat are the variables in boot_dist? What do they mean?\n\n\n\nVisualize the bootstrap distribution\nA sample statistic is a random variable, we can look at its distribution.\nVisualize the bootstrap distribution using a histogram. Describe the shape and center of the distribution.\n\n# add code\n\n\n\nCalculate the confidence interval\nUncomment the lines and fill in the blanks to construct the 95% bootstrap confidence interval for the mean rent of one-bedroom apartments in Manhattan.\n\n#___ %>%\n#  summarize(lower = quantile(______),\n  #          upper = quantile(______))\n\n\n\nInterpret the interval\nWrite the interpretation for the interval calculated above.\n\nQuestion: Does a confidence interval have to be symmetric?\nWhat is one advantage to using a 90% confidence interval instead of a 95% confidence interval to estimate a parameter? - What is one advantage to using a 99% confidence interval instead of a 95% confidence interval to estimate a parameter?"
  },
  {
    "objectID": "hw/hw-4.html",
    "href": "hw/hw-4.html",
    "title": "HW 4 - Ultra Trail Running",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Friday, March 31st at 5:00pm."
  },
  {
    "objectID": "hw/hw-4.html#getting-started",
    "href": "hw/hw-4.html#getting-started",
    "title": "HW 4 - Ultra Trail Running",
    "section": "Getting Started",
    "text": "Getting Started\n\nGo to the Github Organization page and open your hw4-username repo\nClone the repository, open a new project in RStudio. It contains the starter documents you need to complete the homework assignment."
  },
  {
    "objectID": "hw/hw-4.html#exercises",
    "href": "hw/hw-4.html#exercises",
    "title": "HW 4 - Ultra Trail Running",
    "section": "Exercises",
    "text": "Exercises\n\nTo begin, join the data frames. Save your result as ultra. Next, drop all rows without an observed race time_in_seconds. Your final data frame should have 60924 rows and 20 columns. Print the number of rows of ultra to the screen.\nYour friend computes the mean time in seconds it takes participants of 170+ km races to finish. Your friend also constructs a 90% confidence interval and states, “There is a .9 probability that the sample mean race time for races over 170 km is between 130000 and 160000 seconds.” Without running any code, what is wrong with your friend’s statement? Correct the statement as well (without running any code).\nReport the mean race time for races 170 km or longer and construct a 99% bootstrap confidence interval for the mean race time using set.seed(6) and 5000 reps.\n\nNext, check that central limit theorem holds, do you need to make any assumptions? Use CLT to construct a 99% confidence interval. Compare your result to your bootstrap interval. Interpret the interval.\n\nNow, calculate a 95% bootstrap confidence interval for mean race time for races 170 km or longer (same bootstrap distribution as the previous exercise). Which of the following characteristics change compared to the interval created in question 3? (Please answer “yes” or “no” to each of the following. If you answer “yes”, explain the change observed.)\n\n\nThe center of the confidence interval\nThe width of the confidence interval\n\n\nDoes the standard error of the bootstrap distribution change when you change confidence levels? Use appropriate code to justify your answer.\n\n\n\nIn your own words, describe the process of how to create a bootstrap confidence interval. Be specific.\nIdentify at least two anomalies in the data set. For example, if the same runner ran a race in two different countries on the same day, that would be an anomaly. While this example is false, there are indeed real anomalies in the data. For full credit, display your anomaly either via code (printing to screen) or via a visualization. Discuss your findings.\nGiven the race was in Argentina, what is the median age of runners? Can you use Central Limit Theorem (CLT) to construct a confidence interval about this estimate? Explain. If not, construct a 90% bootstrap confidence interval that bounds the median from below. Use set.seed(8) and 10000 reps. Interpret your interval in context.\n\n– Note, this is not a symmetric confidence interval!\n\nA fellow colleague wants your next investigation to be about mean race times in France. They are adamant that we must use 80% confidence intervals when reporting results. In 1-2 sentences, discuss both any potential benefits and concerns you may have with creating a confidence interval with this low of level."
  },
  {
    "objectID": "hw/hw-4.html#rubric",
    "href": "hw/hw-4.html#rubric",
    "title": "HW 4 - Ultra Trail Running",
    "section": "Rubric",
    "text": "Rubric\n\nEx 1: 5 pts.\nEx 2: 4 pts.\nEx 3: 5 pts.\nEx 4: 10 pts.\nEx 5: 6 pts.\nEx 6: 6 pts.\nEx 7: 5 pts\nEx 8: 4 pts\nWorkflow and formatting - 5 pts"
  },
  {
    "objectID": "hw/hw-4.html#submission",
    "href": "hw/hw-4.html#submission",
    "title": "HW 4 - Ultra Trail Running",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect all pages of your PDF submission to be associated with the “Workflow & formatting” question.\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow. This includes:\n\nlinking all pages appropriately on Gradescope\nputting your name in the YAML at the top of the document\ncommitting the submitted version of your .qmd to GitHub\nAre you under the 80 character code limit? (You shouldn’t have to scroll to see all your code).\nPipes %>%, |> and ggplot layers + should be followed by a new line\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs <- and %>% vs |>\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not."
  },
  {
    "objectID": "ae/ae-19.html",
    "href": "ae/ae-19.html",
    "title": "Central limit theorem",
    "section": "",
    "text": "this ae is due for grade. Push your completed ae to GitHub within 48 hours to receive credit\nproject proposal feedback\nhomework 4 due date updated"
  },
  {
    "objectID": "ae/ae-19.html#getting-started",
    "href": "ae/ae-19.html#getting-started",
    "title": "Central limit theorem",
    "section": "Getting started",
    "text": "Getting started\nClone your ae19-username repo from the GitHub organization."
  },
  {
    "objectID": "ae/ae-19.html#today",
    "href": "ae/ae-19.html#today",
    "title": "Central limit theorem",
    "section": "Today",
    "text": "Today\nBy the end of today you will…\n\nUse Central Limit Theorem to define distribution of sample means\nCalculate probabilities from the normal distribution\nUse Central Limit Theorem (CLT) to conduct inference on a population mean"
  },
  {
    "objectID": "ae/ae-19.html#load-packages",
    "href": "ae/ae-19.html#load-packages",
    "title": "Central limit theorem",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-19.html#load-data",
    "href": "ae/ae-19.html#load-data",
    "title": "Central limit theorem",
    "section": "Load data",
    "text": "Load data\n\nmanhattan = read_csv(\n  \"https://sta101-fa22.netlify.app/static/appex/data/manhattan.csv\"\n  )"
  },
  {
    "objectID": "ae/ae-19.html#notes-for-reference",
    "href": "ae/ae-19.html#notes-for-reference",
    "title": "Bootstrap",
    "section": "Notes (for reference)",
    "text": "Notes (for reference)\nBootstrapping is a re-sampling technique. The key idea is you have already collected a sample of size \\(N\\) from the population. To create a bootstrap sample, you sample with replacement from your original sample \\(N\\) times.\nLet’s say you measure the height of five Duke students in meters:\n\nheights = c(1.51, 1.62, 1.89, 2.01, 1.78)\n\nstudents = data.frame(heights)\n\nThere are many ways to create a bootstrap sample in R. We will focus on the tidy way below. which uses the infer package that loads with tidymodels.\n\nExample\n\nset.seed(2)\nstudents %>%\n  specify(response = heights) %>%\n  generate(reps = 1, type = \"bootstrap\")\n\nResponse: heights (numeric)\n# A tibble: 5 × 2\n# Groups:   replicate [1]\n  replicate heights\n      <int>   <dbl>\n1         1    1.78\n2         1    1.51\n3         1    1.78\n4         1    1.51\n5         1    2.01\n\n\n\n\n\n\n\n\nNote\n\n\n\nSampling is random. Notice the seed above ensures we get the same bootstrap sample.\n\n\nFrom here, we can compute a bootstrap statistic. E.g.\n\nset.seed(2)\nstudents %>%\n  specify(response = heights) %>%\n  generate(reps = 1, type = \"bootstrap\") %>%\n  calculate(stat = \"median\")\n\nResponse: heights (numeric)\n# A tibble: 1 × 1\n   stat\n  <dbl>\n1  1.78"
  },
  {
    "objectID": "ae/ae-19.html#example-rent-in-manhattan",
    "href": "ae/ae-19.html#example-rent-in-manhattan",
    "title": "Bootstrap",
    "section": "Example: rent in Manhattan",
    "text": "Example: rent in Manhattan\nOn a given day in 2018, twenty one-bedroom apartments were randomly selected on Craigslist Manhattan from apartments listed as “by owner”. The data are in the manhattan data frame. We will use this sample to conduct inference on the typical rent of 1 bedroom apartments in Manhattan.\n\nPart 1: Drawing a bootstrap sample\nLet’s start by using bootstrapping to estimate the mean rent of one-bedroom apartments in Manhattan.\n\nExercise 1\nWhat is a point estimate (i.e. single number summary) of the typical rent?\n\n\nExercise 2\nLet’s bootstrap!\n\nTo bootstrap we will sample with replacement by drawing a value from the box.\nHow many draws do we need for our bootstrap sample?\n\nFill in the values from the bootstrap sample conducted in class. Once the values are filled in, un-comment the code.\n\n# class_bootstrap = c()\n\n\n\nExercise 3\n\nAbout what value do you expect the bootstrap statistic to take?\nCalculate the statistic from the bootstrap sample.\n\n\n# add code\n\n\n\n\nPart 2: Bootstrap confidence interval\nWe will calculate a 95% confidence interval for the mean rent of one-bedroom apartments in Manhattan.\nWe start by setting a seed to ensure our analysis is reproducible.\n\nGenerating the bootstrap distribution\nWe can use R to take many bootstrap samples, compute a statistic and then view the bootstrap distribution of that statistic.\nUn-comment the lines and fill in the blanks to create the bootstrap distribution of sample means and save the results in the data frame boot_dist.\nUse 1000 reps for the in-class activity. (You will use about 10,000 reps for assignments outside of class.)\n\nset.seed(7182022)\n\nboot_dist = manhattan #%>%\n  #specify(______) %>%\n  #generate(______) %>%\n  #calculate(______)\n\n\nHow many rows are in boot_dist?\nWhat does each row represent?\nWhat are the variables in boot_dist? What do they mean?\n\n\n\nVisualize the bootstrap distribution\nA sample statistic is a random variable, we can look at its distribution.\nVisualize the bootstrap distribution using a histogram. Describe the shape and center of the distribution.\n\n# add code\n\n\n\nCalculate the confidence interval\nUncomment the lines and fill in the blanks to construct the 95% bootstrap confidence interval for the mean rent of one-bedroom apartments in Manhattan.\n\n#___ %>%\n#  summarize(lower = quantile(______),\n  #          upper = quantile(______))\n\n\n\nInterpret the interval\nWrite the interpretation for the interval calculated above.\n\nQuestion: Does a confidence interval have to be symmetric?\nWhat is one advantage to using a 90% confidence interval instead of a 95% confidence interval to estimate a parameter? - What is one advantage to using a 99% confidence interval instead of a 95% confidence interval to estimate a parameter?"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus.\nOur course coordinator, Edric Tam, will handle all inquiries about late work, extensions and absences in accordance with the late policy described in the syllabus below. Please send emails to sta199@duke.edu."
  },
  {
    "objectID": "course-syllabus.html#class-time-and-location",
    "href": "course-syllabus.html#class-time-and-location",
    "title": "Syllabus",
    "section": "Class time and location",
    "text": "Class time and location\n\n\n\nLecture\nW/F: 10:15-11:30 AM\nLSRC B101\nDr. Alexander Fisher\n\n\nLab 1\nM: 10:15-11:30 AM\nPerkins LINK 087 (Classroom 3)\nDavid Buch, Isabella Swigart\n\n\nLab 2\nM: 12:00-1:15 PM\nPerkins LINK 087 (Classroom 3)\nAlonso M Guerrero Castañeda, Kelly Huang\n\n\nLab 3\nM: 1:45-3:00 PM\nPerkins LINK 087 (Classroom 3)\nShuo Wang, Eva Noel\n\n\nLab 4\nM: 3:30-4:35 PM\nPerkins LINK 087 (Classroom 3)\nNathan Varberg, Ben Wallace\n\n\nLab 5\nM: 5:15-6:30 PM\nPerkins LINK 087 (Classroom 3)\nNaomie Gao, Miles Eng\n\n\nLab 11\nM: 5:15 - 6:30 PM\nPerkins LINK 071 (Classroom 5)\nOne Chowdhury, Konnie Huang"
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office hours",
    "text": "Office hours\nClick here for the instructor and TA office hours locations and Zoom links. You are welcome to attend the office hours of any member of the teaching team, regardless of section."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nAll books are freely available online.\n\n\n\nR for Data Science, 2e\nGrolemund, Wickham\nO’Reilly, 2nd edition, 2022\nHard copy only available of 1st edition\n\n\nIntroduction to Modern Statistics\nÇetinkaya-Rundel, Hardin\nOpenIntro Inc., 1st Edition, 2021\nHard copy available on Amazon"
  },
  {
    "objectID": "course-syllabus.html#course-learning-objectives",
    "href": "course-syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will…\n\nlearn to explore, visualize, and analyze data in a reproducible manner\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to effectively communicate results through written assignments and project presentation\ndevelop your own question about a data set of your choosing and use techniques from this class to answer the question"
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. They are designed to follow the Prepare, Practice, Perform format.\n\nPrepare: Includes short videos, reading assignments, and lectures to introduce new concepts and ensure a basic comprehension of the material. The goal is to help you prepare for the in-class activities during lecture.\nPractice: In-class application exercises where you will begin to master the concepts and methods introduced in the prepare assignment. The activities will graded for completion, as they are designed for you to gain experience with the statistical and computing techniques before working on graded assignments.\nPerform: Includes labs, homework, exams, and the project. These assignments build upon the prepare and practice assignments and are the opportunity for you to demonstrate your understanding of the course material and how it is applied to analyze real-world data.\n\n\nTeam work policy\nThe final project and several labs will be completed in teams. GitHub commits will be used to measure individual contribution to the assignment. All group members are expected to participate equally. Commit history may be used to give individual team members different grades. Your grade may differ from the rest of your group.\n\n\nApplication exercises (practice)\nEach lecture, we will work through application exercise (AEs). These serve as notes you will fill in during class mixed with practice exercises. Exercises which give you an opportunity to practice statistical concepts and code introduced in the prepare assignment.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade. To submit an AE, you simply need to push your completed AE to the designated repo in GitHub.\n\n\nLabs (perform)\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Some lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, see team work policy above. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and be submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework (perform)\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nHomework assignments are due at 5:00 PM ET on the indicated due date.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams (perform)\nThere will be two, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analysis and computational tasks related to the content in the prepare, practice, and perform assignments. More details about the content and structure of the exams will be discussed during the semester.\n\n\nProject (perform)\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nLabs\n15%\n\n\nProject\n15%\n\n\nExam 01\n18%\n\n\nExam 02\n18%\n\n\nApplication Exercises\n4%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\nInclusive community: It is my intent that students from all backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nAcademic honesty: You should be familiar with Duke’s community standard: https://studentaffairs.duke.edu/conduct/about-us/duke-community-standard\nBy enrolling in this course, you commit to upholding Duke’s community standard reproduced as follows:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\nPlease abide by the following as you work on assignments in this course: - You may discuss lab assignments with other students; however, you may not directly share (or copy) code or write up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write up with another team. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved. - You may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date. - Reusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. Stack- Overflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nLate policy:\nHomeworks and labs can be turned in within 72 hours of the deadline for grade penalty (5% off per day, stacks to 15% by the third day). Exams cannot be turned in late and can only be excused under exceptional circumstances. The Duke policy for illness requires a short-term illness report or a letter from the Dean; except in emergencies, all other absenteeism must be approved in advance (e.g., an athlete who must miss class may be excused by prior arrangement for specific days). For emergencies, email notification is needed at the first reasonable time.\n\nAll exemptions will be handled by course coordinator, Ed Tam, at sta199@duke.edu\nLast minute coding/rendering issues will not be granted extensions.\n\nProcedures for Requesting a Regrade\nEvery effort will be made to mark your work accurately. We are on your side, and want you to receive every point you have worked to earn. However, sometimes grading mistakes happen. If you believe that an error has been made, return the paper to the instructor within four days, stating your claim in writing.\nThe following claims will be considered for re-grading:\n\npoints are not totaled correctly;\nthe grader did not see a correct answer that is on your paper;\nyour answer is the same as the correct answer, but in a different form (e.g., you wrote a correct answer as 1/3 and the grader was looking for .333);\nyour answer to a free response question is essentially correct but stated slightly differently than the grader’s expectation.\n\nThe following claims will not be considered for re-grading:\n\narguments about the number of points lost;\n\n\n\narguments about question wording.\n\nConsidering re-grades consumes time and resources that TAs and the instructor would rather spend helping you understand material. Please bring only claims of type (i), (ii), (iii), or (iv) to our attention.\nCommunication: All lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website. Announcements will be emailed to the class through sakai. Please check your email regularly to ensure you have the latest announcements for the course. For quick communication with your peers and the teaching team, see the course slack for general questions and discussion.\nAccessibility: If there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations. The Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu."
  },
  {
    "objectID": "course-syllabus.html#additional-resources",
    "href": "course-syllabus.html#additional-resources",
    "title": "Syllabus",
    "section": "Additional resources",
    "text": "Additional resources\nStudent mental health and wellness are of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu. The Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, and more. ARC services are available free to any Duke undergraduate student, studying any discipline.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach. Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: https://students.duke.edu/wellness/dukereach/\nCounseling and Psychological Services (CAPS). CAPS services include individual and group counseling services, psychiatric services, and workshops. To initiate services, walk-in/call-in 9-4 M,W,Th,F and 9-6 Tuesdays. CAPS also provides referral to off- campus resources for specialized care.\n\n660-1000 or https://students.duke.edu/wellness/caps/\n\nTimelyCare (formerly known as Blue Devils Care). An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu"
  },
  {
    "objectID": "ae/ae-19.html#notes",
    "href": "ae/ae-19.html#notes",
    "title": "Central limit theorem",
    "section": "Notes",
    "text": "Notes\nHow do we know when to expect a normal distribution to show up?\nLooking at the data from last time, we can see an example where the distribution of sample means looked approximately normal but the distribution of sample medians does not.\nExample:\n\nset.seed(1)\nboot_dist = manhattan %>%\n  specify(response = rent) %>% \n  generate(reps = 1000, type = \"bootstrap\")\n\nboot_dist %>%\n  calculate(stat = \"mean\") %>%\n  visualize() +\n  labs(x = \"Sample mean\", \n       title = \"Simulated distribution of the sample mean\")\n\n\n\nboot_dist %>%\n  calculate(stat = \"median\") %>%\n  visualize() + \n  labs(x = \"Sample median\",\n       title = \"Simulated distribution of the sample median\")\n\n\n\n\nAre there times when the sample mean will not look normal?\n\nDemo\nThe proportion of observed successes for a binary variable is a sample mean.\nScenario: You flip a biased coin numFlips times and compute the sample mean (the proportion of flips that land heads). You repeat this experiment 1000 times and obtain a distribution of sample means.\n\nHow does the shape of the distribution change as you increase the number of coin flips per sample?\n\n\nset.seed(714)\nnumFlips = 1\nnumHeads = rbinom(n = 1000, size = numFlips, prob = 0.9)\ndf = data.frame(numHeads) # new data frame called df\ndf %>%\nmutate(propHeads = numHeads / numFlips) %>%\nggplot(aes(x = propHeads)) +\ngeom_histogram(binwidth = .01)"
  },
  {
    "objectID": "ae/ae-19.html#what-is-the-central-limit-theorem",
    "href": "ae/ae-19.html#what-is-the-central-limit-theorem",
    "title": "Central limit theorem",
    "section": "What is the central limit theorem?",
    "text": "What is the central limit theorem?\nThe central limit theorem is a statement about the distribution of the sample mean, \\(\\bar{x}\\).\nThe central limit theorem guarantees that, when certain criteria are satisfied, the sample mean (\\(\\bar{x}\\)) is normally distributed.\nSpecifically, if\n\nObservations in the sample are independent. Two rules of thumb to check this:\n\ncompletely random sampling\nif sampling without replacement, sample should be less than 10% of the population size\n\n\nand\n\nThe sample is large enough. The required size varies in different contexts, but some good rules of thumb are:\n\nif the population itself is normal, sample size does not matter.\nif numerical require, >30 observations\nif binary outcome, at least 10 successes and 10 failures.\n\n\nthen\n\\[\n\\bar{x} \\sim N(\\mu, \\sigma / \\sqrt{n})\n\\]\ni.e. \\(\\bar{x}\\) is normally distributed (unimodal and symmetric with bell shape) with mean \\(\\mu\\) and standard deviation \\(\\sigma / \\sqrt{n}\\). The standard deviation of the sampling distribution is called the standard error.\n\n\n\n\n\n\nNote\n\n\n\nThe standard deviation of the sample mean depends on the number of samples, \\(n\\)."
  },
  {
    "objectID": "ae/ae-19.html#practice-using-clt-normal-distribution",
    "href": "ae/ae-19.html#practice-using-clt-normal-distribution",
    "title": "Central limit theorem",
    "section": "Practice using CLT & Normal distribution",
    "text": "Practice using CLT & Normal distribution\nSuppose the bone density for 65-year-old women is normally distributed with mean \\(809 mg/cm^3\\) and standard deviation of \\(140 mg/cm^3\\).\nLet \\(x\\) be the bone density of 65-year-old women. We can write this distribution of \\(x\\) in mathematical notation as\n\\[x \\sim N(809, 140)\\]"
  },
  {
    "objectID": "ae/ae-19.html#visualize-the-population-distribution",
    "href": "ae/ae-19.html#visualize-the-population-distribution",
    "title": "Central limit theorem",
    "section": "Visualize the population distribution",
    "text": "Visualize the population distribution\n\nggplot(data = data.frame(x = c(809 - 140*3, 809 + 140*3)), aes(x = x)) +\n  stat_function(fun = dnorm, args = list(mean = 809, sd = 140),\n                color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = 809, sd = 140/sqrt(10)),\n                color = \"red\",lty = 2) + theme_bw() +\n  labs(title = \"Black solid line = population dist., Red dotted line = sampling dist.\")\n\n\n\n\n\nExercise 1\nBefore typing any code, based on what you know about the normal distribution, what do you expect the median bone density to be?\nWhat bone densities correspond to \\(Q_1\\) (25th percentile), \\(Q_2\\) (50th percentile), and \\(Q_3\\) (the 75th percentile) of this distribution? Use the qnorm() function to calculate these values.\n\n\nExercise 2\nThe densities of three woods are below:\n\nPlywood: 540 mg/cubic centimeter\nPine: 600 mg/cubic centimeter\nMahogany: 710 mg/cubic centimeter\nWhat is the probability that a randomly selected 65-year-old woman has bones less dense than Pine?\nWould you be surprised if a randomly selected 65-year-old woman had bone density less than Mahogany? What if she had bone density less than Plywood? Use the respective probabilities to support your response.\n\n\n\nExercise 3\nSuppose you want to analyze the mean bone density for a group of 10 randomly selected 65-year-old women.\n\nAre the conditions for the Central Limit Theorem met?\n\nIndependence?\nSample size/distribution?\n\nWhat is the shape, center, and spread of the distribution of \\(\\bar{x}\\), the mean bone density for a group of 10 randomly selected 65-year-old women?\nWrite the distribution of \\(\\bar{x}\\) using mathematical notation.\n\n\n\nExercise 4\n\nWhat is the probability that the mean bone density for the group of 10 randomly-selected 65-year-old women is less dense than Pine?\nWould you be surprised if a group of 10 randomly-selected 65-year old women had a mean bone density less than Mahogany? What the group had a mean bone density less than Plywood? Use the respective probabilities to support your response.\n\n\n\nExercise 5\nExplain how your answers differ in Exercises 3 and 5."
  },
  {
    "objectID": "ae/ae-19.html#extra-practice-on-your-own",
    "href": "ae/ae-19.html#extra-practice-on-your-own",
    "title": "Central limit theorem",
    "section": "Extra practice (on your own)",
    "text": "Extra practice (on your own)\nSuppose the distribution of the number of minutes users engage with apps on an iPad has a mean of 8.2 minutes and standard deviation of 1 minute. Let \\(x\\) be the number of minutes users engage with apps on an iPad, \\(\\mu\\) be the population mean and \\(\\sigma\\) the population standard deviation. Then,\n\\[x \\sim N(8.2, 1)\\]\nSuppose you take a sample of 60 randomly selected app users and calculate the mean number of minutes they engage with apps on an iPad, \\(\\bar{x}\\). The conditions (independence & sample size/distribution) to apply the Central Limit Theorem are met. Then by the Central Limit Theorem\n\\[\\bar{x} \\sim N(8.2, 1/\\sqrt{60})\\]\n\nWhat is the probability a randomly selected user engages with iPad apps for more than 8.3 minutes? Use pnorm for calculations.\n\n#add code\n\nWhat is the probability the mean minutes of app engagement for a group of 60 randomly selected iPad users is more than 8.3 minutes? Use pnorm for calculations.\n\n#add code\n\nWhat is the probability the mean minutes of app engagement for a group of 60 randomly selected iPad users is between 8.3 and 8.4 minutes? Use pnorm for calculations.\n\n\n    #add code"
  },
  {
    "objectID": "ae/ae-20.html",
    "href": "ae/ae-20.html",
    "title": "Central limit theorem II",
    "section": "",
    "text": "this ae is due for grade. Push your completed ae to GitHub within 48 hours to receive credit\nhomework 4 due Friday"
  },
  {
    "objectID": "ae/ae-20.html#getting-started",
    "href": "ae/ae-20.html#getting-started",
    "title": "Central limit theorem II",
    "section": "Getting started",
    "text": "Getting started\nClone your ae20-username repo from the GitHub organization."
  },
  {
    "objectID": "ae/ae-20.html#today",
    "href": "ae/ae-20.html#today",
    "title": "Central limit theorem II",
    "section": "Today",
    "text": "Today\nBy the end of today you will…\n\nUse CLT to construct confidence intervals"
  },
  {
    "objectID": "ae/ae-20.html#load-packages",
    "href": "ae/ae-20.html#load-packages",
    "title": "Central limit theorem II",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-20.html#load-data-pokemon",
    "href": "ae/ae-20.html#load-data-pokemon",
    "title": "Central limit theorem II",
    "section": "Load Data: Pokemon",
    "text": "Load Data: Pokemon\nWe will be using the pokemon data set, which contains information about 42 randomly selected Pokemon (from all generations). You may load in the data set with the following code:\n\npokemon = read_csv(\"https://sta101.github.io/static/appex/data/pokemon.csv\")\n\nIn this analysis, we will use CLT-based inference to draw conclusions about the mean height among all Pokemon species.\n\nExercise 1\nLet’s start by looking at the distribution of height_m, the typical height in meters for a Pokemon species, using a visualization and summary statistics.\n\nggplot(data = pokemon, aes(x = height_m)) +\n  geom_histogram(binwidth = 0.25, fill = \"steelblue\", color = \"black\") + \n  labs(x = \"Height (in meters)\", \n       y = \"Distributon of Pokemon heights\")\n\n\n\n\n\npokemon %>%\n  summarise(mean_height = mean(height_m), \n            sd_height = sd(height_m), \n            n_pokemon = n())\n\n# A tibble: 1 × 3\n  mean_height sd_height n_pokemon\n        <dbl>     <dbl>     <int>\n1       0.929     0.497        42\n\n\nIn the previous lecture we were given the mean, \\(\\mu\\), and standard deviation, \\(\\sigma\\), of the population. That is unrealistic in practice (if we knew \\(\\mu\\) and \\(\\sigma\\), we wouldn’t need to do statistical inference!).\nToday we will start on using the Central Limit Theorem to draw conclusions about the \\(\\mu\\), the mean height in the population of Pokemon.\n\nWhat is the point estimate for \\(\\mu\\), i.e., the “best guess” for the mean height of all Pokemon?\nWhat is the point estimate for \\(\\sigma\\), i.e., the “best guess” for the standard deviation of the distribution of Pokemon heights?\n\n\n\nExercise 2\nBefore moving forward, let’s check the conditions required to apply the Central Limit Theorem. Are the following conditions met:\n\nIndependence?\nSample size/distribution?\n\n\n\nCentral limit theorem\nRemember, when the independence and sample size assumptions are met, the central limit theorem states\n\\[\n\\bar{x} \\sim N(\\mu, \\sigma / \\sqrt{n})\n\\]\nIf we know \\(\\sigma\\), we can construct a symmetric confidence interval for the true mean easily using qnorm().\nFor example, if the true standard deviation in pokemon height is 0.4 meters, then to construct a 95% confidence interval:\n\nxbar = pokemon %>%\n  summarize(xbar = mean(height_m)) %>%\n  pull(xbar)\n\nqnorm(c(0.025, 0.975), mean = xbar, sd = 0.4)\n\n[1] 0.1445858 1.7125570\n\n\nThis can be equivalently expressed\n\nzscore = qnorm(0.025)\nxbar + zscore*0.4\n\n[1] 0.1445858\n\nxbar - zscore*0.4\n\n[1] 1.712557\n\n\nwhere we use the fact that we can write any normal distribution as a linear combination of a standard normal. For example,\nif \\(X \\sim N(0.928, .4)\\), then \\(X = .4Z + 0.928\\) where \\(Z\\) is standard normal, in other words \\(Z \\sim N(0, 1)\\).\nIn general, the confidence interval can be written as\n\\[\n\\bar{x} \\pm z^* \\times \\sigma\n\\]\nwhere \\(z^*\\) is the quantile of a standard normal distribution associated with our level of confidence.\nWhat about when we don’t know \\(\\sigma\\)?\n\n\nPractical confidence intervals\nWe don’t know the true population mean \\(\\mu\\) and standard deviation \\(\\sigma\\), how do we use CLT to construct a confidence interval?\nWe approximate \\(\\mu\\) by \\(\\bar{x}\\) and \\(\\sigma\\) by the same standard deviation \\(s\\). However \\(s\\) may be smaller than \\(\\sigma\\) and our confidence interval could be too narrow, for example, run the code below to compute the standard deviation of three draws from a standard normal.\n\nset.seed(6)\nsamples = rnorm(3, mean = 0, sd = 1)\nsd(samples)\n\n[1] 0.7543284\n\n\nThis was just for 1 random seed. If you remove the seed and repeat the simulation, you will find that \\(s\\) is sometimes above and sometimes below the true standard deviation.\nTo account for this uncertainty, we will use a distribution with thicker tails. This sampling distribution is called a t-distribution.\n\nggplot(data = data.frame(x = c(0 - 1*3, 0 + 1*3)), aes(x = x)) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),\n                color = \"black\") +\n  stat_function(fun = dt, args = list(df = 3),\n                color = \"red\",lty = 2) + theme_bw() +\n  labs(title = \"Black solid line = normal, Red dotted line = t-distribution\")\n\n\n\n\nThe t-distribution has a bell shape but the extra thick tails help us correct for the variability introduced by using \\(s\\) instead of \\(\\sigma\\).\nThe t-distribution, like the standard normal, is always centered at zero. Therefore, the t-distribution has only a single parameter: degrees of freedom. The degrees of freedom describes the precise form of the bell-shaped t-distribution. In general, we’ll use a t-distribution with \\(df=n−1\\) to model the sample mean when the sample size is \\(n\\).\nWe can use qt and pt to find quantiles and probabilities respectively under the t-distribution.\n\n\nConfidence interval\nTo construct our practical confidence interval (where we don’t know \\(\\sigma\\)) we use the t-distribution:\n\\[\n\\bar{x} \\pm t^*_{n-1} \\times \\frac{s}{\\sqrt{n}}\n\\]\n\nExercise 3\n\nCalculate the 95% confidence interval for pokemon height using the t-distribution.\n\n\n# code here\n\nHow does this compare to a 95% bootstrap confidence interval?\n\n# code here"
  }
]