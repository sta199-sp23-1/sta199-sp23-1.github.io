[
  {
    "objectID": "labs/lab-project-peer-review.html",
    "href": "labs/lab-project-peer-review.html",
    "title": "Lab - Project peer review",
    "section": "",
    "text": "Learning goals\nIn this lab, you will…\n\nReview others’ project drafts as a team and provide feedback\nPost issues on GitHub using an issue template\nLearn from others’ projects and improve your own project based on their strengths and weaknesses\n\n\n\nProject peer review\nEach team will review two other teams’ project. As a team you should spend ~30 minutes on each team’s project.\n\nFind the names of the teams whose projects you’re reviewing below. You should already have access to this team's repo.\nEach team member should go to the repo of the team you’re reviewing.\nThen,\n\n1-2 team members clone the team’s project and renders it to check for reproducibility.\n1-2 team members open the team’s project in their browser and starts reading through the project draft.\n1 team member opens an issue on the team’s repo using the peer review template.\nAll team members discuss the project based on the prompts on the issue template and one team member records the feedback and submits the issue.\n\nTo open an issue in the repo you’re reviewing, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical reasoning aspect of the project, but do feel free to comment on aspects beyond the reasoning as well.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nWere you able to reproduce the project by clicking on Render Website once you cloned it? Were there any issues with reproducibility?\nProvide constructive feedback on any issues with file and/or code organization.\nWhat have you learned from this team’s project that you are considering implementing in your own project?\n(Optional) Any further comments or feedback?\n\n\n\n\nReview pairings\n\n\n\n\n\n\n  \n  \n    \n      Your team name\n      To review 1\n      To review 2\n    \n  \n  \n    \n      Section 1 - M 10:15 - 11:30 am\n    \n    Alpha equals one\nSeven\nSealteam6\n    2cool4school\nAlpha equals one\nSeven\n    ggplot3\n2cool4school\nAlpha equals one\n    Cuatro\nggplot3\n2cool4school\n    Cinco\nCuatro\nggplot3\n    Sealteam6\nCinco\nCuatro\n    Seven\nSealteam6\nCinco\n    \n      Section 2 - M 1:45 - 3:00 pm\n    \n    Blue Squirrels\nWho's your data?\nSuffer\n    Stats R Us\nBlue Squirrels\nWho's your data?\n    Team300\nStats R Us\nBlue Squirrels\n    geom_slay\nTeam300\nStats R Us\n    Suffer\ngeom_slay\nTeam300\n    Who's your data?\nSuffer\ngeom_slay\n    \n      Section 3 - M 3:30 - 4:45 pm\n    \n    Cool Kids\nSeven Wonders\nMine's Minions\n    Meteors\nCool Kids\nSeven Wonders\n    Green Team\nMeteors\nCool Kids\n    Fantastic Four\nGreen Team\nMeteors\n    Theta-Five\nFantastic Four\nGreen Team\n    Mine's Minions\nTheta-Five\nFantastic Four\n    Seven Wonders\nMine's Minions\nTheta-Five\n    \n      Section 4 - M 5:15 - 6:30 pm\n    \n    Merge Conflicts\ngroup_by(6)\nGit Freaky\n    Quart2\nMerge Conflicts\ngroup_by(6)\n    Git Real\nQuart2\nMerge Conflicts\n    Kameron Krazies\nGit Real\nQuart2\n    Git Freaky\nKameron Krazies\nGit Real\n    group_by(6)\nGit Freaky\nKameron Krazies\n    \n      Section 5 - M 12:00 - 1:15 pm\n    \n    Women in Tech\nSplit Ends\nSuper Raspberries\n    Stats Sisters\nWomen in Tech\nSplit Ends\n    The Outliers\nStats Sisters\nWomen in Tech\n    Duke Data Devils\nThe Outliers\nStats Sisters\n    Super Raspberries\nDuke Data Devils\nThe Outliers\n    Split Ends\nSuper Raspberries\nDuke Data Devils\n  \n  \n  \n\n\n\n\n\n\nGrading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the reviewee’s team’s report.\nOnly the team members participating in the review during the lab session are eligible for points for the peer review. If you’re unable to make it to lab in person, you should arrange to virtually connect with your team during your lab session.\n\n0 points: No peer review\n1 point: Only one peer review issue open, feedback provided is not constructive or actionable\n2 points: Both peer review issues open, feedback provided is not constructive or actionable\n3 points: Both peer review issues open, feedback provided is not sufficiently thorough\n4 points: Both peer review issues open, one of the reviews is not sufficiently thorough\n5 points: Both peer review issues open, both reviews are constructive, actionable, and sufficiently thorough\n\n\n\n\n\n\n\nNote\n\n\n\nThe feedback issue will come from one team member on GitHub since you can’t collectively edit an issue. However it must represent the opinions of the entire team. It is not a single team member’s responsibility to provide feedback, they’re just the record keeper for the team."
  },
  {
    "objectID": "labs/lab-project-draft.html",
    "href": "labs/lab-project-draft.html",
    "title": "Lab - Project draft",
    "section": "",
    "text": "Important\n\n\n\nThe project draft is due Friday, Nov 11, at 11:59pm. No submission on Gradescope needed, just push to GitHub by this time."
  },
  {
    "objectID": "labs/lab-project-draft.html#proposal-feedback-review",
    "href": "labs/lab-project-draft.html#proposal-feedback-review",
    "title": "Lab - Project draft",
    "section": "Proposal feedback review",
    "text": "Proposal feedback review\n\n\n\n\n\n\nImportant\n\n\n\nYou do not need to submit a revised version of your proposal, but if there are issues in your proposal that prevent your project from rendering, you should fix those.\n\n\n\nAs a team, review all feedback left as issues in your GitHub repo.\nEither close the issues on GitHub (by clicking on the Close Issue button) or address them with commits to your project like you learned last week.\nMake decision about which dataset you will use for your project and going forward write up your analysis in report.qmd."
  },
  {
    "objectID": "labs/lab-project-draft.html#project-draft",
    "href": "labs/lab-project-draft.html#project-draft",
    "title": "Lab - Project draft",
    "section": "Project draft",
    "text": "Project draft\n\n\n\n\n\n\nImportant\n\n\n\nYour next project related deadline is Fri, Nov 11 at 11:59pm. Your project draft, written in report.qmd, must be pushed to GitHub by that time. You will lose push access to your repo at that time until your draft has been reviewed. Once again, you will receive feedback as issues on your GitHub repository.\n\n\n\nReview https://sta199-f22-1.github.io/project-description.html#draft for requirements for the project draft.\nStart working on your draft! Make good use of the time with your TA during lab.\nOnce you complete your draft but before you finalize it:\n\nIn report.qmd set echo: false in the YAML of your document. Read through your draft completely and make sure everything makes sense without the code visible, and make any edits as needed. Then, set echo: true again before submitting. (For your draft we want to see your code so we can provide feedback on it. For your final report we will ask you to hide it again.)\nUpdate your index.qmd:\n\nUpdate the title field with your team name.\nAdd your abstract.\n\nUpdate your About page (about.qmd) with information on your team."
  },
  {
    "objectID": "labs/lab-project-draft.html#quarto-options",
    "href": "labs/lab-project-draft.html#quarto-options",
    "title": "Lab - Project draft",
    "section": "Quarto options",
    "text": "Quarto options\n\n\n\n\n\n\nNote\n\n\n\nMuch of what is listed in this section is optional, but we recommend reviewing them as a team and deciding on which ones you want to use/include in your project.\n\n\n\nTheming\nYou can see your deployed project website at the URL listed in your project repo.\n\nYou can pick a theme from https://quarto.org/docs/output-formats/html-themes.html.\nYou can update the theme of your project by changing the theme field in the _quarto.yml file.\nRender the website from the Build tab and commit and push your changes.\n\n\n\nFootnotes\nTo add a footnote, make sure you’re in the Visual editor mode in RStudio and click on Insert > Footnote.1 One you add your footnote, click outside of the footnote area, anywhere else in your document, to go back to editing your document.\n\n\nCross references\nYou can add cross references to your figures and tables so that you can refer to them like “Figure 1 shows that …” or “As seen in Table 1, …” instead of “the figure below” or “the table below”. To do this, you need to label the code chunks for those figures and tables in a special way (with fig- and tbl- suffixes, respectively) and add captions to them.\n\nFigures\nFor example, Figure 1 shows a positive and moderately strong relationship between fuel efficiency of cars (measured as miles/gallon) and their displacement.\n\n```{r}\n#| label: fig-mtcars-plot\n#| fig-cap: \"Fuel efficiency of cars vs. their displacement.\"\n\nggplot(mtcars, aes(x = disp, y = mpg)) +\n  geom_point()\n```\n\n\n\n\nFigure 1: Fuel efficiency of cars vs. their displacement.\n\n\n\n\nWhat you’re not seeing in the text above is that we didn’t type Figure 1 in the text, but instead referenced this figure with @fig-mtcars-plot:\n\nFor example, @fig-mtcars-plot shows a positive and moderately strong relationship between fuel efficiency of cars (measured as miles/gallon) and their displacement.\n\n\n\nTables\nAnd Table 1 shows the output of the linear regression for predicting fuel efficiency from displacement.\nNote that we piped the result of the tidy() function (which outputs a tibble) into the kable() function from the knitr package to turn it into a table. Quarto needs this last step to know that this code chunk produces a table that can be formatted and cross referenced as such.\n\n```{r}\n#| label: tbl-mpg-disp\n#| tbl-cap: \"Linear regression model for predicting fuel efficiency from displacement.\"\n\nlinear_reg() |>\n  fit(mpg ~ disp, data = mtcars) |>\n  tidy() |>\n  knitr::kable()\n```\n\n\n\nTable 1: Linear regression model for predicting fuel efficiency from displacement.\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n29.5998548\n1.2297195\n24.070411\n0\n\n\ndisp\n-0.0412151\n0.0047118\n-8.747151\n0\n\n\n\n\n\n\nOnce again, what you’re not seeing in the text above is that we didn’t type Table 1 in the text, but instead referenced this table with @tbl-mpg-disp.\n\nAnd @tbl-mpg-disp shows the output of the linear regression for predicting fuel efficiency from displacement."
  },
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday, Sep 23 at 11:59pm."
  },
  {
    "objectID": "labs/lab-2.html#warm-up",
    "href": "labs/lab-2.html#warm-up",
    "title": "Lab 2 - Data wrangling",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and render the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your `.qmd and .pdf files. If anything is missing, render, commit, and push again."
  },
  {
    "objectID": "labs/lab-2.html#packages",
    "href": "labs/lab-2.html#packages",
    "title": "Lab 2 - Data wrangling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/lab-2.html#data",
    "href": "labs/lab-2.html#data",
    "title": "Lab 2 - Data wrangling",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSV (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nThe descriptions of the variables are as follows:\n\nid: ID number\nfirstname: First name of laureate\nsurname: Surname\nyear: Year prize won\ncategory: Category of prize\naffiliation: Affiliation of laureate\ncity: City of laureate in prize year\ncountry: Country of laureate in prize year\nborn_date: Birth date of laureate\ndied_date: Death date of laureate\ngender: Gender of laureate\nborn_city: City where laureate was born\nborn_country: Country where laureate was born\nborn_country_code: Code of country where laureate was born\ndied_city: City where laureate died\ndied_country: Country where laureate died\ndied_country_code: Code of country where laureate died\noverall_motivation: Overall motivation for recognition\nshare: Number of other winners award is shared with\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix _original.\n\nborn_country_original: Original country where laureate was born\nborn_city_original: Original city where laureate was born\ndied_country_original: Original country where laureate died\ndied_city_original: Original city where laureate died\ncity_original: Original city where laureate lived at the time of winning the award\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "labs/lab-2.html#get-to-know-your-data",
    "href": "labs/lab-2.html#get-to-know-your-data",
    "title": "Lab 2 - Data wrangling",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\n\n\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code."
  },
  {
    "objectID": "labs/lab-2.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "labs/lab-2.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 2 - Data wrangling",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nnobel_living <- nobel_living |>\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science <- nobel_living |>\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the following exercises, work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your Quarto document, even though the next exercise doesn’t explicitly ask you to do so.\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-2.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "labs/lab-2.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 2 - Data wrangling",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\nCreate a new variable called born_country_us in nobel_living_science that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\n\n\n\n\n\n\n\nNote\n\n\n\nYou should be able to cheat borrow from code you used earlier to create the country_us variable.\n\n\n\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Create two visualizations with this new variable added:\n\nPlot 1: Segmented frequency bar plot\nPlot 2: Segmented relative frequency bar plot (Hint: Add position = \"fill\" to geom_bar().)\n\nHere are some instructions that apply to both of these visualizations:\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be two bars for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\nWhich of these visualizations is a better fit for answering the following question: “Do the data appear to support Buzzfeed’s claim that of those US-based Nobel laureates, many were born in other countries?” First, state which plot you’re using to answer the question. Then, answer the question, explaining your reasoning in 1-2 sentences.\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n\n\n\nIn a single pipeline, filter the nobel_living_science data frame for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3 - Data tidying",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday, Sep 30 at 11:59pm."
  },
  {
    "objectID": "labs/lab-3.html#warm-up",
    "href": "labs/lab-3.html#warm-up",
    "title": "Lab 3 - Data tidying",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and render the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your `.qmd and .pdf files. If anything is missing, render, commit, and push again."
  },
  {
    "objectID": "labs/lab-3.html#packages",
    "href": "labs/lab-3.html#packages",
    "title": "Lab 3 - Data tidying",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and the scales package for better plot labels. These packages are already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "labs/lab-3.html#data",
    "href": "labs/lab-3.html#data",
    "title": "Lab 3 - Data tidying",
    "section": "Data",
    "text": "Data\nThe datasets that you will work with in this dataset come from the Organization for Economic Co-Operation and Development (OECD), stats.oecd.org."
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday, Sep 16 at 11:59pm ET."
  },
  {
    "objectID": "labs/lab-1.html#packages",
    "href": "labs/lab-1.html#packages",
    "title": "Lab 1 - Data visualization",
    "section": "Packages",
    "text": "Packages\nWe will use the tidyverse package to create and customize plots in R.\n\nlibrary(tidyverse)\nlibrary(viridis)"
  },
  {
    "objectID": "labs/lab-1.html#data-lets-take-a-trip-to-the-midwest",
    "href": "labs/lab-1.html#data-lets-take-a-trip-to-the-midwest",
    "title": "Lab 1 - Data visualization",
    "section": "Data: Let’s take a trip to the Midwest",
    "text": "Data: Let’s take a trip to the Midwest\nThe data in this lab is in the midwest data frame. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the console."
  },
  {
    "objectID": "labs/lab-project-proposal.html",
    "href": "labs/lab-project-proposal.html",
    "title": "Lab 3 - Project proposal",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday, Oct 21 at 11:59pm."
  },
  {
    "objectID": "labs/lab-project-proposal.html#why-teams-rationale",
    "href": "labs/lab-project-proposal.html#why-teams-rationale",
    "title": "Lab 3 - Project proposal",
    "section": "Why teams: Rationale",
    "text": "Why teams: Rationale\nIn the real world, data scientists and statisticians often work in research teams. It is a skill to be able to communicate and work together on common projects. Thus, the remaining labs + your project will be team based.\nTeams work better when members have a common understanding of the team’s goals and expectations for collaboration. The purpose of this activity is to help your team making a plan for working together during lab and outside of the scheduled lab time.\nEach team member will have some ideas about how a team should operate. These ideas may be very different. This is your opportunity to share your thoughts and ideas to promote optimal team function and prevent misunderstandings in the future."
  },
  {
    "objectID": "labs/lab-project-proposal.html#team-name",
    "href": "labs/lab-project-proposal.html#team-name",
    "title": "Lab 3 - Project proposal",
    "section": "Team name",
    "text": "Team name\nDiscuss with your group a team name to be called. Your GitHub repos will be created for this team name moving forward. Report your team name to your Lab Leader before moving on."
  },
  {
    "objectID": "labs/lab-project-proposal.html#team-agreement",
    "href": "labs/lab-project-proposal.html#team-agreement",
    "title": "Lab 3 - Project proposal",
    "section": "Team agreement",
    "text": "Team agreement\nDiscuss each of the items below with all team members.\nHave one person act as the recorder and type the team’s decisions in an email.\nBe sure the team agrees on an item before it is recorded.\nOnce the email is complete, the recorder should send it to all team members and cc the lab leader and the course professor (mc301@duke.edu). For the subject line use Team agreement - [TEAM NAME], and replace [TEAM NAME] with your, you guessed it, team name!\nAll team members can refer to this email throughout the semester.\n\nTeam name: The team name you chose, not the code name I gave your team.\nWeekly meetings: Identify a 1 - 2 hour weekly block outside of lab where the team can meet to work on assignments. All team members should block off this time on their calendar in case the group needs to meet to finish lab or work on the project.\nMeeting “location”: How the team will meet to work together (e.g. in-person, Zoom, Facetime, Google Hangouts). Be sure every member is able to access the virtual meeting space, if needed. If you are unable to find a weekly time when the team can meet, briefly outline a plan to work on assignments outside of lab. Otherwise, you can delete this item.\nPrimary method of communication: The team’s primary method of communication outside of meetings (e.g. Slack, text messages, etc.)\nHow should someone notify the other members if they are unable to attend lab or a scheduled team meeting?\nBy when should everyone have their portion of the lab completed Keep in mind your team may want to have time to review the lab before turning it in to make sure it is a cohesive write up.\nAny other items the team would like to discuss or plan."
  },
  {
    "objectID": "labs/lab-project-proposal.html#missing-teammates",
    "href": "labs/lab-project-proposal.html#missing-teammates",
    "title": "Lab 3 - Project proposal",
    "section": "Missing teammates",
    "text": "Missing teammates\nIf you are missing teammates for today’s lab, it is your responsibility to reach out, say hello, and communicate with them that they must contribute to the above and below tasks before the deadline. You can find their email in the teams repo."
  },
  {
    "objectID": "labs/lab-project-proposal.html#resolving",
    "href": "labs/lab-project-proposal.html#resolving",
    "title": "Lab 3 - Project proposal",
    "section": "Resolving",
    "text": "Resolving\nWorking in teams includes using a shared GitHub repo for labs and projects. Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts.\nWhen you and your teammates work on the lines of code within a document, and both try to push your changes, you will run into issues. Merge conflicts happen when you merge branches that have competing renders, and Git needs your help to decide which changes to incorporate in the final merge.\nOur first task today is to walk you through a merge conflict! First, a bit of Git review:\n\nPushing to a repo replaces the code on GitHub with the code you have on your computer.\nIf a collaborator has made a change to your repo on GitHub that you haven’t incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator’s work!\nSo you need to explicitly “merge” your collaborator’s work before you can push.\nIf your and your collaborator’s changes are in different files or in different parts of the same file, git merges the work for you automatically when you pull.\nIf you both changed the same part of a file, git will produce a merge conflict because it doesn’t know how which change you want to keep and which change you want to overwrite.\n\nGit will put conflict markers in your code that look like:\n<<<<<<< HEAD \n\nSee also: [dplyr documentation](https://dplyr.tidyverse.org/)   \n\n======= \n\nSee also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  \n\n>>>>>>> some1alpha2numeric3string4\nThe ===s separate your changes (top) from their changes (bottom).\nNote that on top you see the word HEAD, which indicates that these are your changes.\nAnd at the bottom you see some1alpha2numeric3string4 (well, it probably looks more like 28e7b2ceb39972085a0860892062810fb812a08f).\nThis is the hash (a unique identifier) of the render your collaborator made with the conflicting change.\nYour job is to reconcile the changes: edit the file so that it incorporates the best of both versions and delete the <<<, ===, and >>> lines. Then you can stage and render the result."
  },
  {
    "objectID": "labs/lab-project-proposal.html#merge-conflict-activity",
    "href": "labs/lab-project-proposal.html#merge-conflict-activity",
    "title": "Lab 3 - Project proposal",
    "section": "Merge conflict activity",
    "text": "Merge conflict activity\n\nSetup\n\nClone the project repo and open the about.qmd file.\nAssign the numbers 1, 2, 3, 4, and 5 to each of the team members. If your team has fewer than 5 people, some people will need to have multiple numbers.\n\n\n\nLet’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: Everyone should have the repo cloned and know which role number(s) they are.\nAlso, everyone should go to their Terminal and type git config pull.rebase false to set up their preferences for pulling.\nRole 1:\n\nGo to about.qmd in your project repo. Change the [team name] to your actual team name.\nRender, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange the team name to some other word.\nRender, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nChange the a name of the first team member.\nRender, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nChange the a name of the first team member to something other than what the previous team member did.\nRender, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Render, commit, and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 5:\n\nChange the a name of the rest of the team members and add descriptions for each person with the help of your team members. Role 5 should be the only one typing, the others should help verbally.\nRender and commit. Discuss as a team what you expect to happen when you hit push. Should there be a merge conflict error or not?\nIf there is a merge conflict, fix it. If not, push your changes.\n\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "labs/lab-project-proposal.html#tips-for-collaborating-via-github",
    "href": "labs/lab-project-proposal.html#tips-for-collaborating-via-github",
    "title": "Lab 3 - Project proposal",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "labs/lab-0.html",
    "href": "labs/lab-0.html",
    "title": "Lab 0 - Hello R!",
    "section": "",
    "text": "Important\n\n\n\nThis lab is not a part of your grade in this course. You should still submit your completed lab to Gradescope to practice submitting to Gradescope and receive feedback. Since this lab precedes class lecture, you may be unable to complete the lab until next week.\nThis lab will introduce you to the course computing workflow. The main goal is to demo R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\nAn additional goal is to reinforce Git and GitHub, the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nTo make versioning simpler, this and the next lab are solo labs. In the future, you’ll learn about collaborating on GitHub and producing a single lab report for your lab team, but for now, concentrate on getting the basics down.\nBy the end of the lab, you will…"
  },
  {
    "objectID": "labs/lab-0.html#log-in-to-rstudio",
    "href": "labs/lab-0.html#log-in-to-rstudio",
    "title": "Lab 0 - Hello R!",
    "section": "Log in to RStudio",
    "text": "Log in to RStudio\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you haven’t yet done so, you will need to reserve a container for STA198-199 first."
  },
  {
    "objectID": "labs/lab-0.html#set-up-your-ssh-key",
    "href": "labs/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0 - Hello R!",
    "section": "Set up your SSH key",
    "text": "Set up your SSH key\nYou will authenticate GitHub using SSH. Below are an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nType credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” You should click 1 for yes.\nYou will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you’re interested."
  },
  {
    "objectID": "labs/lab-0.html#configure-git",
    "href": "labs/lab-0.html#configure-git",
    "title": "Lab 0 - Hello R!",
    "section": "Configure Git",
    "text": "Configure Git\nThere is one more thing we need to do before getting started on the assignment. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package. (And we also need to install a package called gert just for this step.)\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\ndevtools::install_github(\"r-lib/gert\")\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\"\n  )\n\nFor example, mine would be\n\ndevtools::install_github(\"r-lib/gert\")\n\nusethis::use_git_config(\n  user.name = \"Alexander Fisher\", \n  user.email = \"alexander.fisher@duke.edu\"\n  )\n\nYou are now ready interact with GitHub via RStudio!"
  },
  {
    "objectID": "labs/lab-0.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-0.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 0 - Hello R!",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta199-sp23-1 organization on GitHub. Click on the repo with the prefix lab-0. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-0-datasaurus.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab."
  },
  {
    "objectID": "labs/lab-0.html#r-and-r-studio",
    "href": "labs/lab-0.html#r-and-r-studio",
    "title": "Lab 0 - Hello R!",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file."
  },
  {
    "objectID": "labs/lab-0.html#yaml",
    "href": "labs/lab-0.html#yaml",
    "title": "Lab 0 - Hello R!",
    "section": "YAML",
    "text": "YAML\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document."
  },
  {
    "objectID": "labs/lab-0.html#committing-changes",
    "href": "labs/lab-0.html#committing-changes",
    "title": "Lab 0 - Hello R!",
    "section": "Committing changes",
    "text": "Committing changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!"
  },
  {
    "objectID": "labs/lab-0.html#push-changes",
    "href": "labs/lab-0.html#push-changes",
    "title": "Lab 0 - Hello R!",
    "section": "Push changes",
    "text": "Push changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push."
  },
  {
    "objectID": "labs/lab-0.html#data-visualization-and-summary",
    "href": "labs/lab-0.html#data-visualization-and-summary",
    "title": "Lab 0 - Hello R!",
    "section": "Data visualization and summary",
    "text": "Data visualization and summary\n\nPlot y vs. x for the dino dataset. Then, calculate the correlation coefficient between x and y for this dataset.\n\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your document and successfully render it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data <- datasaurus_dozen |>\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |>, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: <-, assigns the name dino_data to the filtered data frame.\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as \\(r\\) in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate \\(r\\) only if relevant. In this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear (it’s dinosaurial)!\nFor illustrative purposes only, let’s calculate the correlation coefficient between x and y.\n\n\n\n\n\n\nNote\n\n\n\nStart with `dino_data` and calculate a summary statistic that we will call `r` as the `cor`relation between `x` and `y`.\n\n\n\ndino_data |>\n  summarize(r = cor(x, y))\n\n\nThis is a good place to pause, render, and commit changes with the commit message “Added answer for Ex 2.”\nThen, push these changes when you’re done.\n\n\nPlot y vs. x for the circle dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\n\nThis is another good place to pause, render, and commit changes with the commit message “Added answer for Ex 3.”\nThen, push these changes when you’re done.\n\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\n\nYou should pause again, render, commit changes with the commit message “Added answer for Ex 4”.\nThen, push.\n\nFinally, let’s plot all datasets at once. In order to do this we will make use of faceting, given by the code below:\n\n\n\n\n\n\nNote\n\n\n\nFacet by the dataset variable, placing the plots in a 3 column grid, and don’t add a legend.\n\n\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+\n  geom_point()+\n  facet_wrap(~ dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\nAnd we can use the group_by function to generate all the summary correlation coefficients. We’ll go through these functions next week when we learn about data wrangling.\n\ndatasaurus_dozen |>\n  group_by(dataset) |>\n  summarize(r = cor(x, y)) \n\n\nInclude the faceted plot and the summary of the correlation coefficients in your lab write-up by including relevant code in R chunks (and give them appropriate labels). In the narrative below the code chunks, briefly comment on what you notice about the plots and the correlations between x and y values within each of them (one or two sentences is fine!).\n\nYou’re done with the data analysis exercises, but we’d like to do one more thing to customize the look of the report."
  },
  {
    "objectID": "labs/lab-0.html#resize-your-figures",
    "href": "labs/lab-0.html#resize-your-figures",
    "title": "Lab 0 - Hello R!",
    "section": "Resize your figures",
    "text": "Resize your figures\nWe can customize the output from a particular R chunk by including options in the header that will override any global settings.\n\nIn the R chunks you wrote for Exercises 2-5, customize the settings by modifying the options in the R chunks used to create those figures.\n\nFor Exercises 2, 3, and 4, we want square figures. We can use fig.height and fig.width in the options to adjust the height and width of figures. Modify the chunks in Exercises 2-4 to be as follows:\n\n```{r}\n#| label: ex2-chunk-label\n#| fig-height: 5\n#| fig-width: 5\n\n# Your code that created the figure\n```\n\nFor Exercise 5, modify your figure to have fig-height of 10 and fig-width of 6.\nNow, save and render.\nOnce you’ve created this PDF file, you’re done!\n\nCommit all remaining changes with the commit message “Done with Lab 1!”.\nThen push."
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4 - Probability and Simpson’s Paradox",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday, October 28 at 11:59pm."
  },
  {
    "objectID": "labs/lab-4.html#exercise-1---probability-and-you",
    "href": "labs/lab-4.html#exercise-1---probability-and-you",
    "title": "Lab 4 - Probability and Simpson’s Paradox",
    "section": "Exercise 1 - Probability and you",
    "text": "Exercise 1 - Probability and you\nWe use probabilities all the time when making decisions. As a group, provide two real world examples of when you’ve used probability to make decisions in your every day life. Think critically. Be creative.\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-4.html#exercise-2---risk-of-coronary-heart-disease",
    "href": "labs/lab-4.html#exercise-2---risk-of-coronary-heart-disease",
    "title": "Lab 4 - Probability and Simpson’s Paradox",
    "section": "Exercise 2 - Risk of coronary heart disease",
    "text": "Exercise 2 - Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nLoad in the data set called education-disease and answer the following questions below.\nHow many levels of education are there in these data? How many levels of disease are there? Hint: The distinct() function might be helpful.\nConvert the data to a two-way table where each cell is the number of people falling into each combination of Disease and Education. Hint: Use count and pivot_wider. Your answer should be a 4x3 data frame with counts in each cell.\n\nUsing the summary table you created in part (c), answer the remaining questions. You do not have to use R functions for your calculations, you can use R as a calculator using the values from the summary table. Make sure to show your work, i.e., instead of reporting just the final answer, use R to calculate that in a way we can see the counts you’ve used along the way.\n\nWhat is the probability of a random individual being high risk for cardiovascular disease?\nWhat is the probability of a random individual having high school or GED education and not being high risk for cardiovascular disease?\nWhat is the probability that a random individual who is already high risk for cardiovascular disease has a college education?\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 2 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 3. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-4.html#exercise-3---computer-store",
    "href": "labs/lab-4.html#exercise-3---computer-store",
    "title": "Lab 4 - Probability and Simpson’s Paradox",
    "section": "Exercise 3 - Computer store",
    "text": "Exercise 3 - Computer store\nIn a computer store, 30% of the computers in stock are laptops and 70% are desktops. Five percent of the laptops are on sale, while 10% of the desktops are on sale.1\n\nFill in the code below to create a hypothetical two-way table to represent this situation. Assume the total number of computers is 1000.\n\n\ndata <- tibble( \n  type = c(),\n  sale = c(),\n  values = c()\n  )\n\ndata |>\n  pivot_wider( \n    names_from = ...,\n    values_from = ....\n  )\n\n\nCalculate the probability of that a randomly selected computer will be a desktop, given that the computer is on sale.\nIn your own words, explain what this probability means.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 3 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 4. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-4.html#exercise-4---bike-rentals",
    "href": "labs/lab-4.html#exercise-4---bike-rentals",
    "title": "Lab 4 - Probability and Simpson’s Paradox",
    "section": "Exercise 4 - Bike rentals",
    "text": "Exercise 4 - Bike rentals\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. You are tasked to investigate the relationship between the temperature outside and the number of bikes rented in the Washington DC area between the years 2011 and 2022. You will be investigating data for the months June, July, September, and November.2\nBelow is a list of variables and their definitions:\n\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\nseason\nNumerical representation of Spring (2), Summer (3), and Fall (4)\n\n\nyear\nNumerical representation of 2011 (0) or 2012 (1)\n\n\nmonth\nMonth in which data were collected\n\n\nholiday\nIndicator variable for whether data were collected on a holiday (1) or not (0)\n\n\nweekday\nNumerical representation of day of week\n\n\ntemp\nTemperature in Celsius\n\n\ncount\nNumber of bike rentals for that day\n\n\n\n\nRead in the data. Then, create a scatter plot that investigates the relationship between the number of bikes rented and the temperature outside. Include a straight line of best fit to help discuss the discovered relationship. Summarize your findings in 2-3 sentences.\nAnother researcher suggests to look at the relationship between bikes rented and temperature by each of the four months of interest. Recreate your plot in part a, and color the points by month. Include a straight line for each of the four months to help discuss each month’s relationship between bikes rented and temperature. In 3-4 sentences, summarize your findings.\n\nPlease watch the following video on Simpson’s Paradox here. After you do, please answer the following questions.\n\nIn your own words, summarize Simpson’s Paradox in 2-3 sentences.\nCompare and contrast your findings from part (a) and part (b). What’s different?\nThink critically about your answer to part d. What other context from this study could be creating this paradox? That is, identify a potential confounding variable in this study. Be sure to justify how your example could be a potential confounding variable by relating it back to both bike rentals and temperature.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 4 renders, commits, and pushes, all other team members should pull the changes and render the document. Finally, a team member different than the one responsible for typing up responses to Exercise 4 should do the last task outlined below."
  },
  {
    "objectID": "labs/lab-4.html#closing-an-issue-with-a-commit",
    "href": "labs/lab-4.html#closing-an-issue-with-a-commit",
    "title": "Lab 4 - Probability and Simpson’s Paradox",
    "section": "Closing an issue with a commit",
    "text": "Closing an issue with a commit\nGo to your GitHub repository, you will see an issue with the title “Learn to close an issue with a commit”. Your goal is to close this issue with a commit to practice this workflow, which is the workflow you will use when you are addressing feedback on your projects.\n\nGo to the relevant section in your lab .qmd file.\nDelete the sentence that says “Delete me”.\nRender the document.\nCommit your changes from the git tab with the commit message “Delete sentence, closes #1.”\nPush your changes to your repo and observe that the issue is now closed and the commit associated with this move is linked from the issue.\n\nGitHub allows you to close an issue directly with commits if the commit uses one of the following keywords followed bu the issue number (which you can find next to the issue title): close, closes, closed, fix, fixes, fixed, resolve, resolves, and resolved."
  },
  {
    "objectID": "labs/lab-5.html",
    "href": "labs/lab-5.html",
    "title": "Lab 5 - Predicting a numerical outcome",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday, November 4 at 11:59pm."
  },
  {
    "objectID": "labs/lab-5.html#intro",
    "href": "labs/lab-5.html#intro",
    "title": "Lab 5 - Predicting a numerical outcome",
    "section": "Intro",
    "text": "Intro\nParasites can cause infectious disease – but not all animals are affected by the same parasites. Some parasites are present in a multitude of species and others are confined to a single host. It is hypothesized that closely related hosts are more likely to share the same parasites. More specifically, it is thought that closely related hosts will live in similar environments and have similar genetic makeup that coincides with optimal conditions for the same parasite to flourish.\nIn this lab we will see how much evolutionary history predicts parasite similarity."
  },
  {
    "objectID": "labs/lab-5.html#the-data",
    "href": "labs/lab-5.html#the-data",
    "title": "Lab 5 - Predicting a numerical outcome",
    "section": "The Data",
    "text": "The Data\nToday’s dataset comes from an Ecology Letters paper by Cooper at al. (2012) entitled “Phylogenetic host specificity and understanding parasite sharing in primates” located here. The goal of the paper was to identify the ability of evolutionary history and ecological traits to characterize parasite host specificity.\nEach row of the data contains two species, species1 and species2.\nSubsequent columns describe metrics that compare the species:\n\ndivergence_time: how many (millions) of years ago the two species diverged. i.e. how many million years ago they were the same species.\ndistance: geodesic distance between species geographic range centroids (in kilometers)\nBMdiff: difference in body mass between the two species (in grams)\nprecdiff: difference in mean annual precipitation across the two species geographic ranges (mm)\nparsim: a measure of parasite similarity (proportion of parasites shared between species, ranges from 0 to 1.)\n\nThe data are available in parasites.csv in the data folder."
  },
  {
    "objectID": "labs/lab-5.html#packages",
    "href": "labs/lab-5.html#packages",
    "title": "Lab 5 - Predicting a numerical outcome",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization.\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "labs/lab-5.html#exercises",
    "href": "labs/lab-5.html#exercises",
    "title": "Lab 5 - Predicting a numerical outcome",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 1. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\nTo get started, load the data and save the data frame as parasites.\n\nLet’s start by examining the relationship between divergence_time and parsim.\n\nBased on the goals of the analysis, what is the response variable?\nVisualize the relationship between the two variables.\nUse the visualization to describe the relationship between the two variables.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nNext, we’ll model this relationship.\n\nFit the model and write the estimated regression equation.\nInterpret the slope and the intercept in the context of the data.\nRecreate the visualization from Exercise 1, this time adding a regression line to the visualization.\nWhat do you notice about the prediction (regression) line that may be strange, particularly for very large divergence times?\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 2 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 3. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nSince parsim takes values between 0 and 1, we want to transform this variable so that it can range between (−∞,+∞). This will be better suited for fitting a regression model (and interpreting predicted values!)\n\nUsing mutate, create a new variable transformed_parsim that is calculated as log(parsim/(1-parsim)). Add this variable to your data frame. Note: log() in R represents taking the nautral log.\nThen, visualize the relationship between divergence_time and transformed_parsim. Add a regression line to your visualization.\nWrite a 1-2 sentence description of what you observe in the visualization.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 3 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 4. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nWhich variable is the strongest individual predictor of parasite similarity between species? To answer this question, begin by fitting a linear regression model to each pair of variables. Do not report the model outputs in a tidy format but save each one as dt_model, dist_model, BM_model, and prec_model, respectively.\n\ndivergence_time and transformed_parsim\ndistance and transformed_parsim\nBMdiff and transformed_parsim\nprecdiff and transformed_parsim\n\n\nReport the slops for each of these models. Use proper notation.\nTo answer the question of interest, would it be useful to compare the slopes in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 4 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 5. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nNow, what if calculated \\(R^2\\) to help answer our question? To compare the explanatory power of each individual predictor, we will look at \\(R^2\\) between the models. \\(R^2\\) is a measure of how much of the variability in the response variable is explained by the model.\nAs you may have guessed from the name \\(R^2\\) can be calculated by squaring the correlation when we have a simple linear regression model. The correlation r takes values -1 to 1, therefore, \\(R^2\\) takes values 0 to 1. Intuitively, if r=1 or −1, then \\(R^2\\)=1, indicating the model is a perfect fit for the data. If r≈0 then \\(R^2\\)≈0, indicating the model is a very bad fit for the data.\nYou can calculate \\(R^2\\) using the glance function. For example, you can calculate \\(R^2\\) for dt_model using the code glance(dt_model)$r.squared.\n\nCalculate and report \\(R^2\\) for each model fit in the previous exercise.\nTo answer our question of interest, would it be useful to compare the \\(R^2\\) in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 5 renders, commits, and pushes, all other team members should pull the changes and render the document. Finally, a team member different than the one responsible for typing up responses to Exercise 5 should do the last task outlined below."
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6 - Prediction and bootstrapping",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Friday 18th at 11:59pm."
  },
  {
    "objectID": "labs/lab-6.html#exercise-1",
    "href": "labs/lab-6.html#exercise-1",
    "title": "Lab 6 - Prediction and bootstrapping",
    "section": "Exercise 1",
    "text": "Exercise 1\n\n\n\n\n\n\nImportant\n\n\n\nPick a member of the team write the answer to Exercise 1. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame. Sample code is provided below.\n\n\ngss16_advfront <- gss16 %>%\n  select(___, ___, ___, ___) %>%\n  drop_na()\n\n\nRe-level the advfront variable such that it has two levels: Strongly agree and “Agree\" combined into a new level called Agree and the remaining levels combined into”Not agree\". Then, re-order the levels in the following order: \"Agree\" and \"Not agree\". Finally, count() how many times each new level appears in the advfront variable.\n\nHint: You can do this in various ways. One option is to use the str_detect() function to detect the existence of words. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the str_detect() function, you can use [Aa]gree. However, solve the problem however you like, this is just one option!\n\nCombine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word conservative in them are lumped into a level called \"Conservative\". Then, re-order the levels in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-6.html#exercise-2",
    "href": "labs/lab-6.html#exercise-2",
    "title": "Lab 6 - Prediction and bootstrapping",
    "section": "Exercise 2",
    "text": "Exercise 2\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nSpecify a logistic regression model using “glm” as the engine, that predicts advfront by educ. Name this specification gss16_spec. Report the tidy output below.\nWrite out the estimated model in proper notation.\nUsing your estimated model, predict the probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 2 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-6.html#exercise-3",
    "href": "labs/lab-6.html#exercise-3",
    "title": "Lab 6 - Prediction and bootstrapping",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 3. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nFit a new model that adds the additional explanatory variable of polviews. Report the tidy output below.\nNow, predict the probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years and are Conservative.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 3 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-6.html#exercise-4",
    "href": "labs/lab-6.html#exercise-4",
    "title": "Lab 6 - Prediction and bootstrapping",
    "section": "Exercise 4",
    "text": "Exercise 4\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 4. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\nAnswers to this question are stored in the harass5 variable in our data set.\n\nCreate a subset of the data that only contains Yes and No answers for the harassment question. How many responses chose each of these answers?\nDescribe how bootstrapping can be used to estimate the proportion of all Americans who have been harassed by their superiors or co-workers at their job.\nCalculate a 95% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Use 1000 iterations when creating your bootstrap distribution. Interpret this interval in context of the data.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 4 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "labs/lab-6.html#exercise-5",
    "href": "labs/lab-6.html#exercise-5",
    "title": "Lab 6 - Prediction and bootstrapping",
    "section": "Exercise 5",
    "text": "Exercise 5\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 5. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nWhere was your 95% confidence interval centered? Why does this make sense?\nNow, calculate 90% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Report the interval below. Is it wider or more narrow than the 95% confidence interval?\nNow, suppose you created a bootstrap distribution with 50,000 simulations instead of 1,000. What would you expect to change (if anything)?\n\n\nCenter of the CI\nWidth of the CI\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 5 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 on Duke Container Manager\n\n\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nGradescope\n🔗 on Sakai\n\n\nOffice hours\n🔗 on Google docs\n\n\nTexbooks\n🔗 R for Data Science\n🔗 Introduction to Modern Statistics\n\n\nPackage documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org\n🔗 readxl: readxl.tidyverse.org"
  },
  {
    "objectID": "hw/hw-5.html",
    "href": "hw/hw-5.html",
    "title": "HW 5 - Regression + other stories",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Thursday, Nov 10 at 11:59pm ET.\nHomework assignments are individual, not team based."
  },
  {
    "objectID": "hw/hw-5.html#workflow-formatting",
    "href": "hw/hw-5.html#workflow-formatting",
    "title": "HW 5 - Regression + other stories",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse style guide.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-5.html#packages",
    "href": "hw/hw-5.html#packages",
    "title": "HW 5 - Regression + other stories",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse for much of the data wrangling and visualization and tidymodels for modeling. In addition, we’ll use the palmerpenguins and gapminder for data.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nlibrary(gapminder)"
  },
  {
    "objectID": "hw/hw-5.html#exercise-1---a-work-of-art",
    "href": "hw/hw-5.html#exercise-1---a-work-of-art",
    "title": "HW 5 - Regression + other stories",
    "section": "Exercise 1 - A work of aRt",
    "text": "Exercise 1 - A work of aRt\nYour task is to make the following plot as ugly and as ineffective as possible. Change colors, axes, fonts, theme, or anything else you can think of in the code chunk below. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!\nIn 2-3 sentences, explain why the plot you created is ugly (to you, at least) and ineffective.\n\nggplot(\n  penguins, \n  aes(x = flipper_length_mm, y = bill_length_mm, color = species)\n  ) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "hw/hw-5.html#exercise-2---gdp-vs.-life-expectancy",
    "href": "hw/hw-5.html#exercise-2---gdp-vs.-life-expectancy",
    "title": "HW 5 - Regression + other stories",
    "section": "Exercise 2 - GDP vs. life expectancy",
    "text": "Exercise 2 - GDP vs. life expectancy\nGapminder is a “fact tank” that uses publicly available world data to produce data visualizations and teaching resources on global development. We will use an excerpt of their data to explore relationships among world health metrics across countries and regions between the years 1952 and 2007. The data set is called gapminder, from the gapminder package. A table of variables can be found below.\n\ncountry: The country name\ncontinent: The continent name\nyear: ranges from 1952 to 2007 in increments of 5 years\nlifeExp: life expectancy at birth, in years\npop: population of country\ngdpPercap: GDP per capita (US$, inflation-adjusted)\n\n\nData: For our analysis, we will only be working with data from 2007. Below, filter the data set so only values from the year 2007 are shown. Save this data set as gapminder_07 and use it for the remainder of this exercise and the following.\nVisualization: We are interested in learning more about GDP, and we’ll start with exploring the relationship between life expectancy and GDP. Create two visualizations:\n\nScatter plot of gdpPercap vs. lifeExp.\nScatter plot of gdpPercap_log vs. lifeExp, where gdpPercap_log is a new variable you add to the data set by taking the natural log of gdpPercap.\n\nFirst describe the relationship between each pair of the variables. Then, comment on which relationship would be better modeled using a linear model, and explain your reasoning.\nModel fitting and interpretation:\n\nFit a linear model predicting log gross domestic product from life expectancy. Display the tidy summary.\nInterpret the intercept of the model, making sure that your interpretation is in the units of the original data (not on log scale).\nInterpret the slope of the model, making sure that your interpretation is in the units of the original data (not on log scale).\n\nModel evaluation:\n\nCalculate the R-squared of the model using two methods and confirm that the values match: first method is using glance() and the other method is based on the value of the correlation coefficient between the two variables.\nInterpret R-squared in the context of the data and the research question."
  },
  {
    "objectID": "hw/hw-5.html#exercise-3---gdp-vs.-life-expectancy-continent",
    "href": "hw/hw-5.html#exercise-3---gdp-vs.-life-expectancy-continent",
    "title": "HW 5 - Regression + other stories",
    "section": "Exercise 3 - GDP vs. life expectancy + continent",
    "text": "Exercise 3 - GDP vs. life expectancy + continent\nNext, we want to examine if the relationship between GDP and life expectancy that we observed in the previous exercise holds across all continents in our data. We’ll continue to work with logged GDP (gdpPercap_log) and data from 2007.\n\nJustification: Create a scatter plot of gdpPercap_log vs. lifeExp, where the points are colored by continent. Do you think the trend between gdpPercap_log and lifeExp is different for different continents? Justify your answer with specific features of the plot.\nModel fitting and interpretation:\n\nRegardless of your answer in part (a), fit an additive model (main effects) that predicts gdpPercap_log from life expectancy and continent (with Americas as the baseline level). Display a tidy summary of the model output.\nInterpret the intercept of the model, making sure that your interpretation is in the units of the original data (not on log scale).\nInterpret the slope of the model, making sure that your interpretation is in the units of the original data (not on log scale).\n\nPrediction: Predict the GDP of a country in Asia where the average life expectancy is 70 years old."
  },
  {
    "objectID": "hw/hw-5.html#exercise-4---gdp-vs.-life-expectancy-x-continent",
    "href": "hw/hw-5.html#exercise-4---gdp-vs.-life-expectancy-x-continent",
    "title": "HW 5 - Regression + other stories",
    "section": "Exercise 4 - GDP vs. life expectancy x continent",
    "text": "Exercise 4 - GDP vs. life expectancy x continent\nFinally, we want to examine if the relationship between GDP and life expectancy that we observed in the previous exercise holds across all continents in our data again, this time allowing for different relationships between GDP and life expectancy across continents.. We’ll continue to work with logged GDP (gdpPercap_log) and data from 2007.\n\nModel fitting and interpretation: Fit an interaction model that predicts gdpPercap_log from life expectancy and continent (with Americas as the baseline level). Display a tidy summary of the model output and in 2-3 sentences, explain how this model differs from the additive model.\nEstimated model: Write out the estimated model using proper notation.\nPrediction: Predict the GDP of a country in Asia where the average life expectancy is 70 years old. Is this prediction different from your prediction with the additive model from Exercise 3?\nModel evaluation: Would the R-squared value for this model in exercise 4 be larger or smaller than the R-squared value for the model in exercise 3. Without running any code, please write out and justify your answer."
  },
  {
    "objectID": "hw/hw-5.html#exercise-5---hotel-cancellations",
    "href": "hw/hw-5.html#exercise-5---hotel-cancellations",
    "title": "HW 5 - Regression + other stories",
    "section": "Exercise 5 - Hotel cancellations",
    "text": "Exercise 5 - Hotel cancellations\nFor this exercise, we will explore hotel cancellations. The data describe the demand of two different types of hotels. Each observation represents a hotel booking between July 1, 2015 and August 31, 2017. Some bookings were cancelled (is_canceled = 1) and others were kept, i.e., the guests checked into the hotel (is_canceled = 0). You can view the code book for all variables here.\nThe data can be found in the data folder: hotels.csv. Using these data, we will try to answer the following question:\n\nDo we expect reservations earlier in the month or later in the month to be cancelled?\n\n\nExploration: In a single pipeline, calculate the mean arrival date (arrival_date_day_of_month) for both booking that were cancelled and that were not cancelled.\nJustification: In your own words, explain why we can not fit a linear model to model the relationship between if a hotel reservation was cancelled and the day of month for the booking.\nModel fitting and interpretation:\n\nFit the appropriate model and display a tidy summary of the model output.\nInterpret the slope coefficient in context of the data and the research question.\n\nEstimated model: Write out the estimated model using proper notation.\nPredicted: Calculate the probability that the hotel reservation is cancelled if it the arrival date date is on the 26th of the month. Based on this probability, would you predict this booking would be cancelled or not cancelled. Explain your reasoning for your classification."
  },
  {
    "objectID": "hw/hw-5.html#exercise-6---communicating-statistics",
    "href": "hw/hw-5.html#exercise-6---communicating-statistics",
    "title": "HW 5 - Regression + other stories",
    "section": "Exercise 6 - Communicating statistics",
    "text": "Exercise 6 - Communicating statistics\nCommunication is a critical yet often overlooked part of data science. When we engage with our audience and capture their interest, we can ultimately better communicate what we are trying to share.\nPlease watch the following video: Hans Rosling: 200 years in 4 minutes.\nThen, write a paragraph (4-5 sentences) addressing the following:\n\nWhat did you enjoy about the presentation of data? What did you find interesting\nWere there any aspects of the presentation that were hard to follow? If so, what?\nWhat are your general take-aways from this presentation?\nWhat are your general take-aways from how this presentation was given?"
  },
  {
    "objectID": "hw/hw-5.html#submission",
    "href": "hw/hw-5.html#submission",
    "title": "HW 5 - Regression + other stories",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-5.html#grading",
    "href": "hw/hw-5.html#grading",
    "title": "HW 5 - Regression + other stories",
    "section": "Grading",
    "text": "Grading\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1\nTBD\n\n\nEx 2\nTBD\n\n\nEx 3\nTBD\n\n\nEx 4\nTBD\n\n\nEx 5\nTBD\n\n\nEx 6\nTBD\n\n\nWorkflow & formatting\n5\n\n\nTotal\n50\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” component assesses the reproducible workflow. This includes:\n\nAt least three commits\nLinking HW pages on Gradescope\nFollowing tidyverse code style\nAll code being visible in rendered PDF (no more than 80 characters)\nAppropriate figure sizing, and figures with informative labels and legends"
  },
  {
    "objectID": "hw/hw-4.html",
    "href": "hw/hw-4.html",
    "title": "HW 4 - Scraping + modelling",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Thursday, Nov 3 at 11:59pm ET.\nHomework assignments are individual, not team based."
  },
  {
    "objectID": "hw/hw-4.html#workflow-formatting",
    "href": "hw/hw-4.html#workflow-formatting",
    "title": "HW 4 - Scraping + modelling",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse style guide.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-4.html#packages",
    "href": "hw/hw-4.html#packages",
    "title": "HW 4 - Scraping + modelling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, though you’re welcomed to also load other packages as needed.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rvest)\nlibrary(robotstxt)\nlibrary(openintro)"
  },
  {
    "objectID": "hw/hw-4.html#exercise-1---data-scraping",
    "href": "hw/hw-4.html#exercise-1---data-scraping",
    "title": "HW 4 - Scraping + modelling",
    "section": "Exercise 1 - Data Scraping",
    "text": "Exercise 1 - Data Scraping\nPlease justify, using the tools we’ve learning in this course, if you are allowed to scrape data from each of the following websites:\n\nwww.espn.com\ntwitter.com\nwww.rottentomatoes.com"
  },
  {
    "objectID": "hw/hw-4.html#exercise-2---rotten-tomatoes",
    "href": "hw/hw-4.html#exercise-2---rotten-tomatoes",
    "title": "HW 4 - Scraping + modelling",
    "section": "Exercise 2 - Rotten Tomatoes",
    "text": "Exercise 2 - Rotten Tomatoes\nRotten Tomatoes is an American review aggregation website for film. They give percentage scores for movies based on how “good” the movies are. They provide 2 scores:\n\n\n\n\n\n\n\n\nThe audience score, denoted by a popcorn bucket\n\n\n\nThe Tomatometer score represents the percentage of professional critic reviews that are positive for a given film\n\n\n\nWe are going to investigate the relationship between the audience score and Tomatometer score between the Halloween movies. Please visit the following website to view the data we plan to scrape: https://www.rottentomatoes.com/franchise/halloween\n\nUsing Selector Gadget, scrape the tomato_score and audience_score and report the lengths of these vectors (using the length()) function. Hint: Their lengths should be equal.\nNext, run the following code:\n\n\ntitles_years <- page |>\n  html_nodes(\".franchise-media-list__h3\") |>\n  html_text2()\n  \nhalloween <- tibble(title_year = titles_years) |>\n  separate(title_year, into = c(\"title\", \"year\"), sep= \"\\\\(\" )\n\nIn 2-3 sentences, describe what the above code is doing. Make sure to articulate each step of both of the pipelines. Hint: Print out titles_years and halloween to see what these objects look like. This will help figure out what the code is doing. You should also try running each line of the pipeline individually to see their outputs.\n\nAdd the columns tomato_score and audience_score from part (a) to your data frame called halloween that you created in part (b).\nCreate an appropriate plot the assess the relationship between a movie’s audience score and their tomatometer score. In 2-3 sentences, comment on the relationship. Your plot should include appropriate labels."
  },
  {
    "objectID": "hw/hw-4.html#exercise-3---smoking-during-pregnancy---part-1",
    "href": "hw/hw-4.html#exercise-3---smoking-during-pregnancy---part-1",
    "title": "HW 4 - Scraping + modelling",
    "section": "Exercise 3 - Smoking during pregnancy - Part 1",
    "text": "Exercise 3 - Smoking during pregnancy - Part 1\nWe are interested in the impact of smoking during pregnancy. Since it is not possible to run a randomized controlled experiment to investigate this impact, we will instead use a data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. This is a random sample of 1,000 cases from a data set released in 2014 by the state of North Carolina. The data set is called births14, and it is included in the openintro package you loaded at the beginning of the assignment.\n\nCreate a version of the births14 data set dropping observations where there are NAs for habit. You can call this version births14_habitgiven.\nPlotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions. Create an appropriate plot displaying the relationship between weight and habit. In 2-3 sentences, discuss the relationships observed.\nNow, fit a linear model that investigates the relationship between weight and habit. Provide the tidy summary output below.\nWrite the estimated least squares regression line below using proper notation. Hint: If you need to type an equation using proper notation, type your answers in-between $$ and $$. You may use \\hat{example} to put a hat on a character."
  },
  {
    "objectID": "hw/hw-4.html#exercise-4---smoking-during-pregnacy---part-2",
    "href": "hw/hw-4.html#exercise-4---smoking-during-pregnacy---part-2",
    "title": "HW 4 - Scraping + modelling",
    "section": "Exercise 4 - Smoking during pregnacy - Part 2",
    "text": "Exercise 4 - Smoking during pregnacy - Part 2\n\nAnother researcher is interested in assessing the relationship between babies’ weights and mothers’ ages. Fit another linear model to investigate this relationship. Provide the summary output below.\nIn 2-3 sentences, explain how the regression line to model these data is fit, i.e., based on what criteria R determines the regression line.\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question."
  },
  {
    "objectID": "hw/hw-4.html#exercise-5---americas-neighborhood-pollster",
    "href": "hw/hw-4.html#exercise-5---americas-neighborhood-pollster",
    "title": "HW 4 - Scraping + modelling",
    "section": "Exercise 5 - America’s Neighborhood Pollster",
    "text": "Exercise 5 - America’s Neighborhood Pollster\nSurveyUSA interviewed 886 North Carolina adults between Septermber 28, 2022 and October 2, 2022. This research was conducted online among a representative cross section of North Carolina adults, selected at random by Lucid Holdings LLC of New Orleans. We will look at the results from the following question:\n\nAre you optimistic or pessimistic about the economic outlook for your family over the next year?\n\nResponses were broken down into the following categories:\n\n\n\nVariable\nLevels\n\n\n\n\nAge\n18-49; 50+\n\n\nMood\nOptimistic; Pessimistic\n\n\n\n\nOf the 886 responses, 481 were between the ages of 18-49. Of the individuals that are between 18-49, 237 individuals responded that they were pessimistic. Of the individuals that are 50+, 164 claimed to be optimistic. Fill in the code below to create a hypothetical two-way table to represent this situation.\n\n\ndata <- tibble( \n  age = c(),\n  mood = c(),\n  values = ()\n  )\n\ndata |>\n  pivot_wider( \n    names_from = ...,\n    values_from = ...\n  )\n\n\nUsing your table from part (a), calculate the probability that a randomly selected individual is 50+ and is pessimistic.\nUsing your table from part (a), calculate the probability that a randomly selected individual is optimistic.\nUsing your table from part (a), calculate the probability that a randomly selected 18-49 aged individual is optimistic.\nCreate an appropriate visualization to compare the the relationship between age and mood. Your plot should include appropriate labels. Hint: You may have to re manipulate the data into a more usable form."
  },
  {
    "objectID": "hw/hw-4.html#exercise-6---functionalizing-halloween",
    "href": "hw/hw-4.html#exercise-6---functionalizing-halloween",
    "title": "HW 4 - Scraping + modelling",
    "section": "Exercise 6 - Functionalizing Halloween",
    "text": "Exercise 6 - Functionalizing Halloween\nSuppose you have two types of candy to give out on Halloween; Hershey’s bars and Starbursts. The probability that you give a random trick-or-treater who knocks on your door a Hershey’s bar is 0.5. With this information, create a function that chooses for you which type of candy you will give a trick-or-treater that knocks on your door. Your function should take a numerical value as an input and should give the numbers of Hershey’s bars and Starbursts in a 2x2 tibble with columns candy and n as an output.\nFor example, if you want to select candies for 3 trick or treaters, it might look something like this:\n\ntrick_or_treat(3)\n\nAnd the result might look something like this:\n\n# A tibble: 2 × 2\n  candy             n\n  <chr>         <int>\n1 Hershey's bar     2\n2 Starburst         1\n\nYour function should be able to display a table of counts for Hershey’s bars or Starbursts for any amount of people you expect to see on Halloween.\nWrite this function and test it with 15, 100, and 200 as inputs. You will note that every time you render your document the results will change. This is expected as you’re randomly sampling. (And later on in the course we’ll talk about how to make these numbers not change every time you render, for reproducibility!)\nTo create and test your function, please fill in the ___ below.\nHint: Think about what varies in your function as you define your input.\n\ntrick_or_treat <- function(___){ # input\n  candy_types <- c(\"___\", \"___\") # types of candy\n  tibble(candy = sample(___, size = ___, replace = ___)) |>\n    ___(___)\n}\n\ntrick_or_treat(___)\n\ntrick_or_treat(___)\n\ntrick_or_treat(___)"
  },
  {
    "objectID": "hw/hw-4.html#submission",
    "href": "hw/hw-4.html#submission",
    "title": "HW 4 - Scraping + modelling",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-4.html#grading",
    "href": "hw/hw-4.html#grading",
    "title": "HW 4 - Scraping + modelling",
    "section": "Grading",
    "text": "Grading\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1\n6\n\n\nEx 2\n9\n\n\nEx 3\n8\n\n\nEx 4\n8\n\n\nEx 5\n9\n\n\nEx 6\n5\n\n\nWorkflow & formatting\n5\n\n\nTotal\n50\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” component assesses the reproducible workflow. This includes:\n\nAt least three commits\nLinking HW pages on Gradescope\nFollowing tidyverse code style\nAll code being visible in rendered PDF (no more than 80 characters)\nAppropriate figure sizing, and figures with informative labels and legends"
  },
  {
    "objectID": "hw/hw-6.html",
    "href": "hw/hw-6.html",
    "title": "HW 6 - Statistics experience",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Friday, Dec 9 at 11:59pm ET.\nHomework assignments are individual, not team based.\nThere is no GitHub repo for this assignment, see below for slide format.\nThe world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience\n2️⃣ Make a slide summarizing on your experience\nYou must complete both parts to receive credit."
  },
  {
    "objectID": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "HW 6 - Statistics experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nrstudio::conf 2022 talks\nrstudio::global 2021 talks\nrstudio::conf 2020 talks\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask your professor to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nHow Charts Lie by Alberto Cairo\nList of books about data science ethics\n\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: Coding out loud\nWatch an episode of Coding out loud (either live or pre-recorded) and work through the project.\nA few guidelines:\n✅ Create a GitHub repo for your Coding out loud submission. Your repo should include\n\nThe Quarto file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The final product (visualization, table, etc.) should include features or customization that are beyond what was achieved in the Coding out loud episode.\n✅ Include the link to your GitHub repo in the slide summarizing your experience."
  },
  {
    "objectID": "hw/hw-6.html#part-2-summarize-your-experience",
    "href": "hw/hw-6.html#part-2-summarize-your-experience",
    "title": "HW 6 - Statistics experience",
    "section": "Part 2: Summarize your experience",
    "text": "Part 2: Summarize your experience\nMake one slide summarizing your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something we’ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e. use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "hw/hw-6.html#submission",
    "href": "hw/hw-6.html#submission",
    "title": "HW 6 - Statistics experience",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-6.html#grading",
    "href": "hw/hw-6.html#grading",
    "title": "HW 6 - Statistics experience",
    "section": "Grading",
    "text": "Grading\nThis assignment will be graded out of 50 points, based on the quality and depth of your writing."
  },
  {
    "objectID": "hw/hw-3.html",
    "href": "hw/hw-3.html",
    "title": "HW 3 - Ethics + recap",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Thursday, Oct 13 at 11:59pm ET."
  },
  {
    "objectID": "hw/hw-3.html#workflow-formatting",
    "href": "hw/hw-3.html#workflow-formatting",
    "title": "HW 3 - Ethics + recap",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse style guide.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-3.html#packages",
    "href": "hw/hw-3.html#packages",
    "title": "HW 3 - Ethics + recap",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, though you’re welcomed to also load other packages as needed.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "hw/hw-3.html#exercise-1",
    "href": "hw/hw-3.html#exercise-1",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 1",
    "text": "Exercise 1\nAll about Quarto:\n\nFor each of the character strings below, determine if the string is an proper code chunk label to use in a document when rendering to PDF. If not, explain why. You’re welcomed to try them out to check.\n\nChunk 1:\n\n\n#| label: label with spaces\n\nChunk 2:\n\n\n#| label: reaaaaaaaaaalllllllllyyyyy-long-label \n#|        with-line-breaks\n\nChunk 3:\n\n\n#| label: 1-label-starting-with-number\n\nChunk 4:\n\n\n#| label: label-with-dashes\nWhat values does each of the following chunk options take and what do they do?\n\neval\nerror\nwarning\necho\n\nWhat do the chunk options fig-height and fig-width do – what do they do when they’re set in a single code chunk and what do they do when they’re set in the document YAML on top?"
  },
  {
    "objectID": "hw/hw-3.html#exercise-2",
    "href": "hw/hw-3.html#exercise-2",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 2",
    "text": "Exercise 2\nAll about group_by():\nSuppose we have the following tiny data frame:\n\ndf <- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\ndf\n\n# A tibble: 5 × 3\n      x y     z    \n  <int> <chr> <chr>\n1     1 a     K    \n2     2 b     K    \n3     3 a     L    \n4     4 a     L    \n5     5 b     K    \n\n\na. What does the following code chunk do? Run it and analyze the result and articulate in words what group_by() does.\n\ndf |>\n  group_by(y)\n\nb. What does the following code chunk do? Run it and analyze the result and articulate in words what arrange() does. Also comment on how it’s different from the group_by() in part (a)?\n\ndf |>\n  arrange(y)\n\nc. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does.\n\ndf |>\n  group_by(y) |>\n  summarize(mean_x = mean(x))\n\nd. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. Then, comment on what the message says.\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x))\n\ne. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. How is the output different from the one in part (d).\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\nf. What do the following pipelines do? Run both and analyze their results and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x))\n\ndf |>\n  group_by(y, z) |>\n  mutate(mean_x = mean(x))\n\n\n\nRender, commit (with a descriptive and concise commit message), and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-3.html#exercise-3",
    "href": "hw/hw-3.html#exercise-3",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe following chart was shared by @GraphCrimes on Twitter on September 3, 2022.\n\n\n\n\n\n\nWhat is misleading about this graph?\nSuppose you wanted to recreate this plot, with improvements to avoid its misleading pitfalls from part (a). You would obviously need the data from the survey in order to be able to do that. How many observations would this data have? How many variables (at least) should it have, and what should those variables be?\nLoad the data for this survey from data/survation.csv. Confirm that the data match the percentages from the visualization. That is, calculate the percentages of public sector, private sector, don’t know for each of the services and check that they match the percentages from the plot.\nRecreate the visualization, and improve it. You only need to submit the improved version, not a recreation of the misleading graph exactly. Does the improved visualization look different than the original? Does it send a different message at a first glance?"
  },
  {
    "objectID": "hw/hw-3.html#exercise-4",
    "href": "hw/hw-3.html#exercise-4",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 4",
    "text": "Exercise 4\nA data scientist compiled data from several public sources (voter registration, political contributions, tax records) that were used to predict sexual orientation of individuals in a community. What ethical considerations arise that should guide use of such data sets?1\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-3.html#exercise-5",
    "href": "hw/hw-3.html#exercise-5",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 5",
    "text": "Exercise 5\nA data analyst received permission to post a data set that was scraped from a social media site. The full data set included name, screen name, email address, geographic location, IP (internet protocol) address, demographic profiles, and preferences for relationships. Why might it be problematic to post a deidentified form of this data set where name and email address were removed?2"
  },
  {
    "objectID": "hw/hw-3.html#exercise-6",
    "href": "hw/hw-3.html#exercise-6",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 6",
    "text": "Exercise 6\nTo complete this exercise you will first need to watch the documentary Coded Bias. To do so, you either need to be on the Duke network or connected to the Duke VPN. Then go to https://find.library.duke.edu/catalog/DUKE009834953 and click on “View Online”. Once you watch the video, write a one paragraph reflection highlighting at least one thing that you already knew about (from the course prep materials) and at least one thing you learned from the movie as well as any other aspects of the documentary that you found interesting / enlightening.\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-3.html#submission",
    "href": "hw/hw-3.html#submission",
    "title": "HW 3 - Ethics + recap",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-3.html#grading",
    "href": "hw/hw-3.html#grading",
    "title": "HW 3 - Ethics + recap",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 10 points\nExercise 2: 10 points\nExercise 3: 10 points\nExercise 4: 3 points\nExercise 5: 3 points\nExercise 6: 10 points\nWorkflow + formatting: 4 points\nTotal: 50 points"
  },
  {
    "objectID": "hw/hw-2.html",
    "href": "hw/hw-2.html",
    "title": "HW 2 - Data wrangling",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Thursday, Sep 22 at 11:59pm ET.\nThe first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "hw/hw-2.html#workflow-formatting",
    "href": "hw/hw-2.html#workflow-formatting",
    "title": "HW 2 - Data wrangling",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse code style guidelines.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-2.html#packages",
    "href": "hw/hw-2.html#packages",
    "title": "HW 2 - Data wrangling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization and the scales package for better formatting of labels on visualizations.\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "hw/hw-2.html#data",
    "href": "hw/hw-2.html#data",
    "title": "HW 2 - Data wrangling",
    "section": "Data",
    "text": "Data\nThe data originally come from the fivethirtyeight package but we’ll use versions of the data that have been slightly modified to better suit this assignment. You can load the two datasets we’ll be using for this analysis with the following:\n\nmajor_income_undergrad <- read_csv(\"data/major_income_undergrad.csv\")\nmajor_income_grad <- read_csv(\"data/major_income_grad.csv\")\n\nYou can also take a quick peek at your data frames and view their dimensions with the glimpse function.\n\nglimpse(major_income_undergrad)\n\nRows: 172\nColumns: 12\n$ major_code                            <dbl> 5601, 6004, 6211, 2201, 2001, 32…\n$ major                                 <chr> \"Construction Services\", \"Commer…\n$ major_category                        <chr> \"Industrial Arts & Consumer Serv…\n$ undergrad_total                       <dbl> 86062, 461977, 179335, 37575, 53…\n$ undergrad_employed                    <dbl> 73607, 347166, 145597, 29738, 43…\n$ undergrad_employed_fulltime_yearround <dbl> 62435, 250596, 113579, 23249, 34…\n$ undergrad_unemployed                  <dbl> 3928, 25484, 7409, 1661, 3389, 5…\n$ undergrad_unemployment_rate           <dbl> 0.05066099, 0.06838588, 0.048422…\n$ undergrad_p25th                       <dbl> 47000, 34000, 35000, 29000, 3600…\n$ undergrad_median                      <dbl> 65000, 48000, 50000, 41600, 5200…\n$ undergrad_p75th                       <dbl> 98000, 71000, 75000, 60000, 7800…\n$ undergrad_sharewomen                  <dbl> 0.09071251, 0.69036529, 0.651659…\n\nglimpse(major_income_grad)\n\nRows: 172\nColumns: 11\n$ major_code                       <dbl> 5601, 6004, 6211, 2201, 2001, 6206, 1…\n$ major                            <chr> \"Construction Services\", \"Commercial …\n$ major_category                   <chr> \"Industrial Arts & Consumer Services\"…\n$ grad_total                       <dbl> 9173, 53864, 24417, 5411, 9109, 19099…\n$ grad_employed                    <dbl> 7098, 40492, 18368, 3590, 7512, 15157…\n$ grad_employed_fulltime_yearround <dbl> 6511, 29553, 14784, 2701, 5622, 12304…\n$ grad_unemployed                  <dbl> 681, 2482, 1465, 316, 466, 8324, 473,…\n$ grad_unemployment_rate           <dbl> 0.08754339, 0.05775585, 0.07386679, 0…\n$ grad_p25th                       <dbl> 110000, 89000, 100000, 85000, 83700, …\n$ grad_median                      <dbl> 75000, 60000, 65000, 47000, 57000, 80…\n$ grad_p75th                       <dbl> 53000, 40000, 45000, 24500, 40600, 50…\n\n\nThese two datasets have a trove of information. Three variables are common to both datasets:\n\nmajor_code: Major code, FO1DP in ACS PUMS\nmajor: Major description\nmajor_category: Category of major from Carnevale et al\n\nThe remaining variables start with either grad_ or undergrad_ suffix, depending on which dataset they are in. The descriptions of these variables is as follows.\n\n*_total: Total number of people with major\n*_sample_size: Sample size (unweighted) of full-time, year-round ONLY (used for earnings)\n*_employed: Number employed (ESR == 1 or 2)\n*_employed_fulltime_yearround: Employed at least 50 weeks (WKW == 1) and at least 35 hours (WKHP >= 35)\n*_unemployed: Number unemployed (ESR == 3)\n*_unemployment_rate: Unemployed / (Unemployed + Employed)\n*_p25th: 25th percentile of earnings\n*_median: Median earnings of full-time, year-round workers\n*_p75th: 75th percentile of earnings\n\nFinally, undergrad_sharewomen is the proportion of women with the major, and we only have this information for undergraduates.\nLet’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nHow much are college graduates (those who finished undergrad) making?\nHow do incomes of those with a graduate degree compare to those with an undergraduate degree?\n\nIn the following exercises we aim to answer these questions."
  },
  {
    "objectID": "hw/hw-2.html#exercise-1",
    "href": "hw/hw-2.html#exercise-1",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhich majors have the lowest unemployment rate? Answer the question using a single data wrangling pipeline and focusing on undergraduates (major_income_undergrad). The output should be a tibble with the columns major, and undergrad_unemployment_rate, with the major with the lowest unemployment rate on top, and displaying the majors with the lowest 5 unemployment rates. Include a sentence listing the majors and the unemployment rates (as percentages)."
  },
  {
    "objectID": "hw/hw-2.html#exercise-2",
    "href": "hw/hw-2.html#exercise-2",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhich majors have the highest percentage of women? Answer the question using a single data wrangling pipeline and focusing on undergraduates (major_income_undergrad). The output should be a tibble with the columns major, and undergrad_sharewomen, with the major with the highest proportion of women on top, and displaying the majors with the highest 5 proportions of women. Include a sentence listing the majors and the percentage of women with the major.\n\n\nRender, commit (with a descriptive and concise commit message), and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-3",
    "href": "hw/hw-2.html#exercise-3",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 3",
    "text": "Exercise 3\nHow much are college graduates (those who finished undergrad) making? For this exercise, focus on undergraduates (major_income_undergrad).\n\nPlot the distribution of all median incomes using a histogram with an appropriate binwidth.\nCalculate the mean and median for median income. Based on the shape of the histogram, determine which of these summary statistics is useful for describing the distribution.\nDescribe the distribution of median incomes of college graduates across various majors based on your histogram from part (a) and incorporating the statistic you chose in part (b) to help your narrative. Hint: Mention shape, center, spread, any unusual observations.\n\n\n\nNow is a good time to render, commit (with a descriptive and concise commit message), and push again. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-4",
    "href": "hw/hw-2.html#exercise-4",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 4",
    "text": "Exercise 4\nHow do the distributions of median income compare across major categories? For this exercise, focus on undergraduates (major_income_undergrad).\n\nCalculate a the minimum, median, and maximum median income per major category as well as the number of majors in each category. Your summary statistics should be in decreasing order of median median income.\nCreate box plots of the distribution of median income by major category.\n\nThe variable major_category should be on the y-axis and undergrad_median on the x-axis.\nThe order of the boxes in your plot should match the order in your summary table from part (a).\nUse color to enhance your plot, and turn off any legends providing redundant information.\nStyle the x-axis labels such that the values are shown in thousands, e.g., 20000 should show up as $20K.\n\nIn 1-2 sentences, describe how median incomes across various major categories compare. Your description should also touch on where your own intended/declared major (yes, your major at Duke).\n\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-5",
    "href": "hw/hw-2.html#exercise-5",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 5",
    "text": "Exercise 5\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true. Once again, focus on undergraduates (major_income_undergrad) for this exercise.\n\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\n  \"Biology & Life Science\",\n  \"Computers & Mathematics\",\n  \"Engineering\",\n  \"Physical Sciences\"\n  )\n\nThen, fill in the partial code to create a new variable in our data frame indicating whether a major is STEM or not. Note that you need to figure out the logical operator that goes into ___. Double check that you have successfully created this variable by selecting the variables major_type and major_category.\n\nmajor_income_undergrad <- major_income_undergrad |>\n  mutate(major_type = if_else(major_category ___ stem_categories, \"STEM\", \"Not STEM\"))\n\nIn a single pipeline, determine which STEM majors’ median earnings are less than $55,000. Your answer should be a tibble with the columns major, major_type, and undergrad_median, arranged in order of descending undergrad_median.\n\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-6",
    "href": "hw/hw-2.html#exercise-6",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 6",
    "text": "Exercise 6\nFinally, we want to compare median incomes of STEM majors with and without a graduate degree in their major.\n\nTo do so, we will first join data that contains information on median incomes of those with undergraduate and graduate degrees. Join the major_income_undergrad and the major_income_grad data sets by major_code. Join them in such a way where only rows that include the same major_code from each data set are included. Name the new data set major_income.\nCreate a new variable called grad_multiplier – the ratio of median income of those with a graduate degree divided by median income of those with an undergraduate degree, for STEM majors. The result should be tibble with the variables major, grad_multiplier, grad_median, and undergrad_median. The results should be displayed in descending order of grad_multiplier and display the STEM majors with top 10 grad_multiplier.\nDetermine the number of rows of major_income_undergrad and major_income_grad as well as major_income. How come they don’t all have the same number of rows?\n\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#submission",
    "href": "hw/hw-2.html#submission",
    "title": "HW 2 - Data wrangling",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-2.html#grading",
    "href": "hw/hw-2.html#grading",
    "title": "HW 2 - Data wrangling",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 5 points\nExercise 2: 5 points\nExercise 3: 9 points\nExercise 4: 10 points\nExercise 5: 6 points\nExercise 6: 10 points\nWorkflow + formatting: 5 points\nTotal: 50 points"
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Data visualization",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Thursday, Sep 15 at 11:59pm ET."
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - Data visualization",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "hw/hw-1.html#guidelines-tips",
    "href": "hw/hw-1.html#guidelines-tips",
    "title": "HW 1 - Data visualization",
    "section": "Guidelines + tips",
    "text": "Guidelines + tips\nAs we’ve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete this homework and other assignments in this course. There will be periodic reminders in this assignment to remind you to knit, commit, and push your changes to GithHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\nNote\n\n\n\nNote: Do not let R output answer the question for you unless the question specifically asks for just a plot. For example, if the question asks for the number of columns in the data set, please type out the number of columns. You are subject to lose points if you do not."
  },
  {
    "objectID": "hw/hw-1.html#workflow-formatting",
    "href": "hw/hw-1.html#workflow-formatting",
    "title": "HW 1 - Data visualization",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse code style guidelines.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-1.html#data-1-duke-forest-houses",
    "href": "hw/hw-1.html#data-1-duke-forest-houses",
    "title": "HW 1 - Data visualization",
    "section": "Data 1: Duke Forest houses",
    "text": "Data 1: Duke Forest houses\n\n\n\n\n\n\nNote\n\n\n\nUse this dataset for Exercises 1 and 2.\n\n\nFor the following two exercises you will work with data on houses that were sold in the Duke Forest neighborhood of Durham, NC in November 2020. The duke_forest dataset comes from the openintro package. You can see a list of the variables on the package website or by running ?duke_forest in your console."
  },
  {
    "objectID": "hw/hw-1.html#exercise-1",
    "href": "hw/hw-1.html#exercise-1",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you’re helping some family friends who are looking to buy a house in Duke Forest. As they browse Zillow listings, they realize some houses have garages and others don’t, and they wonder: Does having a garage make a difference?\nLuckily, you can help them answer this question with data visualization!\n\nMake histograms of the prices of houses in Duke Forest based on whether they have a garage.\n\nIn order to do this, you will first need to create a new variable called garage (with levels \"Garage\" and \"No garage\").\nBelow is the code for creating this new variable. Here, we mutate() the duke_forest data frame to add a new variable called garage which takes the value \"Garage\" if the text string \"Garage\" is detected in the parking variable and takes the test string \"No garage\" if not.\n\n\n\nduke_forest |>\n  mutate(garage = if_else(str_detect(parking, \"Garage\"),   \"Garage\", \"No garage\"))\n\n\nThen, facet by garage and use different colors for the two facets.\nChoose an appropriate binwidth and decide whether a legend is needed, and turn it off if not.\nInclude informative title and axis labels.\nFinally, include a brief (2-3 sentence) narrative comparing the distributions of prices of Duke Forest houses that do and don’t have garages. Your narrative should touch on whether having a garage “makes a difference” in terms of the price of the house.\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#exercise-2",
    "href": "hw/hw-1.html#exercise-2",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 2",
    "text": "Exercise 2\nIt’s expected that within any given marker larger houses will be priced higher. It’s also expected that the age of the house will have an effect on the price. However in some markets new houses might be more expensive while in others new construction might mean “no character” and hence be less expensive. So your family friends ask: “In Duke Forest, do houses that are bigger and more expensive tend to be newer ones than those that are smaller and cheaper?”\nOnce again, data visualization skills to the rescue!\n\nCreate a scatter plot to exploring the relationship between price and area, conditioning for year_built.\nUse geom_smooth() with the argument se = FALSE to add a smooth curve fit to the data and color the points by year_built.\nInclude informative title, axis, and legend labels.\nDiscuss each of the following claims (1-2 sentences per claim). Your discussion should touch on specific things you observe in your plot as evidence for or against the claims.\n\nClaim 1: Larger houses are priced higher.\nClaim 2: Newer houses are priced higher.\nClaim 3: Bigger and more expensive houses tend to be newer ones than smaller and cheaper ones.\n\n\n\nNow is a good time to render, commit, and push.\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#data-2-brfss",
    "href": "hw/hw-1.html#data-2-brfss",
    "title": "HW 1 - Data visualization",
    "section": "Data 2: BRFSS",
    "text": "Data 2: BRFSS\n\n\n\n\n\n\nNote\n\n\n\nUse this dataset for Exercises 3 to 5.\n\n\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is the nation’s premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world.\nSource: cdc.gov/brfss\n\nIn the following exercises we will work with data from the 2020 BRFSS survey. The originally come from here, though we will work with a random sample of responses and a small number of variables from the data provided. These have already been sampled for you and the dataset you’ll use can be found in the data folder of your repo. It’s called brfss.csv.\n\nbrfss <- read_csv(\"data/brfss.csv\")"
  },
  {
    "objectID": "hw/hw-1.html#exercise-3",
    "href": "hw/hw-1.html#exercise-3",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nHow many rows are in the brfss dataset? What does each row represent?\nHow many columns are in the brfss dataset? Indicate the type of each variable.\nInclude the code and resulting output used to support your answer.\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-4",
    "href": "hw/hw-1.html#exercise-4",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 4",
    "text": "Exercise 4\nDo people who smoke more tend to have worse health conditions?\n\nUse a segmented bar chart to visualize the relationship between smoking (smoke_freq) and general health (general_health). Decide on which variable to represent with bars and which variable to fill the color of the bars by.\nPay attention to the order of the bars and, if need be, use the fct_relevel function to reorder the levels of the variables.\n\nBelow is sample code for releveling general_health. Here we first convert general_health to a factor (how R stores categorical data) and then order the levels from Excellent to Poor.\n\n\n\nbrfss |>\n  mutate(\n    general_health = as.factor(general_health),\n    general_health = fct_relevel(general_health, \"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\")\n  )\n\n\nInclude informative title, axis, and legend labels.\nComment on the motivating question based on evidence from the visualization: Do people who smoke more tend to have worse health conditions?\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-5",
    "href": "hw/hw-1.html#exercise-5",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 5",
    "text": "Exercise 5\nHow are sleep and general health associated?\n\nCreate a visualization displaying the relationship between sleep and general_health.\nInclude informative title and axis labels.\nModify your plot to use a different theme than the default.\nComment on the motivating question based on evidence from the visualization: How are sleep and general health associated?\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-6",
    "href": "hw/hw-1.html#exercise-6",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nFill in the blanks:\n\nThe gg in the name of the package ggplot2 stands for ___.\nIf you map the same continuous variable to both x and y aesthetics in a scatterplot, you get a straight ___ line. (Choose between “vertical”, “horizontal”, or “diagonal”.)\n\nCode style: Fix up the code style by spaces and line breaks where needed. Briefly describe your fixes. (Hint: You can refer to the Tidyverse style guide.)\n\n\nggplot(data=mpg,mapping=aes(x=drv,fill=class))+geom_bar() +scale_fill_viridis_d()\n\n\nRead ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments?\n\n\n Render, commit, and push one last time.\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - Data visualization",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - Data visualization",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 7 points\nExercise 2: 9 points\nExercise 3: 5 points\nExercise 4: 9 points\nExercise 5: 7 points\nExercise 6: 8 points\nWorkflow + formatting: 5 points\nTotal: 50 points"
  },
  {
    "objectID": "prepare/09-05.html",
    "href": "prepare/09-05.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR4DS: Chp 2 - Data visualization - Sections 2.1 and 2.4\n\nIf you haven’t yet done so:\n\nRead the syllabus!\nComplete the Getting to know you survey\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\nJoin the course Slack using the invitation link in your email.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "prepare/10-24.html",
    "href": "prepare/10-24.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS: Chp 2 - Study design"
  },
  {
    "objectID": "prepare/10-18.html",
    "href": "prepare/10-18.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-25.html",
    "href": "prepare/10-25.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-31.html",
    "href": "prepare/10-31.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-12.html",
    "href": "prepare/09-12.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-06.html",
    "href": "prepare/09-06.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR4DS: Chp 2 - Data visualization - Sections 2.5 - 2.10\n\n⌨️ Watch:\n\nData and visualization\nVisualising data with ggplot2"
  },
  {
    "objectID": "prepare/10-27.html",
    "href": "prepare/10-27.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-13.html",
    "href": "prepare/09-13.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-20.html",
    "href": "prepare/10-20.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-15.html",
    "href": "prepare/09-15.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-01.html",
    "href": "prepare/09-01.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR for Data Science (R4DS): Chp 1 - Introduction\nIntroduction to Modern Statistics (IMS): Chp 1 - Hello data\nThe syllabus!\n\n⌨️ Do:\n\nComplete the Getting to know you survey\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\n\nIf you haven’t yet done so:\n\nJoin the course Slack using the invitation link in your email.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "prepare/09-29.html",
    "href": "prepare/09-29.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-07.html",
    "href": "prepare/11-07.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-10.html",
    "href": "prepare/11-10.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/08-30.html",
    "href": "prepare/08-30.html",
    "title": "Prepare",
    "section": "",
    "text": "Join the course Slack using the invitation link in your email.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "prepare/11-15.html",
    "href": "prepare/11-15.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS: Chp 11 - Hypothesis testing with randomization\nIMS: Chp 12 - Confidence intervals with bootstrapping\n\n\n\n\n\n\n\n\nNote\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-01.html",
    "href": "prepare/11-01.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-29.html",
    "href": "prepare/11-29.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-14.html",
    "href": "prepare/11-14.html",
    "title": "Prepare",
    "section": "",
    "text": "⌨️ Watch:\n\nQuantifying uncertainty\nBootstrapping\nHypothesis testing\n\n\n\n\n\n\n\n\nNote\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-17.html",
    "href": "prepare/11-17.html",
    "title": "Prepare",
    "section": "",
    "text": "No prepare materials for today, work on exam prep!"
  },
  {
    "objectID": "prepare/11-03.html",
    "href": "prepare/11-03.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-08.html",
    "href": "prepare/11-08.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/12-01.html",
    "href": "prepare/12-01.html",
    "title": "Prepare",
    "section": "",
    "text": "⌨️ Watch:\n\nDoing data science\n\nTake the survey for indicating preferences for looking further topics"
  },
  {
    "objectID": "prepare/10-04.html",
    "href": "prepare/10-04.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-19.html",
    "href": "prepare/09-19.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR4DS: Chp 6 - Data tidying (Sections 6.1 and 6.2)\nTidy Data by Hadley Wickham"
  },
  {
    "objectID": "prepare/09-27.html",
    "href": "prepare/09-27.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-06.html",
    "href": "prepare/10-06.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-13.html",
    "href": "prepare/10-13.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-26.html",
    "href": "prepare/09-26.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR4DS: Chp 14 - Numbers (Sections 14.1, 14.2, and 14.4)\nR4DS: Chp 15 - Strings (Sections 15.1 - 15.3)"
  },
  {
    "objectID": "prepare/09-22.html",
    "href": "prepare/09-22.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-17.html",
    "href": "prepare/10-17.html",
    "title": "Prepare",
    "section": "",
    "text": "Check your email before lab to find out who your teammates are. If you like, reach out to them before class. Or just find them when you get there."
  },
  {
    "objectID": "prepare/09-20.html",
    "href": "prepare/09-20.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-08.html",
    "href": "prepare/09-08.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS: Chp 4 - Exploring categorical data\nIMS: Chp 5 - Exploring numerical data\n\n⌨️ Watch:\n\nVisualizing numerical data\nVisualizing categorical data\n\n📜Optional reading – Blog posts that might be of interest for those who want to dive deeper / go further:\n\n#barbarplots\nVisualizing distributions with raincloud plots"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html",
    "href": "ae/ae-03-wrangling-flights.html",
    "title": "AE 03: Wrangling flights",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-03-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, Sep 16 at 11:59pm.\nTo demonstrate data wrangling we will use flights, a tibble in the nycflights13 R package. It includes characteristics of all flights departing from New York City (JFK, LGA, EWR) in 2013.\nThe data frame has over 336,000 observations (rows), 336776 observations to be exact, so we will not view the entire data frame. Instead we’ll use the commands below to help us explore the data.\nThe head() function returns “A tibble: 6 x 19” and then the first six rows of the flights data."
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#select",
    "href": "ae/ae-03-wrangling-flights.html#select",
    "title": "AE 03: Wrangling flights",
    "section": "select()",
    "text": "select()\n\nDemo: Make a data frame that only contains the variables dep_delay and arr_delay.\n\n\n# add code here\n\n\nDemo: Make a data frame that keeps every variable except dep_delay.\n\n\n# add code here\n\n\nDemo: Make a data frame that includes all variables between year through dep_delay (inclusive). These are all variables that provide information about the departure of each flight.\n\n\n# add code here\n\n\nDemo: Use the select helper contains() to make a data frame that includes the variables associated with the arrival, i.e., contains the string \"arr\\_\" in the name.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#the-pipe",
    "href": "ae/ae-03-wrangling-flights.html#the-pipe",
    "title": "AE 03: Wrangling flights",
    "section": "The pipe",
    "text": "The pipe\nBefore working with more data wrangling functions, let’s formally introduce the pipe. The pipe, |>, is an operator (a tool) for passing information from one process to another. We will use |> mainly in data pipelines to pass the output of the previous line of code as the first input of the next line of code.\nWhen reading code “in English”, say “and then” whenever you see a pipe.\n\nYour turn (4 minutes): Run the following chunk and observe its output. Then, come up with a different way of obtaining the same output.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#slice",
    "href": "ae/ae-03-wrangling-flights.html#slice",
    "title": "AE 03: Wrangling flights",
    "section": "slice()",
    "text": "slice()\n\nDemo: Display the first five rows of the flights data frame.\n\n\n# add code here\n\n\nDemo: Display the last two rows of the flights data frame.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#arrange",
    "href": "ae/ae-03-wrangling-flights.html#arrange",
    "title": "AE 03: Wrangling flights",
    "section": "arrange()",
    "text": "arrange()\n\nDemo: Let’s arrange the data by departure delay, so the flights with the shortest departure delays will be at the top of the data frame.\n\nQuestion: What does it mean for the dep_delay to have a negative value?\n\n# add code here\n\n\nDemo: Now let’s arrange the data by descending departure delay, so the flights with the longest departure delays will be at the top.\n\n\n# add code here\n\n\nYour turn (5 minutes): Create a data frame that only includes the plane tail number (tailnum), carrier (carrier), and departure delay for the flight with the longest departure delay. What is the plane tail number (tailnum) for this flight? Share your response on Slack on the relevant thread on #general using code formatting.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#filter",
    "href": "ae/ae-03-wrangling-flights.html#filter",
    "title": "AE 03: Wrangling flights",
    "section": "filter()",
    "text": "filter()\n\nDemo: Filter the data frame by selecting the rows where the destination airport is RDU.\n\n\n# add code here\n\n\nDemo: We can also filter using more than one condition. Here we select all rows where the destination airport is RDU and the arrival delay is less than 0.\n\n\n# add code here\n\nWe can do more complex tasks using logical operators:\n\n\n\noperator\ndefinition\n\n\n\n\n<\nis less than?\n\n\n<=\nis less than or equal to?\n\n\n>\nis greater than?\n\n\n>=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x?\n\n\n\nThe final operator only makes sense if x is logical (TRUE / FALSE).\n\nYour turn (4 minutes): Describe what the code is doing in words. Share your response on Slack on the relevant thread on #general.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#count",
    "href": "ae/ae-03-wrangling-flights.html#count",
    "title": "AE 03: Wrangling flights",
    "section": "count()",
    "text": "count()\n\nDemo: Create a frequency table of the destination locations for flights from New York.\n\n\n# add code here\n\n\nDemo: In which month was there the fewest number of flights? How many flights were there in that month?\n\n\n# add code here\n\n\nYour turn (5 minutes): On which date (month + day) was there the largest number of flights? How many flights were there on that day? Share your response on Slack on the relevant thread on #general using code formatting.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#mutate",
    "href": "ae/ae-03-wrangling-flights.html#mutate",
    "title": "AE 03: Wrangling flights",
    "section": "mutate()",
    "text": "mutate()\nUse mutate() to create a new variable.\n\nDemo: In the code chunk below, air_time (minutes in the air) is converted to hours, and then new variable mph is created, corresponding to the miles per hour of the flight.\n\n\n# add code here\n\n\nYour turn (4 minutes): Create a new variable to calculate the percentage of flights in each month. What percentage of flights take place in July?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#summarize",
    "href": "ae/ae-03-wrangling-flights.html#summarize",
    "title": "AE 03: Wrangling flights",
    "section": "summarize()",
    "text": "summarize()\nsummarize() collapses the rows into summary statistics and removes columns irrelevant to the calculation.\nBe sure to name your columns!\n\n# add code here\n\nQuestion: Why did this code return NA?\nLet’s fix it!\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights.html#group_by",
    "href": "ae/ae-03-wrangling-flights.html#group_by",
    "title": "AE 03: Wrangling flights",
    "section": "group_by()",
    "text": "group_by()\ngroup_by() is used for grouped operations. It’s very powerful when paired with summarise() to calculate summary statistics by group.\nHere we find the mean and standard deviation of departure delay for each month.\n\n# add code here\n\n\nYour turn (4 minutes): What is the median departure delay for each airports around NYC (origin)? Which airport has the shortest median departure delay? Share your response on Slack on the relevant thread.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-11-yankee-candle.html",
    "href": "ae/ae-11-yankee-candle.html",
    "title": "Yankee Candle reviews on Amazon",
    "section": "",
    "text": "Do this part in yankee-candle-scrape.R."
  },
  {
    "objectID": "ae/ae-11-yankee-candle.html#part-2---data-analysis",
    "href": "ae/ae-11-yankee-candle.html#part-2---data-analysis",
    "title": "Yankee Candle reviews on Amazon",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\n\nLoad the data you saved into the data folder and name it yc_reviews_raw.\n\n\n# add code here\n\n\nYour turn (5 minutes): Our goal is to plot the number of reviews mentioning “no scent” or “no smell” per week, limiting our plot to reviews posted in 2022. Take a look at the data you loaded and outline how you can transform it to prepare it for such a plot. Your response should be bullet points that can roughly be translated to steps in a data wrangling pipeline.\n\nAdd your response here.\n\nDemo: Create the plot described above.\n\n\n# add code here\n\n\nYour turn (3 minutes): Outline how this exercise could be expanded to make a plot like this one that compares number of reviews mentioning no scent/smell and number of COVID cases.\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-19-inference-overview.html",
    "href": "ae/ae-19-inference-overview.html",
    "title": "Inference overview",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\n\n\nrc <- read_csv(\"data/roller_coasters.csv\")\n\nIn this application exercise, we will be looking at a roller coaster and amusement park database by Duane Marden.1 This database records multiple features of roller coasters. For the purpose of this activity, we will work with a random sample of 157 roller coasters.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nage_group\n1: Older (Built between 1900-1979)\n2: Recent (1980-1999)\n3: Newest (2000-current)\n\n\ncoaster\nName of the roller coaster\n\n\npark\nName of the park where the roller coaster is located\n\n\ncity\nCity where the roller coaster is located\n\n\nstate\nState where the roller coaster is located\n\n\ntype\nMaterial of track (Steel or Wooden)\n\n\ndesign\nHow a passenger is positioned in the roller coaster:\nFlying: a roller coaster ridden while parallel with the track.\nInverted: a roller coaster which uses trains traveling beneath, rather than on top of, the track. Unlike a suspended roller coaster, an inverted roller coaster’s trains are rigidly attached to the track.\nSit Down: a traditional roller coaster ridden while sitting down.\nSuspended: a roller coaster using trains which travel beneath the track and pivot on a swinging arm from side to side, exaggerating the track’s banks and turns.\nStand Up: a coaster ridden while standing up instead of sitting down.\nPipeline: a coaster where riders are positioned between the rails instead of above or below.\nWing: a coaster where pairs of riders sit on either side of a roller coaster track in which nothing is above or below the riders.\n4th Dimension: a coaster where the cars have the ability to rotate on an axis perpendicular to that of the track.\n\n\nyear_opened\nYear when roller coaster opened\n\n\ntop_speed\nMaximum speed of roller coaster (mph)\n\n\nmax_height\nHighest point of roller coaster (ft)\n\n\ndrop\nLength of largest gap between high and low points of roller coaster (ft)\n\n\nlength\nLength of roller coaster track (ft)\n\n\nduration\nTime length of roller coaster ride (sec)\n\n\ninversions\nWhether or not roller coaster flips passengers at any point (Yes or No)\n\n\nnum_of_inversions\nNumber of times roller coaster flips passengers\n\n\n\n\nResearch question 1\n\nIs the true proportion of steel roller coasters opened before 1970 different than those opened after 1970?\n\n\nDemo: Create a new variable called opened_recently that has a response of yes if the roller coaster was opened after 1970, and no if the roller coaster was opened during or before 1970. Save this new factor variable in the rc data set. Additionally, make type a factor variable.\n\n\n# add code here\n\n\nYour turn: Based on the research question, which of the following is the appropriate null hypothesis?\n\n\\(H_0\\): \\(\\mu = 0.5\\)\n\\(H_0\\): \\(p > 0.5\\)\n\\(H_0\\): \\(\\mu_1 - \\mu_2 = 0\\)\n\\(H_0\\): \\(p_1 - p_2 = 0\\)\n\n\nAdd response here.\n\nDemo: Write out the appropriate alternative hypothesis in both words and notation.\n\nAdd response here.\n\nDemo: Calculate the observed statistic.\n\n\n# add code here\n\n\nDemo: How do we create a null distribution for this hypothesis test? Write out the steps below.\n\nAdd response here.\n\nDemo: Create the null distribution with 1,000 repeated samples.\n\n\n# add code here\n\n\nDemo: Visualize the null distribution and shade in the area used to calculate the p-value.\n\n\n# add code here\n\n\nYour turn: Calculate p-value. Then use the p-value to make your conclusion using a significance level of 0.1 and write out an appropriate conclusion below. Recall that the conclusion has 3 components.\n\nHow the p-value compares to the significance level.\nThe decision you make with respect to the hypotheses (reject \\(H_0\\) /fail to reject \\(H_0\\))\nThe conclusion in the context of the alternative hypothesis.\n\n\nAdd response here.\n\n# add code here\n\n\n\nResearch question 2\n\nWe want to investigate the relationship between how fast a roller coaster goes, and how long a roller coaster lasts. Specifically, we are interested in how well the duration of a roller coaster explains or predicts how fast it is.\n\n\nQuestion: Based on this research question, which two variables should we use from our data set? Which is our response?\n\nAdd response here.\n\nDemo: Fit a model predicting top_speed from duration and display the tidy summary output.\n\n\n# add code here\n\n\nYour turn: Use your model to estimate the top speed of a roller coaster if their duration is 155 minutes\n\n\n# add code here\n\n\nDemo: Write out the estimated model in proper notation and interpret the slope coefficient\n\nAdd response here.\n\nQuestion: The slope you calculated and interpeted above is a sample statistic (an estimate). It is possible (and quite likely) that the true slope of the relationship between durations and top speeds of all roller coasters is not exactly equal to this value. How can we quantify the uncertainty around this estimate?\n\nAdd response here.\n\nYour turn: Describe how we can construct a bootstrap distribution for the slope of the model predicting top_speed from duration.\n\nAdd response here.\n\nDemo: Now, construct this bootstrap distribution.\n\n\n# add code here\n\n\nDemo: Create a 90% confidence interval by filling in the code below.\n\n\n# add code here\n\n\nDemo: Interpret the confidence interval in the context of the problem.\n\nAdd response here.\n\nDemo: Now fit a model predicting log of top_speed from duration.\n\n\n# add code here\n\n\nDemo: Write the estimated model and interpret the slope.\n\nAdd response here.\n\n\nResearch question 3\n\nWe are also interested in investigating if roller coasters opened after 1970 are faster than those opened before. For this question, we want to estimate the difference.\n\n\nQuestion: How is this different from question one? Should we make a confidence interval or conduct a hypothesis test?\n\nAdd response here.\n\nDemo: Now, use bootstrapping to estimate the difference between the true speeds of roller coasters before and after 1970.\n\n\n# add code here\n\n\nYour turn: Create a 99% confidence interval and interpret it in the context of the data and the research question.\n\n\n# add code here\n\nAdd response here.\n\n\nDiscussion\n\nBrainstorm the differences between generating new samples via bootstrapping and permuting. Write down the key differences below. Hint: Think back to the different sampling techniques between research question 1 and research questions 2 and 3.\n\n\n\n\n\n\nFootnotes\n\n\nRoller Coaster DataBase, UltimateRollerCoaster.com, ESTEEM: Enhancing Statistics Teachers Education with E-Modules.↩︎"
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates.html",
    "href": "ae/ae-15-modelling-loan-interest-rates.html",
    "title": "Modelling loan interest rates",
    "section": "",
    "text": "In this application exercise we will be studying loan interest rates. The dataset is one you’ve come across before in your reading – the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nBefore we use the dataset, we’ll make a few transformations to it.\nHere is a glimpse at the data:"
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates.html#main-effects-model",
    "href": "ae/ae-15-modelling-loan-interest-rates.html#main-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(add~math~text~here\\)\nMortgage: \\(add~math~text~here\\)\nOwn: \\(add~math~text~here\\)\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates.html#interaction-effects-model",
    "href": "ae/ae-15-modelling-loan-interest-rates.html#interaction-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(add~math~text~here\\)\nMortgage: \\(add~math~text~here\\)\nOwn: \\(add~math~text~here\\)\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates.html#choosing-a-model",
    "href": "ae/ae-15-modelling-loan-interest-rates.html#choosing-a-model",
    "title": "Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\n# add code here\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nAdd response here.\n\nQuestion: Based on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-21-jane-austen.html",
    "href": "ae/ae-21-jane-austen.html",
    "title": "He replied / she cried: Text mining and gender roles",
    "section": "",
    "text": "Which verbs follow “she” and “he” pronouns in Jane Austen novels? Are they similar or different?\n\nGoal: Use text mining methods to explore whether verbs that follow she and he pronouns are similar or different.\nInspirations:\n\nBlog post by Julia Silge: https://juliasilge.com/blog/gender-pronouns\nJockers, Matthew, and Gabi Kirilloff. “Understanding gender and character agency in the 19th century novel.” Journal of Cultural Analytics 2.2 (2016): 11066.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidytext)\nlibrary(knitr)\nlibrary(janeaustenr) # install.packages(\"janeaustenr)\nlibrary(textdata)    # install.packages(\"textdata)\n\n\n\n\nThe janeaustenr package offers a function, austen_books(), that returns a tidy data frame of Jane Austen’s 6 completed, published novels.\n\n# add code here\n\n\nDemo: Which books are included in the dataset?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-09-dse-bias-A.html",
    "href": "ae/ae-09-dse-bias-A.html",
    "title": "AE 09: Data science ethics - Algorithmic bias",
    "section": "",
    "text": "Part 1 - Stochastic parrots\nYour turn (10 minutes):\n\nRead the following title and abstract.\n\n\nOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 (Bender et. al., 2021)\nThe past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.\n\n\nHave you used a natural language model before? Describe your use.\n\n[Answers may vary.] Predictive typing on phone messages.\n\nWhat is meant by “stochastic parrots” in the paper title?\n\n[Answers may vary.] The language models “parrot” (repeat) the biases in the input data they’re trained on.\n\n\nPart 2 - Predicting ethnicity\nYour turn (12 minutes): Imai and Khanna (2016) built a racial prediction algorithm using a Bayes classifier trained on voter registration records from Florida and the U.S. Census Bureau’s name list.\n\nThe following is the title and the abstract of the paper. Take a minute to read them.\n\n\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology.\n\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nThen, if you feel comfortable, load the wru package and try it out using the sample data provided in the package. And if you don’t feel comfortable doing so, take a look at the results below. Was the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(tidyverse)\nlibrary(wru)\n\npredict_race(voter.file = voters, surname.only = TRUE) %>% \n  select(surname, pred.whi, pred.bla, pred.his, pred.asi, pred.oth)\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi    pred.oth\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906 0.084557725\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581 0.170827160\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883 0.010573240\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323 0.057857101\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594 0.009224032\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635 0.109676251\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765 0.077409913\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125 0.012105576\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541 0.048937658\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712 0.054333479\n\n\n[Answers may vary.]\n\nIf you have installed the package, re-run the code, this time to see what the package predicts for your race. Now consider the same questions again: Was the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nme <- tibble(surname = \"Rundel\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\nWarning: Unknown or uninitialised column: `state`.\n\n\nProceeding with last name predictions...\n\n\nℹ All local files already up-to-date!\nℹ All local files already up-to-date!\n\n\n  surname  pred.whi pred.bla pred.his pred.asi   pred.oth\n1  Rundel 0.9177967        0        0        0 0.08220329\n\n\n[Answers may vary.]"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html",
    "href": "ae/ae-17-quantify-uncertainty.html",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#population-vs-sample",
    "href": "ae/ae-17-quantify-uncertainty.html#population-vs-sample",
    "title": "Quantifying uncertainty",
    "section": "Population vs Sample",
    "text": "Population vs Sample\n\nMotivation\nWe have data on the price per guest (ppg) for a random sample of 50 Airbnb listings in 2020 for Asheville, NC. We are going to use these data to investigate what we would of expected to pay for an Airbnb in in Asheville, NC in June 2020. Read in the data and answer the following questions.\n\nabb <- read_csv(\"data/asheville.csv\")\n\nglimpse(abb)\n\nRows: 50\nColumns: 1\n$ ppg <dbl> 48.00000, 40.00000, 99.00000, 13.00000, 55.00000, 75.00000, 74.000…"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#terminology",
    "href": "ae/ae-17-quantify-uncertainty.html#terminology",
    "title": "Quantifying uncertainty",
    "section": "Terminology",
    "text": "Terminology\n\nPopulation parameter - What we are interested in. Statistical measure that describes an entire population.\nSample statistic (point estimate) - describes a sample. A piece of information you get from a fraction of the population.\n\nUse these data and the tools we’ve learned in this class to come up with your best guess for what you would expect to pay (i.e. true price) for an Airbnb in Asheville, NC (June 2020).\n\n# add code here\n\nDo you think your guess is correct?\nNot really\n\nIf you want to estimate a population parameter, do you prefer to report a range of values the parameter might be in, or a single value?\n\nRange of values\n\nVariability - How spread out your data are. Uncertainty.\n\nSuppose we split the class in half and ask each student their height. Then, we calculate the mean height of students on each side of the classroom. Would you expect these two means to be exactly equal, close but not equal, or wildly different?\nClose, but not equal"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#why-do-we-care",
    "href": "ae/ae-17-quantify-uncertainty.html#why-do-we-care",
    "title": "Quantifying uncertainty",
    "section": "Why do we care?",
    "text": "Why do we care?\nWe can quantify the variability of the sample statistics to help calculate a range of plausible values for the population parameter of interest\nBootstrapping is a statistical procedure that re samples a single data set to create many simulated samples."
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#how-do-we-do-this",
    "href": "ae/ae-17-quantify-uncertainty.html#how-do-we-do-this",
    "title": "Quantifying uncertainty",
    "section": "How do we do this?",
    "text": "How do we do this?\nGoal: create a distribution of sample statistics under “the same” conditions. How do we do this?\nDemo\n- Resample with replacement from our data n (50) times - Calculate the new resampled mean - Plot it - Do this entire process many many times"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#confidence-interval",
    "href": "ae/ae-17-quantify-uncertainty.html#confidence-interval",
    "title": "Quantifying uncertainty",
    "section": "Confidence Interval",
    "text": "Confidence Interval\n\nWhat is it?\n\nRange of plausiable values for our population parameter… just like we wanted!\n\nExercise 1 - Airbnb\nLet’s bootstrap!\nIt’s good practice to ask yourself the following questions:\n\nWhat is my sample statistic? 76.6\nHow many draws do we need for our bootstrap sample? n number of times (50)\n\nFill in the *** from the bootstrap sample code below.\n\nset.seed(12345)\n\nboot_df <- abb |>\n  specify(response = ppg) |>\n  generate(reps = 10000, type = \"bootstrap\") |>\n  calculate(stat = \"mean\")\n\n\nTake a glimpse at boot_df. What do you see?\n\n\n# add code here\n\n\nPlot a histogram of boot_df. Where is it centered? Why does this make sense?\n\n\n# add code here\n\nNow, let’s use boot_dfto create our 95% confidence interval.\n\n# add code here\n\nLet’s visualize our confidence interval by adding a vertical line at each of these values. Use the code you wrote above and add two lines using geom_vline.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#interpretation",
    "href": "ae/ae-17-quantify-uncertainty.html#interpretation",
    "title": "Quantifying uncertainty",
    "section": "Interpretation",
    "text": "Interpretation\nConfidence intervals - range of plausible values for our parameter of interest\nConfidence intervals are often misinterpreted as probability….\nLets explore: http://www.rossmanchance.com/ISIapplets.html\n\nHow do we interpret this?\n\nA There is a 95% probability the true mean price per night for an Airbnb in Asheville is between 63.3 and 91.0.\nB There is a 95% probability the price per night for an Airbnb in Asheville is between 63.3 and 91.0.\nC We are 95% confident the true mean price per night for Airbnbs in Asheville is between 63.3 and 91.0 $.\nD We are 95% confident the price per night for an Airbnb in Asheville is between 63.3 and 91.0."
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty.html#optional",
    "href": "ae/ae-17-quantify-uncertainty.html#optional",
    "title": "Quantifying uncertainty",
    "section": "Optional",
    "text": "Optional\nNow, create a 90% confidence interval. Report it below. Is it wider or more narrow than the 95% confidence interval?\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-data-types-classes-A.html",
    "href": "ae/ae-06-data-types-classes-A.html",
    "title": "AE 06: Data types and classes",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nskimr: For summarizing the entire data frame at once.\nscales: For better axis labels.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(scales)"
  },
  {
    "objectID": "ae/ae-06-data-types-classes-A.html#type-coercion",
    "href": "ae/ae-06-data-types-classes-A.html#type-coercion",
    "title": "AE 06: Data types and classes",
    "section": "Type coercion",
    "text": "Type coercion\n\nDemo: Determine the type of the following vector. And then, change the type to numeric.\n\nx <- c(\"1\", \"2\", \"3\")\ntypeof(x)\n\n[1] \"character\"\n\nas.numeric(x)\n\n[1] 1 2 3\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\ny <- c(\"a\", \"b\", \"c\")\ntypeof(y)\n\n[1] \"character\"\n\nas.numeric(y)\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\nz <- c(\"1\", \"2\", \"three\")\ntypeof(z)\n\n[1] \"character\"\n\nas.numeric(z)\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA\n\n\nDemo: Suppose you conducted a survey where you asked people how many cars their household owns collectively. And the answers are as follows:\n\nsurvey_results <- tibble(cars = c(1, 2, \"three\"))\nsurvey_results\n\n# A tibble: 3 × 1\n  cars \n  <chr>\n1 1    \n2 2    \n3 three\n\n\nThis is annoying because of that third survey taker who just had to go and type out the number instead of providing as a numeric value. So now you need to update the cars variable to be numeric. You do the following\n\nsurvey_results |>\n  mutate(cars = as.numeric(cars))\n\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3    NA\n\n\nAnd now things are even more annoying because you get a warning NAs introduced by coercion that happened while computing cars = as.numeric(cars) and the response from the third survey taker is now an NA (you lost their data). Fix your mutate() call to avoid this warning.\n\nsurvey_results |>\n  mutate(\n    cars = if_else(cars == \"three\", \"3\", cars),\n    cars = as.numeric(cars)\n    )\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3     3\n\n\nYour turn: First, guess the type of the vector. Then, check if you guessed right. I’ve done the first one for you, you’ll see that it’s helpful to check the type of each element of the vector first.\n\nc(1, 1L, \"C\")\n\nv1 <- c(1, 1L, \"C\")\n\n# to help you guess\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"C\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v1)\n\n[1] \"character\"\n\n\nc(1L / 0, \"A\")\n\nv2 <- c(1L / 0, \"A\")\n\n# to help you guess\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L / 0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v2)\n\n[1] \"character\"\n\n\nc(1:3, 5)\n\nv3 <- c(1:3, 5)\n\n# to help you guess\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n# to check after you guess\ntypeof(v3)\n\n[1] \"double\"\n\n\nc(3, \"3+\")\n\nv4 <- c(3, \"3+\")\n\n# to help you guess\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v4)\n\n[1] \"character\"\n\n\nc(NA, TRUE)\n\nv5 <- c(NA, TRUE)\n\n# to help you guess\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n# to check after you guess\ntypeof(v5)\n\n[1] \"logical\""
  },
  {
    "objectID": "ae/ae-06-data-types-classes-A.html#hotel-bookings",
    "href": "ae/ae-06-data-types-classes-A.html#hotel-bookings",
    "title": "AE 06: Data types and classes",
    "section": "Hotel bookings",
    "text": "Hotel bookings\n\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\n\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nQuestion: Take a look at the the following visualization. How are the months ordered? What would be a better order?\n\n\n\n\n\nDemo: Reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\n\nhotels |>\n  group_by(hotel, arrival_date_month) |>   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr), .groups = \"drop\") |>       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n  ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n  )\n\n\n\n\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\nhotels |>\n  group_by(hotel, arrival_date_month) |>   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr), .groups = \"drop\") |>       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n  ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-18-hypothesis-testing.html",
    "href": "ae/ae-18-hypothesis-testing.html",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "An article in the The Asheville Citizen-Times published in the summer of 2020 claims that the average price per guest (ppg) for properties in Asheville is $60 on Airbnb. To evaluate their claim we will use a dataset on 50 randomly selected Asheville Airbnb listings in June 2020. These data can be found in data/asheville.csv.\nLet’s load the packages we’ll use first.\nAnd then the data."
  },
  {
    "objectID": "ae/ae-18-hypothesis-testing.html#generate",
    "href": "ae/ae-18-hypothesis-testing.html#generate",
    "title": "Quantifying uncertainty",
    "section": "Generate",
    "text": "Generate\nWe’ll start by generating the null distribution.\n\nDemo: Generate the null distribution?\n\n\nset.seed(4321)\n\n\n# add code here\n\n\nYour turn: Take a look at null_dist. What does each element in this distribution represent?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-18-hypothesis-testing.html#visualize",
    "href": "ae/ae-18-hypothesis-testing.html#visualize",
    "title": "Quantifying uncertainty",
    "section": "Visualize",
    "text": "Visualize\n\nQuestion: Before you visualize the distribution of null_dist – at what value would you expect this distribution to be centered? Why?\n\nAdd response here.\n\nDemo: Create an appropriate visualization for your null distribution. Does the center of the distribution match what you guessed in the previous question?\n\n\n# add code here\n\n\nDemo: Now, add a vertical red line on your null distribution that represents your sample statistic.\n\n\n# add code here\n\n\nQuestion: Based on the position of this line, does your observed sample mean appear to be an unusual observation under the assumption of the null hypothesis?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz.html",
    "href": "ae/ae-01-bechdel-dataviz.html",
    "title": "AE 01: Bechdel + data visualization",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-01-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, Sep 9 at 11:59pm.\nIn this mini analysis we work with the data used in the FiveThirtyEight story titled “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”.\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz.html#getting-started",
    "href": "ae/ae-01-bechdel-dataviz.html#getting-started",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\n\nPackages\nWe start with loading the packages we’ll use: tidyverse for majority of the analysis and scales for pretty plot labels later on.\n\nlibrary(tidyverse)\nlibrary(scales)\n\n\n\nData\nThe data are stored as a CSV (comma separated values) file in the data folder of your repository. Let’s read it from there and save it as an object called bechdel.\n\nbechdel <- read_csv(\"data/bechdel.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nThis a modified version of the bechdel dataset from the previous application exercise. It’s been modified to include some new variables derived from existing variables as well as to limit the scope of the data to movies released between 1990 and 2013. For now we’re not going to discuss how these modifications were made (that’s next week’s topic) but if you’re curious, you can find the data prep script in the data/ folder of your repo. Don’t spend too long trying to decipher it, wait till next week when you have the right tools to do so!\n\n\n\n\nGet to know the data\nWe can use the glimpse function to get an overview (or “glimpse”) of the data.\n\n# add code here\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a ___.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are ___ columns in the dataset.\n\n\nVariables of interest\nThe variables we’ll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars.\ngross_2013: Gross (US and international combined) in 2013 inflation adjusted dollars.\nroi: Return on investment, calculated as the ratio of the gross to budget.\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won’t be using them in this analysis."
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz.html#visualizing-data-with-ggplot2",
    "href": "ae/ae-01-bechdel-dataviz.html#visualizing-data-with-ggplot2",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Visualizing data with ggplot2",
    "text": "Visualizing data with ggplot2\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, \n       mapping = aes(x = budget_2013, y = gross_2013))\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you’ll often see this written as:\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013))\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point()\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNote that this results in a warning as well. What does the warning mean?"
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz.html#gross-revenue-vs.-budget",
    "href": "ae/ae-01-bechdel-dataviz.html#gross-revenue-vs.-budget",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Gross revenue vs. budget",
    "text": "Gross revenue vs. budget\n\nStep 1 - Your turn\nModify the following plot to change the color of all points to a different color.\n\n\n\n\n\n\nTip\n\n\n\nSee http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf for many color options you can use by name in R or use the hex code for a color of your choice.\n\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point(color = \"deepskyblue3\") \n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 2 - Your turn\nAdd labels for the title and x and y axes.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013))+\n  geom_point(color = \"deepskyblue3\") + \n  labs(\n    x = \"___\", \n    y = \"___\", \n    title = \"___\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 3 - Your turn\nAn aesthetic is a visual property of one of the objects in your plot. Commonly used aesthetic options are:\n\ncolor\nfill\nshape\nsize\nalpha (transparency)\n\nModify the plot below, so the color of the points is based on the variable binary.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point() + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by ___\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 4 - Your turn\nExpand on your plot from the previous step to make the size of your points based on roi.\n\n# add code here\n\n\n\nStep 5 - Your turn\nExpand on your plot from the previous step to make the transparency (alpha) of the points 0.5.\n\n# add code here\n\n\n\nStep 6 - Your turn\nExpand on your plot from the previous step by using facet_wrap to display the association between budget and gross for different values of clean_test.\n\n# add code here\n\n\n\nStep 7 - Demo\nImprove your plot from the previous step by making the x and y scales more legible.\n\n\n\n\n\n\nTip\n\n\n\nMake use of the scales package, specifically the scale_x_continuous() and scale_y_continuous() functions.\n\n\n\n# add code here\n\n\n\nStep 8 - Your turn\nExpand on your plot from the previous step by using facet_grid to display the association between budget and gross for different combinations of clean_test and binary. Comment on whether this was a useful update.\n\n# add code here\n\nAdd comment here…\n\n\nStep 9 - Demo\nWhat other improvements could we make to this plot?\n\n# add code here\n\n\n\nRender, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called “staging” the changes). Commit the changes you made using a simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz.html#return-on-investment",
    "href": "ae/ae-01-bechdel-dataviz.html#return-on-investment",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nFinally, let’s take a look at return-on-investment (ROI).\n\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\n# add code here\n\nWhat are those movies with very high returns on investment?\n\nbechdel |>\n  filter(roi > 400) |>\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  <chr>                   <dbl>       <dbl>      <dbl> <dbl> <chr>     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi < ___ to get a better view of how the medians across the categories compare.\n\n# add code here\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html",
    "href": "ae/ae-17-quantify-uncertainty-A.html",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#population-vs-sample",
    "href": "ae/ae-17-quantify-uncertainty-A.html#population-vs-sample",
    "title": "Quantifying uncertainty",
    "section": "Population vs Sample",
    "text": "Population vs Sample\n\nMotivation\nWe have data on the price per guest (ppg) for a random sample of 50 Airbnb listings in 2020 for Asheville, NC. We are going to use these data to investigate what we would of expected to pay for an Airbnb in in Asheville, NC in June 2020. Read in the data and answer the following questions.\n\nabb <- read_csv(\"data/asheville.csv\")\n\nglimpse(abb)\n\nRows: 50\nColumns: 1\n$ ppg <dbl> 48.00000, 40.00000, 99.00000, 13.00000, 55.00000, 75.00000, 74.000…"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#terminology",
    "href": "ae/ae-17-quantify-uncertainty-A.html#terminology",
    "title": "Quantifying uncertainty",
    "section": "Terminology",
    "text": "Terminology\n\nPopulation parameter - What we are interested in. Statistical measure that describes an entire population.\nSample statistic (point estimate) - describes a sample. A piece of information you get from a fraction of the population.\n\nUse these data and the tools we’ve learned in this class to come up with your best guess for what you would expect to pay (i.e. true price) for an Airbnb in Asheville, NC (June 2020).\n\nabb |> \n  summarize(ppg.mean = mean(ppg))\n\n# A tibble: 1 × 1\n  ppg.mean\n     <dbl>\n1     76.6\n\n\nDo you think your guess is correct?\nNot really\n\nIf you want to estimate a population parameter, do you prefer to report a range of values the parameter might be in, or a single value?\n\nRange of values\n\nVariability - How spread out your data are. Uncertainty.\n\nSuppose we split the class in half and ask each student their height. Then, we calculate the mean height of students on each side of the classroom. Would you expect these two means to be exactly equal, close but not equal, or wildly different?\nClose, but not equal"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#why-do-we-care",
    "href": "ae/ae-17-quantify-uncertainty-A.html#why-do-we-care",
    "title": "Quantifying uncertainty",
    "section": "Why do we care?",
    "text": "Why do we care?\nWe can quantify the variability of the sample statistics to help calculate a range of plausible values for the population parameter of interest\nBootstrapping is a statistical procedure that re samples a single data set to create many simulated samples."
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#how-do-we-do-this",
    "href": "ae/ae-17-quantify-uncertainty-A.html#how-do-we-do-this",
    "title": "Quantifying uncertainty",
    "section": "How do we do this?",
    "text": "How do we do this?\nGoal: create a distribution of sample statistics under “the same” conditions. How do we do this?\nDemo\n- Resample with replacement from our data n (50) times - Calculate the new resampled mean - Plot it - Do this entire process many many times"
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#confidence-interval",
    "href": "ae/ae-17-quantify-uncertainty-A.html#confidence-interval",
    "title": "Quantifying uncertainty",
    "section": "Confidence Interval",
    "text": "Confidence Interval\n\nWhat is it?\n\nRange of plausiable values for our population parameter… just like we wanted!\n\nExercise 1 - Airbnb\nLet’s bootstrap!\nIt’s good practice to ask yourself the following questions:\n\nWhat is my sample statistic? 76.6\nHow many draws do we need for our bootstrap sample? n number of times (50)\n\nFill in the *** from the bootstrap sample code below.\n\nset.seed(12345) \n\nboot_df <- abb |>\n  specify(response = ppg) |>\n  generate(reps = 10000, type = \"bootstrap\") |>\n  calculate(stat = \"mean\")\n\n\nTake a glimpse at boot_df. What do you see?\n\n\nglimpse(boot_df)\n\nRows: 10,000\nColumns: 2\n$ replicate <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ stat      <dbl> 81.03667, 63.22333, 81.23333, 76.11333, 81.31833, 84.60500, …\n\n\n\nPlot a histogram of boot_df. Where is it centered? Why does this make sense?\n\n\nboot_df |> \n  ggplot(\n    aes( x = stat)\n  ) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow, let’s use boot_dfto create our 95% confidence interval.\n\nboot_df |>\n  summarize(\n    lower = quantile(stat, 0.025),\n    upper = quantile(stat, 0.975)\n  )\n\n# A tibble: 1 × 2\n  lower upper\n  <dbl> <dbl>\n1  63.3  91.0\n\n\nLet’s visualize our confidence interval by adding a vertical line at each of these values. Use the code you wrote above and add two lines using geom_vline.\n\nboot_df |>\n  ggplot(\n    aes(x = stat)\n  ) + \n  geom_histogram() + \n  geom_vline(xintercept = c(63.3, 91.0)) \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#interpretation",
    "href": "ae/ae-17-quantify-uncertainty-A.html#interpretation",
    "title": "Quantifying uncertainty",
    "section": "Interpretation",
    "text": "Interpretation\nConfidence intervals - range of plausible values for our parameter of interest\nConfidence intervals are often misinterpreted as probability….\nLets explore: http://www.rossmanchance.com/ISIapplets.html\n\nHow do we interpret this?\n\nA There is a 95% probability the true mean price per night for an Airbnb in Asheville is between 63.3 and 91.0.\nB There is a 95% probability the price per night for an Airbnb in Asheville is between 63.3 and 91.0.\nC We are 95% confident the true mean price per night for Airbnbs in Asheville is between 63.3 and 91.0 $.\nD We are 95% confident the price per night for an Airbnb in Asheville is between 63.3 and 91.0."
  },
  {
    "objectID": "ae/ae-17-quantify-uncertainty-A.html#optional",
    "href": "ae/ae-17-quantify-uncertainty-A.html#optional",
    "title": "Quantifying uncertainty",
    "section": "Optional",
    "text": "Optional\nNow, create a 90% confidence interval. Report it below. Is it wider or more narrow than the 95% confidence interval?\n\n# add code here"
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html",
    "href": "ae/ae-16-spam-filter-A.html",
    "title": "Building a spam filter",
    "section": "",
    "text": "Use logistic regression to fit a model for a binary response variable\nFit a logistic regression model in R\nUse a logistic regression model for classification\n\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <int> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         <dttm> 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       <fct> no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  <int> 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       <fct> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       <fct> big, small, small, small, none, none, big, small, small, …\n\n\nThe variables we’ll use in this analysis are\n\nspam: 1 if the email is spam, 0 otherwise\nexclaim_mess: The number of exclamation points in the email message\n\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-1",
    "href": "ae/ae-16-spam-filter-A.html#exercise-1",
    "title": "Building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nDemo: Fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\n\nlog_fit <- logistic_reg() |>\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  <chr>            <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\nYour turn: How does the code above differ from previous code we’ve used to fit regression models? Compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]\nWe use logistic instead of linear regression."
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-2",
    "href": "ae/ae-16-spam-filter-A.html#exercise-2",
    "title": "Building a spam filter",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points?\n\nDemo: Answer the question using R as a calculator\n\n\n-2.27 - 0.000272 * 10\n\n[1] -2.27272\n\nexp(-2.27272) # p / (1 - p)\n\n[1] 0.1030316\n\n0.103 / 1.103\n\n[1] 0.09338169\n\n\n\nDemo: Answer the question using the predict() function.\n\nWe can use the predict function in R to produce the probability as well.\n\nep_10 <- tibble(exclaim_mess = 10)\npredict(log_fit, ep_10, type = \"prob\")\n\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    <dbl>   <dbl>\n1   0.906  0.0937"
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-3",
    "href": "ae/ae-16-spam-filter-A.html#exercise-3",
    "title": "Building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nYour turn: What are some trade offs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAnswers will vary.\n\naugment(log_fit, email) |>\n  select(spam, exclaim_mess, .pred_class) |>\n  ggplot(aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-4",
    "href": "ae/ae-16-spam-filter-A.html#exercise-4",
    "title": "Building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit a model with all variables in the dataset as predictors and recreate the visualization above for this model.\n\nlog_fit2 <- logistic_reg() |>\n  fit(spam ~ ., data = email)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\naugment(log_fit2, email) |>\n  select(spam, exclaim_mess, .pred_class) |>\n  ggplot(aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-02-viz-data-types.html",
    "href": "ae/ae-02-viz-data-types.html",
    "title": "AE 02: Visualizing penguins",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-02-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Sunday, Sep 11 at 11:59pm.\nFor all analyses, we’ll use the tidyverse and palmerpenguins packages.\nThe dataset we will visualize is called penguins. Let’s glimpse() at it."
  },
  {
    "objectID": "ae/ae-02-viz-data-types.html#single-variable",
    "href": "ae/ae-02-viz-data-types.html#single-variable",
    "title": "AE 02: Visualizing penguins",
    "section": "Single variable",
    "text": "Single variable\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the a single variable is called univariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins.\n\nMake a histogram. Set an appropriate binwidth.\n\n\n# add code here\n\n\nMake a boxplot.\n\n\n# add code here\n\n\nBased on these, determine if each of the following statements about the shape of the distribution is true or false.\n\nThe distribution of penguin weights in this sample is left skewed. FALSE\nThe distribution of penguin weights in this sample is unimodal. TRUE"
  },
  {
    "objectID": "ae/ae-02-viz-data-types.html#two-variables",
    "href": "ae/ae-02-viz-data-types.html#two-variables",
    "title": "AE 02: Visualizing penguins",
    "section": "Two variables",
    "text": "Two variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between two variables is called bivariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins by species.\n\nMake a single histogram. Set an appropriate binwidth.\n\n\n# add code here\n\n\nUse multiple histograms via faceting, one for each species. Set an appropriate binwidth, add color as you see fit, and turn off legends if not needed.\n\n\n# add code here\n\n\nUse side-by-side box plots. Add color as you see fit and turn off legends if not needed.\n\n\n# add code here\n\n\nUse density plots. Add color as you see fit.\n\n\n# add code here\n\n\nUse violin plots. Add color as you see fit and turn off legends if not needed.\n\n\n# add code here\n\n\nMake a jittered scatter plot. Add color as you see fit and turn off legends if not needed.\n\n\n# add code here\n\n\nUse beeswarm plots. Add color as you see fit and turn off legends if not needed.\n\n\n# add code here\n\n\nUse multiple geoms on a single plot. Be deliberate about the order of plotting. Change the theme and the color scale of the plot. Finally, add informative labels.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-viz-data-types.html#multiple-variables",
    "href": "ae/ae-02-viz-data-types.html#multiple-variables",
    "title": "AE 02: Visualizing penguins",
    "section": "Multiple variables",
    "text": "Multiple variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between three or more variables is called multivariate analysis.\n\n\n\nFacet the plot you created in the previous exercise by island. Adjust labels accordingly.\n\n\n# add code here\n\nBefore you continue, let’s turn off all warnings the code chunks generate and resize all figures. We’ll do this by editing the YAML."
  },
  {
    "objectID": "ae/ae-02-viz-data-types.html#visualizing-other-variables---your-turn",
    "href": "ae/ae-02-viz-data-types.html#visualizing-other-variables---your-turn",
    "title": "AE 02: Visualizing penguins",
    "section": "Visualizing other variables - Your turn!",
    "text": "Visualizing other variables - Your turn!\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\n# add code here\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n# add code here\n\nInterpretation goes here…\n\nMake another plot that uses at least three variables. At least one should be numeric and at least one categorical. In 1-2 sentences, describe what the plot shows about the relationships between the variables you plotted. Don’t forget to label your code chunk.\n\n\n# add code here\n\nInterpretation goes here…"
  },
  {
    "objectID": "ae/ae-14-moar-palmerpenguins-A.html",
    "href": "ae/ae-14-moar-palmerpenguins-A.html",
    "title": "Palmer Penguins and regression with multiple predictors",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nPlease read the following context and take a glimpse at the data set before we get started.\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass."
  },
  {
    "objectID": "ae/ae-14-moar-palmerpenguins-A.html#additive-vs.-interaction-models",
    "href": "ae/ae-14-moar-palmerpenguins-A.html#additive-vs.-interaction-models",
    "title": "Palmer Penguins and regression with multiple predictors",
    "section": "Additive vs. interaction models",
    "text": "Additive vs. interaction models\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n\n# Plot A\nggplot(penguins, \n       aes(x = flipper_length_mm, y = body_mass_g,\n           color = island)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Plot A - Interaction model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n# Plot B\nbm_fl_island_aug <- augment(bm_fl_island_fit, new_data = penguins)\nggplot(bm_fl_island_aug, \n       aes(x = flipper_length_mm, y = body_mass_g,\n           color = island)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(aes(y = .pred), method = \"lm\") +\n  labs(title = \"Plot B - Additive model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\nPlot B represent the model we fit.\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nFor every 1 millimeter the flipper is longer, we expect body mass to be higher, on average, by 44.5 grams, holding all else (the island) constant. In other words, this is true for penguins in a given island, regardless of the island.\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\npenguin_200_Dream <- tibble(\n  flipper_length_mm = 200,\n  island = \"Dream\"\n)\n\npredict(bm_fl_island_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1 4021.\n\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nThe additive model assumes the same slope between body mass and flipper length for all three islands.\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\nbm_fl_island_int_fit <- linear_reg() |>\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)\n\ntidy(bm_fl_island_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  <chr>                                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                        -5464.     431.      -12.7  2.51e-30\n2 flipper_length_mm                     48.5      2.05     23.7  1.66e-73\n3 islandDream                         3551.     969.        3.66 2.89e- 4\n4 islandTorgersen                     3218.    1680.        1.92 5.62e- 2\n5 flipper_length_mm:islandDream        -19.4      4.94     -3.93 1.03e- 4\n6 flipper_length_mm:islandTorgersen    -17.4      8.73     -1.99 4.69e- 2\n\n\n\\[\n\\widehat{body~mass} = -5464 \\\\\n+ 48.5 \\times flipper~length \\\\\n+ 3551 \\times Dream + 3218 \\times Torgersen \\\\\n- 19.4 \\times flipper~length*Dream - 17.4 \\times flipper~length*Torgersen\n\\]\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nThe interaction effect allows us to model the rate of change in estimated body mass as flipper length increases as different in the three islands.\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\npredict(bm_fl_island_int_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1 3915."
  },
  {
    "objectID": "ae/ae-14-moar-palmerpenguins-A.html#choosing-a-model",
    "href": "ae/ae-14-moar-palmerpenguins-A.html#choosing-a-model",
    "title": "Palmer Penguins and regression with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\nglance(bm_fl_island_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squ…¹ sigma stati…²   p.value    df logLik   AIC   BIC devia…³\n      <dbl>       <dbl> <dbl>   <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n1     0.774       0.772  383.    386. 7.60e-109     3 -2517. 5045. 5064.  4.95e7\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\nglance(bm_fl_island_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squ…¹ sigma stati…²   p.value    df logLik   AIC   BIC devia…³\n      <dbl>       <dbl> <dbl>   <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n1     0.786       0.783  374.    246. 4.55e-110     5 -2508. 5031. 5057.  4.70e7\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-13-palmerpenguins-A.html",
    "href": "ae/ae-13-palmerpenguins-A.html",
    "title": "Palmer Penguins and regression with a single predictor",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins’ flipper lengths and their body masses.\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nBody mass.\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\nggplot(penguins,\n       aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nCorrelation\n\nYour turn (5 minutes):\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# option 1\npenguins |>\n  summarize(r = cor(flipper_length_mm, body_mass_g, use = \"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  <dbl>\n1 0.871\n\n# option 2\npenguins |>\n  drop_na(flipper_length_mm, body_mass_g) |>\n  summarize(r = cor(flipper_length_mm, body_mass_g))\n\n# A tibble: 1 × 1\n      r\n  <dbl>\n1 0.871\n\n\n\n\nDefining, fitting, and summarizing a model\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\n\\widehat{body~mass} = \\beta_0 + \\beta_1 \\times flipper~length\n\\]\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_fl_fit <- linear_reg() |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\ntidy(bm_fl_fit)\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\n\\[\n\\widehat{body~mass} = -5781 + 49.7 \\times flipper~length\n\\]\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Penguins with 0 flipper length are expected, on average, to weigh 5,781 grams.\nSlopes: For each additional millimeter of a penguin;s flipper length, the weight of their penguin is expected to be higher, on average, by 49.7 grams.\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\nggplot(penguins,\n       aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nYour turn: What is the estimated body mass for a penguin with a flipper length of 210?\n\n\nbm_fl_fit |>\n  predict(new_data = tibble(flipper_length_mm = 210))\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1 4653.\n\n\n\nDemo: What is the estimated body mass for a penguin with a flipper length of 100?\n\nBut we shouldn’t do this prediction based on this model since 100 mm is outside of the range of the data (extrapolation).\n\nbm_fl_fit |>\n  predict(new_data = tibble(flipper_length_mm = 100))\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1 -812.\n\n\n\n\nAnother model\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nPredictor is categorical.\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\nggplot(penguins, \n       aes(x = island, y = body_mass_g)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\npenguins |>\n  group_by(island) |>\n  summarize(mean_bm = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  island    mean_bm\n  <fct>       <dbl>\n1 Biscoe      4716.\n2 Dream       3713.\n3 Torgersen   3706.\n\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\nggplot(penguins, \n       aes(x = island, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_island_fit <- linear_reg() |>\n  fit(body_mass_g ~ island, data = penguins)\n\ntidy(bm_island_fit)\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\nSlopes:\n\nPenguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nPenguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island.\n\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\nbm_island_fit |>\n  predict(new_data = tibble(island = c(\"Biscoe\", \"Dream\", \"Torgersen\")))\n\n# A tibble: 3 × 1\n  .pred\n  <dbl>\n1 4716.\n2 3713.\n3 3706."
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz-A.html",
    "href": "ae/ae-01-bechdel-dataviz-A.html",
    "title": "AE 01: Bechdel + data visualization",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this mini analysis we work with the data used in the FiveThirtyEight story titled “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”.\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz-A.html#getting-started",
    "href": "ae/ae-01-bechdel-dataviz-A.html#getting-started",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\n\nPackages\nWe start with loading the packages we’ll use: tidyverse for majority of the analysis and scales for pretty plot labels later on.\n\nlibrary(tidyverse)\nlibrary(scales)\n\n\n\nData\nThe data are stored as a CSV (comma separated values) file in the data folder of your repository. Let’s read it from there and save it as an object called bechdel.\n\nbechdel <- read_csv(\"data/bechdel.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nThis a modified version of the bechdel dataset from the previous application exercise. It’s been modified to include some new variables derived from existing variables as well as to limit the scope of the data to movies released between 1990 and 2013. For now we’re not going to discuss how these modifications were made (that’s next week’s topic) but if you’re curious, you can find the data prep script in the data/ folder of your repo. Don’t spend too long trying to decipher it, wait till next week when you have the right tools to do so!\n\n\n\n\nGet to know the data\nWe can use the glimpse function to get an overview (or “glimpse”) of the data.\n\nglimpse(bechdel)\n\nRows: 1,615\nColumns: 7\n$ title       <chr> \"21 & Over\", \"Dredd 3D\", \"12 Years a Slave\", \"2 Guns\", \"42…\n$ year        <dbl> 2013, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ gross_2013  <dbl> 67878146, 55078343, 211714070, 208105475, 190040426, 18416…\n$ budget_2013 <dbl> 13000000, 45658735, 20000000, 61000000, 40000000, 22500000…\n$ roi         <dbl> 5.221396, 1.206305, 10.585703, 3.411565, 4.751011, 0.81851…\n$ binary      <chr> \"FAIL\", \"PASS\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"P…\n$ clean_test  <chr> \"notalk\", \"ok\", \"notalk\", \"notalk\", \"men\", \"men\", \"notalk\"…\n\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset.\n\n\nVariables of interest\nThe variables we’ll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars.\ngross_2013: Gross (US and international combined) in 2013 inflation adjusted dollars.\nroi: Return on investment, calculated as the ratio of the gross to budget.\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won’t be using them in this analysis."
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz-A.html#visualizing-data-with-ggplot2",
    "href": "ae/ae-01-bechdel-dataviz-A.html#visualizing-data-with-ggplot2",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Visualizing data with ggplot2",
    "text": "Visualizing data with ggplot2\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, \n       mapping = aes(x = budget_2013, y = gross_2013))\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you’ll often see this written as:\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013))\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point()\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNote that this results in a warning as well. What does the warning mean?"
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz-A.html#gross-revenue-vs.-budget",
    "href": "ae/ae-01-bechdel-dataviz-A.html#gross-revenue-vs.-budget",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Gross revenue vs. budget",
    "text": "Gross revenue vs. budget\n\nStep 1 - Your turn\nModify the following plot to change the color of all points to a different color.\n\n\n\n\n\n\nTip\n\n\n\nSee http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf for many color options you can use by name in R or use the hex code for a color of your choice.\n\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point(color = \"coral\") \n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 2 - Your turn\nAdd labels for the title and x and y axes.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013))+\n  geom_point(color = \"deepskyblue3\") + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 3 - Your turn\nAn aesthetic is a visual property of one of the objects in your plot. Commonly used aesthetic options are:\n\ncolor\nfill\nshape\nsize\nalpha (transparency)\n\nModify the plot below, so the color of the points is based on the variable binary.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013, color = binary)) +\n  geom_point() + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 4 - Your turn\nExpand on your plot from the previous step to make the size of your points based on roi.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point() + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 5 - Your turn\nExpand on your plot from the previous step to make the transparency (alpha) of the points 0.5.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 6 - Your turn\nExpand on your plot from the previous step by using facet_wrap to display the association between budget and gross for different values of clean_test.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  facet_wrap(~clean_test) +\n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 7 - Demo\nImprove your plot from the previous step by making the x and y scales more legible.\n\n\n\n\n\n\nTip\n\n\n\nMake use of the scales package, specifically the scale_x_continuous() and scale_y_continuous() functions.\n\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  facet_wrap(~clean_test) +\n  scale_x_continuous(labels = label_dollar(scale = 1/1000000)) +\n  scale_y_continuous(labels = label_dollar(scale = 1/1000000)) +\n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nStep 8 - Your turn\nExpand on your plot from the previous step by using facet_grid to display the association between budget and gross for different combinations of clean_test and binary. Comment on whether this was a useful update.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  facet_grid(binary~clean_test) +\n  scale_x_continuous(labels = label_dollar(scale = 1/1000000)) +\n  scale_y_continuous(labels = label_dollar(scale = 1/1000000)) +\n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis was not a useful update as one of the levels of clean_test maps directly to one of the levels of binary.\n\n\nStep 9 - Demo\nWhat other improvements could we make to this plot?\n\n# Answers may vary\n\n\n\nRender, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called “staging” the changes). Commit the changes you made using a simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-01-bechdel-dataviz-A.html#return-on-investment",
    "href": "ae/ae-01-bechdel-dataviz-A.html#return-on-investment",
    "title": "AE 01: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nFinally, let’s take a look at return-on-investment (ROI).\n\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\nggplot(bechdel, \n       aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n    )\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel |>\n  filter(roi > 400) |>\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  <chr>                   <dbl>       <dbl>      <dbl> <dbl> <chr>     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi < ___ to get a better view of how the medians across the categories compare.\n\nggplot(bechdel, \n       aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n    ) +\n  coord_cartesian(ylim = c(0, 18))\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?"
  },
  {
    "objectID": "ae/ae-08-dse-misrepresentation-A.html",
    "href": "ae/ae-08-dse-misrepresentation-A.html",
    "title": "AE 08: Data science ethics - Misrepresentation",
    "section": "",
    "text": "Packages\n\nlibrary(tidyverse)\n\n\n\nPart 1 - People’s Poll\nGB News tweeted the following on Aug 26, 2022.\n\n\n\n\n\n\nQuestion: What is wrong with the visualization above?\n\nThe bars are not drawn to scale, hence are misleading\n\nYour turn (5 minutes): The data from this poll are at data/gbpoll.csv. First, load the data and confirm the number of responses match those mentioned in the tweet.\n\ngbpoll <- read_csv(\"data/gbpoll.csv\")\n\nRows: 1235 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): party\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnrow(gbpoll)\n\n[1] 1235\n\n\nThen, confirm that the proportions of intended votes match those mentioned in the tweet.\n\ngbpoll |>\n  count(party) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 5 × 3\n  party                 n   prop\n  <chr>             <int>  <dbl>\n1 Conservative        321 0.260 \n2 Labour              494 0.4   \n3 Liberal Democrats   136 0.110 \n4 Other               210 0.170 \n5 SNP                  74 0.0599\n\n\nDemo: Recreate the visualization from the tweet. You do not need to worry about matching the colors precisely and your bars should be correctly scaled.\n\ngbpoll |>\n  count(party) |>\n  mutate(\n    prop = round(n / sum(n), 2),\n    prop_char = paste0(prop*100, \"%\")\n    ) |>\n  filter(party != \"Other\") |>\n  mutate(party = fct_reorder(party, prop)) |>\n  ggplot(\n    aes(\n      y = party, \n      x = prop, \n      fill = party\n    )\n  ) +\n  geom_col(show.legend = FALSE) +\n  scale_y_discrete(drop = TRUE) +\n  theme_void() +\n  geom_text(\n    aes(label = str_wrap(party, 10)),\n    x = 0.005,\n    hjust = 0,\n    color = \"white\",\n    fontface = \"bold\"\n    ) +\n  geom_text(\n    aes(label = prop_char),\n    nudge_x = -0.005,\n    hjust = 1,\n    color = \"white\",\n    fontface = \"bold\"\n    ) +\n  scale_fill_manual(values = c(\"#D0C123\", \"#F99C1A\",\"#00AEEF\", \"#E4013B\")) +\n  labs(\n    title = str_to_upper(\"If there were to be a general election tomorrow,\\nwhich party would you vote for?\")\n  )\n\n\n\n\n\n\n\nYour turn (10 minutes): Improve the visualization. State the improvements you made and why you made them. Discuss how these improvements help make the plot less misleading.\n\ngbpoll |>\n  count(party) |>\n  mutate(\n    prop = round(n / sum(n), 2),\n    prop_char = paste0(prop*100, \"%\")\n    ) |>\n  mutate(party = fct_reorder(party, prop)) |>\n  ggplot(\n    aes(\n      y = party, \n      x = prop, \n      fill = party\n    )\n  ) +\n  geom_col(show.legend = FALSE) +\n  scale_y_discrete(drop = TRUE) +\n  theme_void() +\n  geom_text(\n    aes(label = str_wrap(party, 10)),\n    x = 0.005,\n    hjust = 0,\n    color = \"white\",\n    fontface = \"bold\"\n    ) +\n  geom_text(\n    aes(label = prop_char),\n    nudge_x = -0.005,\n    hjust = 1,\n    color = \"white\",\n    fontface = \"bold\"\n    ) +\n  scale_fill_viridis_d(option = \"E\", end = 0.8) +\n  labs(\n    title = \"If there were to be a general election tomorrow,\\nwhich party would you vote for?\",\n    caption = \"Source: GBNews Poll, Aug 26, 2022\"\n  )\n\n\n\n\n\n\n\nPart 2 - Private sector\nThe following chart was shared by @GraphCrimes on Twitter on September 3, 2022.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis exercise has been moved to HW 3. Suggested answers will be released with HW 3 answers.\n\n\n\nQuestion: What is misleading about this graph?\nYour turn (6 minutes): If you needed to recreate this plot, with improvements to avoid its misleading pitfalls, what data do you need? How many variables? How many observations? Can you find the data online? Try looking for it for at least 3 minutes with a partner.\nDemo: Load the data for this survey from data/survation.csv. First confirm that the data match the percentages from the visualization. Then, recreate the visualization, and improve it. Does the improved visualization look different than the original? Does it send a different message at a first glance?"
  },
  {
    "objectID": "ae/ae-18-hypothesis-testing-A.html",
    "href": "ae/ae-18-hypothesis-testing-A.html",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "An article in the The Asheville Citizen-Times published in the summer of 2020 claims that the average price per guest (ppg) for properties in Asheville is $60 on Airbnb. To evaluate their claim we will use a dataset on 50 randomly selected Asheville Airbnb listings in June 2020. These data can be found in data/asheville.csv.\nLet’s load the packages we’ll use first.\nAnd then the data."
  },
  {
    "objectID": "ae/ae-18-hypothesis-testing-A.html#generate",
    "href": "ae/ae-18-hypothesis-testing-A.html#generate",
    "title": "Quantifying uncertainty",
    "section": "Generate",
    "text": "Generate\nWe’ll start by generating the null distribution.\n\nDemo: Generate the null distribution?\n\n\nset.seed(4321)\n\n\nnull_dist <- abb |>\n  specify(response = ppg) |>\n  hypothesize(null = \"point\", mu = 60) |>\n  generate(reps = 100, type = \"bootstrap\") |>\n  calculate(stat = \"mean\")\n\n\nYour turn: Take a look at null_dist. What does each element in this distribution represent?\n\n\nnull_dist\n\nResponse: ppg (numeric)\nNull Hypothesis: point\n# A tibble: 100 × 2\n   replicate  stat\n       <int> <dbl>\n 1         1  63.7\n 2         2  50.7\n 3         3  74.3\n 4         4  56.7\n 5         5  66.1\n 6         6  50.5\n 7         7  52.8\n 8         8  62.4\n 9         9  55.9\n10        10  58.7\n# … with 90 more rows"
  },
  {
    "objectID": "ae/ae-18-hypothesis-testing-A.html#visualize",
    "href": "ae/ae-18-hypothesis-testing-A.html#visualize",
    "title": "Quantifying uncertainty",
    "section": "Visualize",
    "text": "Visualize\n\nQuestion: Before you visualize the distribution of null_dist – at what value would you expect this distribution to be centered? Why?\n\nAt 60, since we created this distribution assuming \\(\\mu = 60\\).\n\nDemo: Create an appropriate visualization for your null distribution. Does the center of the distribution match what you guessed in the previous question?\n\n\nggplot(null_dist, aes(x = stat)) +\n  geom_dotplot()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\nDemo: Now, add a vertical red line on your null distribution that represents your sample statistic.\n\n\nggplot(null_dist, aes(x = stat)) +\n  geom_dotplot() +\n  geom_vline(xintercept = 76.6, color = \"red\")\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\nQuestion: Based on the position of this line, does your observed sample mean appear to be an unusual observation under the assumption of the null hypothesis?\n\nYes, it’s pretty far from the center."
  },
  {
    "objectID": "ae/ae-19-inference-overview-A.html",
    "href": "ae/ae-19-inference-overview-A.html",
    "title": "Inference overview",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\n\n\nrc <- read_csv(\"data/roller_coasters.csv\")\n\nIn this application exercise, we will be looking at a roller coaster and amusement park database by Duane Marden.1 This database records multiple features of roller coasters. For the purpose of this activity, we will work with a random sample of 157 roller coasters.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nage_group\n1: Older (Built between 1900-1979)\n2: Recent (1980-1999)\n3: Newest (2000-current)\n\n\ncoaster\nName of the roller coaster\n\n\npark\nName of the park where the roller coaster is located\n\n\ncity\nCity where the roller coaster is located\n\n\nstate\nState where the roller coaster is located\n\n\ntype\nMaterial of track (Steel or Wooden)\n\n\ndesign\nHow a passenger is positioned in the roller coaster:\nFlying: a roller coaster ridden while parallel with the track.\nInverted: a roller coaster which uses trains traveling beneath, rather than on top of, the track. Unlike a suspended roller coaster, an inverted roller coaster’s trains are rigidly attached to the track.\nSit Down: a traditional roller coaster ridden while sitting down.\nSuspended: a roller coaster using trains which travel beneath the track and pivot on a swinging arm from side to side, exaggerating the track’s banks and turns.\nStand Up: a coaster ridden while standing up instead of sitting down.\nPipeline: a coaster where riders are positioned between the rails instead of above or below.\nWing: a coaster where pairs of riders sit on either side of a roller coaster track in which nothing is above or below the riders.\n4th Dimension: a coaster where the cars have the ability to rotate on an axis perpendicular to that of the track.\n\n\nyear_opened\nYear when roller coaster opened\n\n\ntop_speed\nMaximum speed of roller coaster (mph)\n\n\nmax_height\nHighest point of roller coaster (ft)\n\n\ndrop\nLength of largest gap between high and low points of roller coaster (ft)\n\n\nlength\nLength of roller coaster track (ft)\n\n\nduration\nTime length of roller coaster ride (sec)\n\n\ninversions\nWhether or not roller coaster flips passengers at any point (Yes or No)\n\n\nnum_of_inversions\nNumber of times roller coaster flips passengers\n\n\n\n\nResearch question 1\n\nIs the true proportion of steel roller coasters opened before 1970 different than those opened after 1970?\n\n\nDemo: Create a new variable called opened_recently that has a response of yes if the roller coaster was opened after 1970, and no if the roller coaster was opened during or before 1970. Save this new factor variable in the rc data set. Additionally, make type a factor variable.\n\n\nrc <- rc |>\n  mutate(\n    opened_recently = if_else(year_opened > 1970, \"yes\" , \"no\"), \n    opened_recently = as.factor(opened_recently),\n    type = as.factor(type)\n  ) \n\n\nYour turn: Based on the research question, which of the following is the appropriate null hypothesis?\n\n\\(H_0\\): \\(\\mu = 0.5\\)\n\\(H_0\\): \\(p > 0.5\\)\n\\(H_0\\): \\(\\mu_1 - \\mu_2 = 0\\)\n\\(H_0\\): \\(p_1 - p_2 = 0\\)\n\n\nThe answer is (d).\n\nDemo: Write out the appropriate alternative hypothesis in both words and notation.\n\n\\(H_A\\): \\(p_1 - p_2 \\ne 0\\)\n\nDemo: Calculate the observed statistic.\n\n\npoint_estimate <- rc |>\n  specify(type ~ opened_recently, success = \"Steel\") |>\n  calculate(stat = \"diff in props\", order = c(\"yes\", \"no\"))\n\n\nDemo: How do we create a null distribution for this hypothesis test? Write out the steps below.\n\nShuffle responses into one pile.\nRedistribute data into two new piles of size n1 and n2.\nCalculate new difference in proportions.\nRepeat steps 1-3 many times to create the null distribution.\n\nDemo: Create the null distribution with 1,000 repeated samples.\n\n\nset.seed(101821)\n\nnull_dist <- rc %>%\n  specify(type ~ opened_recently, success = \"Steel\") %>%\n  hypothesize(null = \"independence\") %>%\n  generate(1000, type = \"permute\") %>%\n  calculate(stat = \"diff in props\", order = c(\"yes\", \"no\"))\n\n\nDemo: Visualize the null distribution and shade in the area used to calculate the p-value.\n\n\nvisualize(null_dist) +\n shade_p_value(obs_stat = point_estimate, direction = \"two sided\")\n\n\n\n\n\nYour turn: Calculate p-value. Then use the p-value to make your conclusion using a significance level of 0.1 and write out an appropriate conclusion below. Recall that the conclusion has 3 components.\n\nHow the p-value compares to the significance level.\nThe decision you make with respect to the hypotheses (reject \\(H_0\\) /fail to reject \\(H_0\\))\nThe conclusion in the context of the alternative hypothesis.\n\n\nSince the p-value is smaller than 10%, we reject the null hypothesis in favor of the alternative hypothesis. The data provide convincing evidence that the proportion of steel roller coasters opened before 1970 is different than those opened after 1970.\n\nnull_dist |>\n  get_p_value(obs_stat = point_estimate, direction = \"two sided\")\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information.\n\n\n# A tibble: 1 × 1\n  p_value\n    <dbl>\n1       0\n\n\n\n\nResearch question 2\n\nWe want to investigate the relationship between how fast a roller coaster goes, and how long a roller coaster lasts. Specifically, we are interested in how well the duration of a roller coaster explains or predicts how fast it is.\n\n\nQuestion: Based on this research question, which two variables should we use from our data set? Which is our response?\n\ntop_speed and duration.\n\nDemo: Fit a model predicting top_speed from duration and display the tidy summary output.\n\n\nspeed_fit <- linear_reg() |>\n  fit(top_speed ~ duration, data = rc) \n\ntidy(speed_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  52.0       4.08       12.8  3.99e-24\n2 duration      0.0560    0.0305      1.83 6.92e- 2\n\n\n\nYour turn: Use your model to estimate the top speed of a roller coaster if their duration is 155 minutes\n\n\nduration_155 <- tibble(duration = 155)\n\npredict(speed_fit, new_data = duration_155)\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1  60.7\n\n\n\nDemo: Write out the estimated model in proper notation and interpret the slope coefficient\n\n\\(\\widehat{top~speed} = 52 + 0.056 \\times duration\\)\nFor each additional second the ride is longer, the predicted top speed of the roller coaster is higher by 0.057 miles per hour, on average.\n\nQuestion: The slope you calculated and interpeted above is a sample statistic (an estimate). It is possible (and quite likely) that the true slope of the relationship between durations and top speeds of all roller coasters is not exactly equal to this value. How can we quantify the uncertainty around this estimate?\n\nUse a confidence interval.\n\nYour turn: Describe how we can construct a bootstrap distribution for the slope of the model predicting top_speed from duration.\n\nTake a bootstrap sample of pairs of top_speed and duration.\nFit a model predicting top_speed from duration using the bootstrap sample and record the value of the slope.\nRepeat steps 1 and 2 many times.\n\nDemo: Now, construct this bootstrap distribution.\n\n\nset.seed(12345)\n\nboot_df_slope <- rc |>\n  specify(top_speed ~ duration) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"slope\")\n\nWarning: Removed 34 rows containing missing values.\n\n\n\nDemo: Create a 90% confidence interval by filling in the code below.\n\n\nboot_df_slope |>\n  summarize(\n    lower = quantile(stat, 0.05),\n    upper = quantile(stat, 0.95)\n  )\n\n# A tibble: 1 × 2\n    lower upper\n    <dbl> <dbl>\n1 -0.0195 0.132\n\n\n\nDemo: Interpret the confidence interval in the context of the problem.\n\nWe are 90% confident that, for each additional second the ride is longer, the predicted top speed of the roller coaster is lower by -0.0195 to higher by 0.132 miles per hour, on average.\n\nDemo: Now fit a model predicting log of top_speed from duration.\n\n\nrc <- rc |>\n  mutate(top_speed_log = log(top_speed))\n\nspeed_log_fit <- linear_reg() |>\n  fit(top_speed_log ~ duration, data = rc) \n\ntidy(speed_log_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  3.92     0.0686       57.1  2.15e-89\n2 duration     0.00104  0.000514      2.03 4.48e- 2\n\n\n\nDemo: Write the estimated model and interpret the slope.\n\n\\(\\widehat{log(top~speed)} = 3.92 + 0.00104 \\times duration\\)\nRecall that to interpret the slope value we need to exponentiate it!\nWhy?\n\\[\n\\begin{aligned}\nlog(y~for~x + 1) - log(y~for~x) &= \\beta_1 \\\\\nlog\\Big(\\frac{y~for~x + 1}{y~for~x}\\Big) &= \\beta_1 \\\\\ne^{log\\Big(\\frac{y~for~x + 1}{y~for~x}\\Big)} &= e^\\beta_1 \\\\\n\\frac{y~for~x + 1}{y~for~x} &= e^\\beta_1\n\\end{aligned}\n\\]\nThis implies that our explanatory variable has a multiplicative relationship with our response variable.\nFor each additional second the ride is longer, the predicted top speed of the roller coaster is higher by a factor of \\(e^0.00104 = 1.001\\), on average.\n\n\nResearch question 3\n\nWe are also interested in investigating if roller coasters opened after 1970 are faster than those opened before. For this question, we want to estimate the difference.\n\n\nQuestion: How is this different from question one? Should we make a confidence interval or conduct a hypothesis test?\n\nWe are interested in estimating the difference. This suggests we should make a confidence interval.\n\nDemo: Now, use bootstrapping to estimate the difference between the true speeds of roller coasters before and after 1970.\n\n\nset.seed(12345)\n\nboot_df <- rc |>\n  specify(top_speed ~ opened_recently) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"diff in means\", order = c(\"yes\", \"no\"))\n\nWarning: Removed 11 rows containing missing values.\n\n\n\nYour turn: Create a 99% confidence interval and interpret it in the context of the data and the research question.\n\n\nboot_df |>\n  summarize(\n    lower = quantile(stat, 0.005),\n    upper = quantile(stat, 0.995)\n  )\n\n# A tibble: 1 × 2\n  lower upper\n  <dbl> <dbl>\n1  8.88  23.3\n\n\nWe are 99% confident that the true mean speed between roller coasters after 1970 are 8.88 to 23.3 mph higher than the true mean speed for roller coasters before 1970.\n\n\nDiscussion\n\nBrainstorm the differences between generating new samples via bootstrapping and permuting. Write down the key differences below. Hint: Think back to the different sampling techniques between research question 1 and research questions 2 and 3.\n\n\n\n\n\n\nFootnotes\n\n\nRoller Coaster DataBase, UltimateRollerCoaster.com, ESTEEM: Enhancing Statistics Teachers Education with E-Modules.↩︎"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html",
    "href": "ae/ae-20-effective-dataviz-A.html",
    "title": "Trends instructional staff employees in universities",
    "section": "",
    "text": "The American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains the following image. What trends are apparent in this visualization?"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#packages",
    "href": "ae/ae-20-effective-dataviz-A.html#packages",
    "title": "Trends instructional staff employees in universities",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggthemes)"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#data",
    "href": "ae/ae-20-effective-dataviz-A.html#data",
    "title": "Trends instructional staff employees in universities",
    "section": "Data",
    "text": "Data\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n\nstaff <- read_csv(\"data/instructional-staff.csv\")\nstaff\n\n# A tibble: 5 × 12\n  facult…¹ `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Full-Ti…   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8\n2 Full-Ti…   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6\n3 Full-Ti…   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1\n4 Part-Ti…   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1\n5 Graduat…   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4\n# … with 1 more variable: `2011` <dbl>, and abbreviated variable name\n#   ¹​faculty_type"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#recreate",
    "href": "ae/ae-20-effective-dataviz-A.html#recreate",
    "title": "Trends instructional staff employees in universities",
    "section": "Recreate",
    "text": "Recreate\n\nYour turn (10 minutes): Recreate the visualization above. Try to match as many of the elements as possible. Hint: You might need to reshape your data first.\n\n\nstaff_long <- staff |>\n  pivot_longer(cols = -faculty_type, names_to = \"year\", \n               values_to = \"percentage\") |>\n  mutate(\n    percentage = as.numeric(percentage),\n    faculty_type = fct_relevel(faculty_type,\n                               \"Full-Time Tenured Faculty\",\n                               \"Full-Time Tenure-Track Faculty\",\n                               \"Full-Time Non-Tenure-Track Faculty\",\n                               \"Part-Time Faculty\",\n                               \"Graduate Student Employees\")\n    )\n\n\nstaff_long |>\n  ggplot(aes(x = str_wrap(faculty_type, 20), \n             y = percentage, \n             fill = year)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(breaks = seq(5, 45, 5), limits = c(0, 45)) +\n  labs(\n    x = NULL, \n    y = \"Percent of Total Instructional Staff\", \n    fill = NULL,\n    title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n    subtitle = \"All Institutions, National Totals\",\n    caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n    ) +\n  theme(\n    legend.position = c(0.4, 0.93),\n    legend.direction = \"horizontal\",\n    legend.key.size = unit(0.2, \"cm\"),\n    legend.key.height = unit(0.1, \"cm\"),\n    legend.text.align = 0,\n    legend.background = element_rect(color = \"black\", linewidth = 0.2),\n    legend.text = element_text(size = 7),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    plot.caption = element_text(size = 8, hjust = 0)\n    ) +\n  guides(fill = guide_legend(nrow = 1))"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#represent-percentages-as-parts-of-a-whole",
    "href": "ae/ae-20-effective-dataviz-A.html#represent-percentages-as-parts-of-a-whole",
    "title": "Trends instructional staff employees in universities",
    "section": "Represent percentages as parts of a whole",
    "text": "Represent percentages as parts of a whole\n\nDemo: Recreate the previous visualization where the percentages are represented as parts of a whole.\n\n\nstaff_long |>\n  ggplot(aes(x = str_wrap(faculty_type, 20), \n             y = percentage, \n             fill = fct_rev(year))) +\n  geom_col(position = \"fill\", color = \"white\", linewidth = 0.2) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       fill = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  theme(\n    legend.text.align = 0,\n    legend.background = element_rect(color = \"black\", size = 0.2),\n    legend.text = element_text(size = 7),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    plot.caption = element_text(size = 8, hjust = 0)\n  )\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead."
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#place-time-on-x-axis",
    "href": "ae/ae-20-effective-dataviz-A.html#place-time-on-x-axis",
    "title": "Trends instructional staff employees in universities",
    "section": "Place time on x-axis",
    "text": "Place time on x-axis\n\nDemo: Convert the visualization to a line plot with time on the x-axis.\n\n\nstaff_long |>\n  ggplot(aes(x = year, \n             y = percentage, \n             color = str_wrap(faculty_type, 20), \n             group = str_wrap(faculty_type, 20))) +\n  geom_line(linewidth = 1) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       color = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  scale_y_continuous(labels = label_percent(accuracy = 1, scale = 1)) +\n  theme(\n    legend.key.height = unit(1.5, \"cm\"),\n    plot.caption = element_text(size = 8, hjust = 0)\n  )"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#pay-attention-to-variable-types",
    "href": "ae/ae-20-effective-dataviz-A.html#pay-attention-to-variable-types",
    "title": "Trends instructional staff employees in universities",
    "section": "Pay attention to variable types",
    "text": "Pay attention to variable types\n\nQuestion: What is wrong with the x-axis of the plot above? How can you fix it?\n\nTime is represented as a character string (equally spaces between levels) instead of on a continuous scale (with spacing indicating numbers of years between ticks.\n\nYour turn: Implement the fix for the x-axis of the plot.\n\n\nstaff_long <- staff_long |>\n  mutate(year = as.numeric(year))\n\nggplot(staff_long,\n       aes(x = year, \n           y = percentage, \n           color = str_wrap(faculty_type, 20), \n           group = str_wrap(faculty_type, 20))) +\n  geom_line(linewidth = 1) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       color = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  scale_y_continuous(labels = label_percent(accuracy = 1, scale = 1)) +\n  theme(\n    legend.key.height = unit(1.5, \"cm\"),\n    plot.caption = element_text(size = 8, hjust = 0)\n  )"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#use-an-accessible-color-scale",
    "href": "ae/ae-20-effective-dataviz-A.html#use-an-accessible-color-scale",
    "title": "Trends instructional staff employees in universities",
    "section": "Use an accessible color scale",
    "text": "Use an accessible color scale\nQuestion: What do we mean by an accessible color scale? What types of color vision deficiencies are there?\n\nDemo: What does the plot look like to people with various color vision deficiencies?\nDemo: Remake the plot with an accessible color scale.\n\n\nggplot(staff_long,\n       aes(x = year, \n           y = percentage, \n             color = str_wrap(faculty_type, 20), \n             group = str_wrap(faculty_type, 20))) +\n  geom_line(linewidth = 1) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       color = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  scale_y_continuous(labels = label_percent(accuracy = 1, scale = 1)) +\n  theme(\n    legend.key.height = unit(1.5, \"cm\"),\n    plot.caption = element_text(size = 8, hjust = 0)\n  ) +\n  scale_color_colorblind() # from ggthemes package"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#use-direct-labeling",
    "href": "ae/ae-20-effective-dataviz-A.html#use-direct-labeling",
    "title": "Trends instructional staff employees in universities",
    "section": "Use direct labeling",
    "text": "Use direct labeling\n\nDemo: Remove the legend and add labels for each line at the end of the line (where x is the max(x) recorded).\n\n\nstaff_long |>\n  ggplot(aes(x = year, \n             y = percentage, \n             color = faculty_type, \n             group = faculty_type)) +\n  geom_line(linewidth = 1, show.legend = FALSE) +\n  geom_text(\n    data = staff_long |> filter(year == max(year)),\n    aes(x = year + 1, y = percentage, label = faculty_type),\n    hjust = \"left\", show.legend = FALSE, size = 4\n  ) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       color = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  scale_y_continuous(labels = label_percent(accuracy = 1, scale = 1)) +\n  theme(    \n    plot.caption = element_text(size = 8, hjust = 0),\n    plot.margin = margin(0.1, 2.5, 0.1, 0.1, unit = \"in\")\n    ) +\n  coord_cartesian(clip = \"off\") +\n  scale_color_colorblind()"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#use-color-to-draw-attention",
    "href": "ae/ae-20-effective-dataviz-A.html#use-color-to-draw-attention",
    "title": "Trends instructional staff employees in universities",
    "section": "Use color to draw attention",
    "text": "Use color to draw attention\n\nDemo: Redo the line plot where Part-time Faculty is red and the rest are gray.\n\n\nstaff_long <- staff_long |>\n  mutate(faculty_type_color = if_else(faculty_type == \"Part-Time Faculty\", \"firebrick3\", \"gray40\"))\n\n\nstaff_long |>\n  ggplot(aes(x = year, \n             y = percentage, \n             color = faculty_type_color, group = faculty_type)) +\n  geom_line(linewidth = 1, show.legend = FALSE) +\n  geom_text(\n    data = staff_long |> filter(year == max(year)),\n    aes(x = year + 1, y = percentage, label = faculty_type),\n    hjust = \"left\", show.legend = FALSE, size = 4\n  ) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       color = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  scale_y_continuous(labels = label_percent(accuracy = 1, scale = 1)) +\n  scale_color_identity() +\n  theme(\n    plot.caption = element_text(size = 8, hjust = 0),\n    plot.margin = margin(0.1, 2.5, 0.1, 0.1, unit = \"in\")\n    ) +\n  coord_cartesian(clip = \"off\")"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#pick-a-purpose",
    "href": "ae/ae-20-effective-dataviz-A.html#pick-a-purpose",
    "title": "Trends instructional staff employees in universities",
    "section": "Pick a purpose",
    "text": "Pick a purpose\n\np <- staff_long |>\n  ggplot(aes(x = year, \n             y = percentage, \n             color = faculty_type_color, group = faculty_type)) +\n  geom_line(linewidth = 1, show.legend = FALSE) +\n  labs(x = NULL, \n       y = \"Percent of Total Instructional Staff\", \n       color = NULL,\n       title = \"Trends in Instructional Staff Employment Status, 1975-2011\",\n       subtitle = \"All Institutions, National Totals\",\n       caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\"\n       ) +\n  scale_y_continuous(labels = label_percent(accuracy = 1, scale = 1)) +\n  scale_color_identity() +\n  theme(\n    plot.caption = element_text(size = 8, hjust = 0),\n    plot.margin = margin(0.1, 0.6, 0.1, 0.1, unit = \"in\")\n    ) +\n  coord_cartesian(clip = \"off\") +\n    annotate(\n    geom = \"text\",\n    x = 2012, y = 41, label = \"Part-Time\\nFaculty\", \n    color = \"firebrick3\", hjust = \"left\", size = 5\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 2012, y = 13.5, label = \"Other\\nFaculty\", \n    color = \"gray40\", hjust = \"left\", size = 5\n  ) +\n  annotate(\n    geom = \"segment\",\n    x = 2011.5, xend = 2011.5,\n    y = 7, yend = 20,\n    color = \"gray40\", linetype = \"dotted\"\n  )"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#use-labels-to-communicate-the-message",
    "href": "ae/ae-20-effective-dataviz-A.html#use-labels-to-communicate-the-message",
    "title": "Trends instructional staff employees in universities",
    "section": "Use labels to communicate the message",
    "text": "Use labels to communicate the message\n\np + \n  labs(\n    title = \"Instruction by part-time faculty on a steady increase\",\n    subtitle = \"Trends in Instructional Staff Employment Status, 1975-2011\\nAll Institutions, National Totals\",\n    caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\",\n    y = \"Percent of Total Instructional Staff\", \n    x = NULL\n)"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#simplify",
    "href": "ae/ae-20-effective-dataviz-A.html#simplify",
    "title": "Trends instructional staff employees in universities",
    "section": "Simplify",
    "text": "Simplify\n\np + \n  labs(\n    title = \"Instruction by part-time faculty on a steady increase\",\n    subtitle = \"Trends in Instructional Staff Employment Status, 1975-2011\\nAll Institutions, National Totals\",\n    caption = \"Source: US Department of Education, IPEDS Fall Staff Survey\",\n    y = \"Percent of Total Instructional Staff\", \n    x = NULL\n) +\n  theme(\n    panel.grid.minor = element_blank()\n    )"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz-A.html#summary",
    "href": "ae/ae-20-effective-dataviz-A.html#summary",
    "title": "Trends instructional staff employees in universities",
    "section": "Summary",
    "text": "Summary\n\nRepresent percentages as parts of a whole\nPlace variables representing time on the x-axis when possible\nPay attention to data types, e.g., represent time as time on a continuous scale, not years as levels of a categorical variable\nPrefer direct labeling over legends\nUse accessible colors\nUse color to draw attention\nPick a purpose and label, color, annotate for that purpose\nCommunicate your main message directly in the plot labels\nSimplify before you call it done (a.k.a. “Before you leave the house, look in the mirror and take one thing off”)"
  },
  {
    "objectID": "ae/ae-12-modelling-fish-A.html",
    "href": "ae/ae-12-modelling-fish-A.html",
    "title": "Modelling fish",
    "section": "",
    "text": "For this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish <- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\n\nvariable\ndescription\n\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\n\nVisualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish.\n\nDemo: Create an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n\n\n\n\nYour turn (5 minutes):\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\nStart from the bottom and go up Identify the first and last point and draw a line through most the others.\nNow, let R draw the line for you. Refer to the documentation at https://ggplot2.tidyverse.org/reference/geom_smooth.html. Specifically, refer to the method section.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. lengths of fish\",\n    x = \"Head-to-tail lentgh (cm)\",\n    y = \"Weight of fish (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nWhat types of questions can this plot help answer?\nIs there a relationship between fish heights and weights of fish?\n\nYour turn (3 minutes):\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\nAt 10 cm, we estimate a weight of 375 grams. At 15 cm, we estimate a weight of 600 grams At 20 cm, we estimate a weight of 975 grams. 20 cm would be considered extrapolation.\nWhat is a residual?\nDifference between predicted and observed.\n\n\n\n\nModel fitting\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\nfish_hw_fit <- linear_reg() |>\n  fit(weight ~ height, data = fish)\n\nfish_hw_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = weight ~ height, data = data)\n\nCoefficients:\n(Intercept)       height  \n    -288.42        60.92  \n\n\n\nYour turn (3 minutes): Predict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\nx <- c(10, 15, 20)\n-288 + 60.92 * x\n\n[1] 321.2 625.8 930.4\n\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\nfish_hw_aug <- augment(fish_hw_fit$fit)\n\nggplot(fish_hw_aug, aes(x = height, y = weight)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +  \n  geom_segment(aes(xend = height, yend = .fitted), color = \"gray\") +  \n  geom_point(aes(y = .fitted), shape = \"circle open\") + \n  theme_minimal() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    subtitle = \"Residuals\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nModel summary\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\nfish_hw_tidy <- tidy(fish_hw_fit)\n\n# intercept\nfish_hw_tidy |>\n  filter(term == \"(Intercept)\") |>\n  pull(estimate)\n\n[1] -288.4152\n\n# slope\nfish_hw_tidy |>\n  filter(term == \"height\") |>\n  pull(estimate)\n\n[1] 60.91587\n\n\n\nDemo: Write out your model using mathematical notation.\n\n\\(\\widehat{weight} = 1.96 + 0.233 \\times height\\)\n\n\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nYour turn (5 minutes):\n\nWhat is correlation? What are values correlation can take?\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between heights and weights of fish?\n\n\nfish |>\n  summarize(r = cor(height, weight))\n\n# A tibble: 1 × 1\n      r\n  <dbl>\n1 0.954\n\n\n\n\nAdding a third variable\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\nggplot(fish, \n       aes(x = height, y = weight, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nFitting other models\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\nggplot(fish, \n       aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "ae/ae-10-chronicle-A.html",
    "href": "ae/ae-10-chronicle-A.html",
    "title": "Opinion articles in The Chronicle",
    "section": "",
    "text": "See chronicle-scrape.R for suggested scraping code."
  },
  {
    "objectID": "ae/ae-10-chronicle-A.html#part-2---data-analysis",
    "href": "ae/ae-10-chronicle-A.html#part-2---data-analysis",
    "title": "Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\nYour turn (1 minute): Load the data you saved into the data folder and name it chronicle.\n\n\nchronicle <- read_csv(\"data/chronicle.csv\")\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\nchronicle |>\n  count(author, sort = TRUE)\n\n# A tibble: 67 × 2\n   author                        n\n   <chr>                     <int>\n 1 Advikaa Anand                 3\n 2 Anthony Salgado               3\n 3 Billy Cao                     3\n 4 Community Editorial Board     3\n 5 Heidi Smith                   3\n 6 Linda Cao                     3\n 7 Luke A. Powery                3\n 8 Monday Monday                 3\n 9 Sonia Green                   3\n10 Valerie Tan                   3\n# … with 57 more rows\n\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\nchronicle |>\n  count(date) |>\n  ggplot(aes(x = date, y = n, group = 1)) +\n  geom_line()\n\n\n\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\n\nchronicle |>\n  mutate(\n    title = str_to_lower(title),\n    climate = if_else(str_detect(title, \"climate\"), \"mentioned\", \"not mentioned\")\n    ) |>\n  count(climate) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  <chr>         <int> <dbl>\n1 mentioned         3  0.03\n2 not mentioned    97  0.97\n\n\n\nYour turn (5 minutes): What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\nchronicle |>\n  mutate(\n    title = str_to_lower(title),\n    abstract = str_to_lower(abstract),\n    climate = if_else(\n      str_detect(title, \"climate\") | str_detect(abstract, \"climate\"), \n      \"mentioned\", \n      \"not mentioned\"\n      )\n    ) |>\n  count(climate) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  <chr>         <int> <dbl>\n1 mentioned         4  0.04\n2 not mentioned    96  0.96\n\n\n\nTime permitting: Come up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-21-jane-austen-A.html",
    "href": "ae/ae-21-jane-austen-A.html",
    "title": "He replied / she cried: Text mining and gender roles",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-21-jane-austen-A.html#packages",
    "href": "ae/ae-21-jane-austen-A.html#packages",
    "title": "He replied / she cried: Text mining and gender roles",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidytext)\nlibrary(knitr)\nlibrary(janeaustenr) # install.packages(\"janeaustenr)"
  },
  {
    "objectID": "ae/ae-21-jane-austen-A.html#data",
    "href": "ae/ae-21-jane-austen-A.html#data",
    "title": "He replied / she cried: Text mining and gender roles",
    "section": "Data",
    "text": "Data\nThe janeaustenr package offers a function, austen_books(), that returns a tidy data frame of Jane Austen’s 6 completed, published novels.\n\nausten_books <- austen_books() |>\n  filter(text != \"\")\n\n\nDemo: Which books are included in the dataset?\n\n\nausten_books |>\n  distinct(book)\n\n# A tibble: 6 × 1\n  book               \n  <fct>              \n1 Sense & Sensibility\n2 Pride & Prejudice  \n3 Mansfield Park     \n4 Emma               \n5 Northanger Abbey   \n6 Persuasion"
  },
  {
    "objectID": "ae/ae-13-palmerpenguins.html",
    "href": "ae/ae-13-palmerpenguins.html",
    "title": "Palmer Penguins and regression with a single predictor",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\n# add code here\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins’ flipper lengths and their body masses.\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nAdd response here\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\n# add code here \n\n\nCorrelation\n\nYour turn (5 minutes):\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# add code here\n\n\n\nDefining, fitting, and summarizing a model\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\nadd~math~text~here\n\\]\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Add your response here\nSlopes: Add your response here\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\n# add code here\n\n\nWhat is the estimated body mass for a penguin with a flipper length of 210?\n\n\n# add code here\n\n\nWhat is the estimated body mass for a penguin with a flipper length of 100?\n\n\n# add code here\n\n\n\nAnother model\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nAdd response here\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\n# add code here\n\n\n# add code here\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\n# add code here\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\n# add code here\n\nAdd math text here\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Add your response here\nSlopes: Add your response here\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors-A.html",
    "href": "ae/ae-05-pivoting-statsci-majors-A.html",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "",
    "text": "Our ultimate goal in this application exercise is to make the following data visualization.\n\n\n\n\n\n\nYour turn (3 minutes): Take a close look at the plot and describe what it shows in 2-3 sentences.\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors-A.html#data",
    "href": "ae/ae-05-pivoting-statsci-majors-A.html#data",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I’ve put the data exported in a CSV file for you. Let’s load that in.\n\nlibrary(tidyverse)\n\nstatsci <- read_csv(\"data/statsci.csv\")\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 12\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# … with 1 more variable: `2021` <dbl>\n\n\nThe dataset has 4 rows and 12 columns. The first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major). The remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2021.\n\nYour turn (4 minutes): Take a look at the plot we aim to make and sketch the data frame we need to make the plot. Determine what each row and each column of the data frame should be. Hint: We need data to be in columns to map to aesthetic elements of the plot.\n\nColumns: year, n , degree_type\nRows: Combination of year and degree type"
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors-A.html#pivoting",
    "href": "ae/ae-05-pivoting-statsci-majors-A.html#pivoting",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "Pivoting",
    "text": "Pivoting\n\nDemo: Pivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\"\n  )\n\n# A tibble: 44 × 3\n   degree                    year      n\n   <chr>                     <chr> <dbl>\n 1 Statistical Science (AB2) 2011     NA\n 2 Statistical Science (AB2) 2012      1\n 3 Statistical Science (AB2) 2013     NA\n 4 Statistical Science (AB2) 2014     NA\n 5 Statistical Science (AB2) 2015      4\n 6 Statistical Science (AB2) 2016      4\n 7 Statistical Science (AB2) 2017      1\n 8 Statistical Science (AB2) 2018     NA\n 9 Statistical Science (AB2) 2019     NA\n10 Statistical Science (AB2) 2020      1\n# … with 34 more rows\n\n\n\nQuestion: What is the type of the year variable? Why? What should it be?\n\nIt’s a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric.\n\nDemo: Start over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  )\n\n# A tibble: 44 × 3\n   degree                     year     n\n   <chr>                     <dbl> <dbl>\n 1 Statistical Science (AB2)  2011    NA\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013    NA\n 4 Statistical Science (AB2)  2014    NA\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018    NA\n 9 Statistical Science (AB2)  2019    NA\n10 Statistical Science (AB2)  2020     1\n# … with 34 more rows\n\n\n\nQuestion: What does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\nNAs should actually be 0s.\n\nDemo: Add on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n))\n\n# A tibble: 44 × 3\n   degree                     year     n\n   <chr>                     <dbl> <dbl>\n 1 Statistical Science (AB2)  2011     0\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013     0\n 4 Statistical Science (AB2)  2014     0\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018     0\n 9 Statistical Science (AB2)  2019     0\n10 Statistical Science (AB2)  2020     1\n# … with 34 more rows\n\n\n\nDemo: In our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    )\n\n# A tibble: 44 × 4\n   major               degree_type  year     n\n   <chr>               <fct>       <dbl> <dbl>\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# … with 34 more rows\n\n\n\nYour turn (5 minutes): Now we start making our plot, but let’s not get too fancy right away. Create the following plot, which will serve as the “first draft” on the way to our Goal. Do this by adding on to your pipeline from earlier.\n\n\n\n\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\nYour turn (4 minutes): What aspects of the plot need to be updated to go from the draft you created above to the Goal plot at the beginning of this application exercise.\n\nx-axis scale: need to go from 2011 to 2021 in increments of 2 years\nline colors\naxis labels: title, subtitle, x, y, caption\ntheme\nlegend position and border\n\nDemo: Update x-axis scale such that the years displayed go from 2011 to 2021 in increments of 2 years. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2))\n\n\n\n\n\nDemo: Update line colors using the following level / color assignments. Once again, do this by adding on to your pipeline from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\", \n               \"BS2\" = \"cadetblue3\", \n               \"AB\" = \"lightgoldenrod4\", \n               \"AB2\" = \"lightgoldenrod3\"))\n\n\n\n\n\nYour turn (4 minutes): Update the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2021\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nDemo: Finally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Set fig-width: 7 and fig-height: 5 for your plot in the chunk options.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2021\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = c(0.2, 0.8),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n    )"
  },
  {
    "objectID": "ae/ae-09-dse-bias.html",
    "href": "ae/ae-09-dse-bias.html",
    "title": "AE 09: Data science ethics - Algorithmic bias",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-09-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Sunday, Oct 9 at 11:59pm.\n\n\n\nPart 1 - Stochastic parrots\nYour turn (10 minutes):\n\nRead the following title and abstract.\n\n\nOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 (Bender et. al., 2021)\nThe past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.\n\n\nHave you used a natural language model before? Describe your use.\n\nAdd your response here.\n\nWhat is meant by “stochastic parrots” in the paper title?\n\nAdd your response here.\n\n\nPart 2 - Predicting ethnicity\nYour turn (12 minutes): Imai and Khanna (2016) built a racial prediction algorithm using a Bayes classifier trained on voter registration records from Florida and the U.S. Census Bureau’s name list.\n\nThe following is the title and the abstract of the paper. Take a minute to read them.\n\n\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology.\n\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nThen, if you feel comfortable, load the wru package and try it out using the sample data provided in the package. And if you don’t feel comfortable doing so, take a look at the results below. Was the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(tidyverse)\nlibrary(wru)\n\npredict_race(voter.file = voters, surname.only = TRUE) %>% \n  select(surname, pred.whi, pred.bla, pred.his, pred.asi, pred.oth)\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi    pred.oth\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906 0.084557725\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581 0.170827160\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883 0.010573240\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323 0.057857101\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594 0.009224032\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635 0.109676251\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765 0.077409913\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125 0.012105576\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541 0.048937658\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712 0.054333479\n\n\nAdd your response here.\n\nIf you have installed the package, re-run the code, this time to see what the package predicts for your race. Now consider the same questions again: Was the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nme <- tibble(surname = \"Rundel\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\nWarning: Unknown or uninitialised column: `state`.\n\n\nProceeding with last name predictions...\n\n\nℹ All local files already up-to-date!\nℹ All local files already up-to-date!\n\n\n  surname  pred.whi pred.bla pred.his pred.asi   pred.oth\n1  Rundel 0.9177967        0        0        0 0.08220329\n\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-10-chronicle.html",
    "href": "ae/ae-10-chronicle.html",
    "title": "Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle-scrape.R R script. Save the resulting data frame in the data folder."
  },
  {
    "objectID": "ae/ae-10-chronicle.html#part-2---data-analysis",
    "href": "ae/ae-10-chronicle.html#part-2---data-analysis",
    "title": "Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\nYour turn (1 minute): Load the data you saved into the data folder and name it chronicle.\n\n\n# add code here\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\n# add code here\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\n# add code here\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\n\n# add code here\n\n\nYour turn (5 minutes): What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\n# add code here\n\n\nTime permitting: Come up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-14-moar-palmerpenguins.html",
    "href": "ae/ae-14-moar-palmerpenguins.html",
    "title": "Palmer Penguins and regression with multiple predictors",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nPlease read the following context and take a glimpse at the data set before we get started.\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass."
  },
  {
    "objectID": "ae/ae-14-moar-palmerpenguins.html#additive-vs.-interaction-models",
    "href": "ae/ae-14-moar-palmerpenguins.html#additive-vs.-interaction-models",
    "title": "Palmer Penguins and regression with multiple predictors",
    "section": "Additive vs. interaction models",
    "text": "Additive vs. interaction models\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\nAdd response here.\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nAdd response here.\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\n# add code here\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nThe additive model assumes the same slope between body mass and flipper length for all three islands.\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nThe interaction effect allows us to model the rate of change in estimated body mass as flipper length increases as different in the three islands.\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-14-moar-palmerpenguins.html#choosing-a-model",
    "href": "ae/ae-14-moar-palmerpenguins.html#choosing-a-model",
    "title": "Palmer Penguins and regression with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\n# add code here\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-06-data-types-classes.html",
    "href": "ae/ae-06-data-types-classes.html",
    "title": "AE 06: Data types and classes",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-05-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Sunday, Sep 26 at 11:59pm."
  },
  {
    "objectID": "ae/ae-06-data-types-classes.html#packages",
    "href": "ae/ae-06-data-types-classes.html#packages",
    "title": "AE 06: Data types and classes",
    "section": "Packages",
    "text": "Packages\nWe will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nskimr: For summarizing the entire data frame at once.\nscales: For better axis labels.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(scales)"
  },
  {
    "objectID": "ae/ae-06-data-types-classes.html#type-coercion",
    "href": "ae/ae-06-data-types-classes.html#type-coercion",
    "title": "AE 06: Data types and classes",
    "section": "Type coercion",
    "text": "Type coercion\n\nDemo: Determine the type of the following vector. And then, change the type to numeric.\n\nx <- c(\"1\", \"2\", \"3\")\ntypeof(x)\n\n[1] \"character\"\n\nas.numeric(x)\n\n[1] 1 2 3\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\ny <- c(\"a\", \"b\", \"c\")\n\n# add code here\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\nz <- c(\"1\", \"2\", \"three\")\n\n# add code here\n\nDemo: Suppose you conducted a survey where you asked people how many cars their household owns collectively. And the answers are as follows:\n\nsurvey_results <- tibble(cars = c(1, 2, \"three\"))\nsurvey_results\n\n# A tibble: 3 × 1\n  cars \n  <chr>\n1 1    \n2 2    \n3 three\n\n\nThis is annoying because of that third survey taker who just had to go and type out the number instead of providing as a numeric value. So now you need to update the cars variable to be numeric. You do the following\n\nsurvey_results |>\n  mutate(cars = as.numeric(cars))\n\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3    NA\n\n\nAnd now things are even more annoying because you get a warning NAs introduced by coercion that happened while computing cars = as.numeric(cars) and the response from the third survey taker is now an NA (you lost their data). Fix your mutate() call to avoid this warning.\n\n# add code here\n\nYour turn (8 minutes): First, guess the type of the vector. Then, check if you guessed right. I’ve done the first one for you, you’ll see that it’s helpful to check the type of each element of the vector first.\n\nc(1, 1L, \"C\")\n\nv1 <- c(1, 1L, \"C\")\n\n# to help you guess\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"C\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v1)\n\n[1] \"character\"\n\n\nc(1L / 0, \"A\")\n\nv2 <- c(1L / 0, \"A\")\n\n# to help you guess\n\n# to check after you guess\n\nc(1:3, 5)\n\nv3 <- c(1:3, 5)\n\n# to help you guess\n\n# to check after you guess\n\nc(3, \"3+\")\n\nv4 <- c(3, \"3+\")\n\n# to help you guess\n\n# to check after you guess\n\nc(NA, TRUE)\n\nv5 <- c(NA, TRUE)\n\n# to help you guess\n\n# to check after you guess"
  },
  {
    "objectID": "ae/ae-06-data-types-classes.html#hotel-bookings",
    "href": "ae/ae-06-data-types-classes.html#hotel-bookings",
    "title": "AE 06: Data types and classes",
    "section": "Hotel bookings",
    "text": "Hotel bookings\n\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\n\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nQuestion: Take a look at the the following visualization. How are the months ordered? What would be a better order?\nAdd your response here.\n\n\n\n\n\nDemo: Reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\n\n# add code here\n\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html",
    "href": "ae/ae-02-viz-data-types-A.html",
    "title": "AE 02: Visualizing penguins",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nFor all analyses, we’ll use the tidyverse and palmerpenguins packages.\nThe dataset we will visualize is called penguins. Let’s glimpse() at it."
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#single-variable",
    "href": "ae/ae-02-viz-data-types-A.html#single-variable",
    "title": "AE 02: Visualizing penguins",
    "section": "Single variable",
    "text": "Single variable\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the a single variable is called univariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins.\n\nMake a histogram. Set an appropriate binwidth.\n\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 250)\n\n\n\n\n\nMake a boxplot.\n\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_boxplot()\n\n\n\n\n\nBased on these, determine if each of the following statements about the shape of the distribution is true or false.\n\nThe distribution of penguin weights in this sample is left skewed. FALSE\nThe distribution of penguin weights in this sample is unimodal. TRUE"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#two-variables",
    "href": "ae/ae-02-viz-data-types-A.html#two-variables",
    "title": "AE 02: Visualizing penguins",
    "section": "Two variables",
    "text": "Two variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between two variables is called bivariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins by species.\n\nMake a single histogram. Set an appropriate binwidth.\n\n\nggplot(penguins, \n       aes(x = body_mass_g, fill = species)) +\n  geom_histogram(binwidth = 250, alpha = 0.5, color = \"black\")\n\n\n\n\n\nUse multiple histograms via faceting, one for each species. Set an appropriate binwidth, add color as you see fit, and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = body_mass_g, fill = species)) +\n  geom_histogram(binwidth = 250, show.legend = FALSE) +\n  facet_wrap(~species, ncol = 1)\n\n\n\n\n\nUse side-by-side box plots. Add color as you see fit and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot(show.legend = FALSE)\n\n\n\n\n\nUse density plots. Add color as you see fit.\n\n\nggplot(penguins, \n       aes(x = body_mass_g, fill = species)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\nUse violin plots. Add color as you see fit and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, fill = species)) +\n    geom_violin(alpha = 0.5, show.legend = FALSE)\n\n\n\n\n\nMake a jittered scatter plot. Add color as you see fit and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n    geom_jitter(show.legend = FALSE)\n\n\n\n\n\nUse beeswarm plots. Add color as you see fit and turn off legends if not needed.\n\n\nlibrary(ggbeeswarm)\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n  geom_beeswarm(show.legend = FALSE)\n\n\n\n\n\nUse multiple geoms on a single plot. Be deliberate about the order of plotting. Change the theme and the color scale of the plot. Finally, add informative labels.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n  geom_beeswarm(show.legend = FALSE) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5) +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(\n    x = \"Species\",\n    y = \"Body mass (g)\",\n    title = \"Body mass of penguins in Palmer Archipelago\",\n    subtitle = \"By species\"\n  )"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#multiple-variables",
    "href": "ae/ae-02-viz-data-types-A.html#multiple-variables",
    "title": "AE 02: Visualizing penguins",
    "section": "Multiple variables",
    "text": "Multiple variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between three or more variables is called multivariate analysis.\n\n\n\nFacet the plot you created in the previous exercise by island. Adjust labels accordingly.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n  geom_beeswarm(show.legend = FALSE) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5) +\n  facet_wrap(~island) +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(\n    x = \"Species\",\n    y = \"Body mass (g)\",\n    title = \"Body mass of penguins in Palmer Archipelago\",\n    subtitle = \"By species and island\"\n  )\n\n\n\n\nBefore you continue, let’s turn off all warnings the code chunks generate and resize all figures. We’ll do this by editing the YAML."
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#visualizing-other-variables---your-turn",
    "href": "ae/ae-02-viz-data-types-A.html#visualizing-other-variables---your-turn",
    "title": "AE 02: Visualizing penguins",
    "section": "Visualizing other variables - Your turn!",
    "text": "Visualizing other variables - Your turn!\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\n\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here…\n\nMake another plot that uses at least three variables. At least one should be numeric and at least one categorical. In 1-2 sentences, describe what the plot shows about the relationships between the variables you plotted. Don’t forget to label your code chunk.\n\n\n# add code here\n\nInterpretation goes here…"
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates-A.html",
    "href": "ae/ae-15-modelling-loan-interest-rates-A.html",
    "title": "Modelling loan interest rates",
    "section": "",
    "text": "In this application exercise we will be studying loan interest rates. The dataset is one you’ve come across before in your reading – the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nBefore we use the dataset, we’ll make a few transformations to it.\nHere is a glimpse at the data:"
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates-A.html#main-effects-model",
    "href": "ae/ae-15-modelling-loan-interest-rates-A.html#main-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_fit <- linear_reg() |>\n  fit(interest_rate ~ credit_util + homeownership, data = loans)\n\ntidy(rate_util_home_fit)\n\n# A tibble: 4 × 5\n  term                  estimate std.error statistic   p.value\n  <chr>                    <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\\[\n\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util + 0.696 \\times Mortgage - 0.128 \\times Own\n\\]\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util\\)\nMortgage: \\(\\widehat{interest~rate} = 10.626 + 5.34 \\times credit~util\\)\nOwn: \\(\\widehat{interest~rate} = 10.058 + 5.34 \\times credit~util\\)\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nThe same."
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates-A.html#interaction-effects-model",
    "href": "ae/ae-15-modelling-loan-interest-rates-A.html#interaction-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_int_fit <- linear_reg() |>\n  fit(interest_rate ~ credit_util * homeownership, data = loans)\n\ntidy(rate_util_home_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  <chr>                                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                          9.44      0.199     47.5  0       \n2 credit_util                          6.20      0.325     19.1  1.01e-79\n3 homeownershipMortgage                1.39      0.228      6.11 1.04e- 9\n4 homeownershipOwn                     0.697     0.316      2.20 2.75e- 2\n5 credit_util:homeownershipMortgage   -1.64      0.457     -3.58 3.49e- 4\n6 credit_util:homeownershipOwn        -1.06      0.590     -1.80 7.24e- 2\n\n\n\\[\n\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util + 1.39 \\times Mortgage + 0.697 \\times Own - 1.64 \\times credit_util:Mortgage - 1.06 \\times credit_util:Own\n\\]\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util\\)\nMortgage: \\(\\widehat{interest~rate} = 10.83 + 4.56 \\times credit~util\\)\nOwn: \\(\\widehat{interest~rate} = 10.137 + 5.14 \\times credit~util\\)\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nDifferent."
  },
  {
    "objectID": "ae/ae-15-modelling-loan-interest-rates-A.html#choosing-a-model",
    "href": "ae/ae-15-modelling-loan-interest-rates-A.html#choosing-a-model",
    "title": "Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\nglance(rate_util_home_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.…¹ sigma stati…²   p.value    df  logLik    AIC    BIC devia…³\n      <dbl>    <dbl> <dbl>   <dbl>     <dbl> <dbl>   <dbl>  <dbl>  <dbl>   <dbl>\n1    0.0682   0.0679  4.83    244. 1.25e-152     3 -29926. 59861. 59897. 232954.\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\nglance(rate_util_home_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.…¹ sigma stati…²   p.value    df  logLik    AIC    BIC devia…³\n      <dbl>    <dbl> <dbl>   <dbl>     <dbl> <dbl>   <dbl>  <dbl>  <dbl>   <dbl>\n1    0.0694   0.0689  4.83    149. 4.79e-153     5 -29919. 59852. 59903. 232652.\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables).\n\nQuestion: Based on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nThe interaction effects model, though just barely."
  },
  {
    "objectID": "ae/ae-11-yankee-candle-A.html",
    "href": "ae/ae-11-yankee-candle-A.html",
    "title": "Yankee Candle reviews on Amazon",
    "section": "",
    "text": "See yankee-candle-scrape-A.R for suggested scraping code."
  },
  {
    "objectID": "ae/ae-11-yankee-candle-A.html#part-2---data-analysis",
    "href": "ae/ae-11-yankee-candle-A.html#part-2---data-analysis",
    "title": "Yankee Candle reviews on Amazon",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\n\nLoad the data you saved into the data folder and name it yc_reviews_all.\n\n\nyc_reviews_all <- read_csv(\"data/yc-reviews-all.csv\")\n\n\nYour turn (5 minutes): Our goal is to plot the number of reviews or titles mentioning “no scent” or “no smell” per week. Take a look at the data you loaded and outline how you can transform it to prepare it for such a plot. Your response should be bullet points that can roughly be translated to steps in a data wrangling pipeline.\n\nExtract date of review.\nFigure out which week of the year the date corresponds to.\nLook for “no scent” or “no smell” in the titles or reviews.\nCount how many titles or reviews have these phrases mentioned for each week.\nPlot the number of mentions by week against week number.\n\nDemo: Create the plot described above.\n\n\nyc_reviews_all |>\n  mutate(\n    date = mdy(country_date),\n    week = week(date),\n    review = str_to_lower(review),\n    title = str_to_lower(title),\n    no_scent = case_when(\n      str_detect(review, \"no scent\") | str_detect(title, \"no scent\") ~ \"mentioned\",\n      str_detect(review, \"no smell\") | str_detect(title, \"no smell\") ~ \"mentioned\",\n      TRUE ~ \"not mentioned\"\n    )\n  ) |>\n  count(week, no_scent) |>\n  filter(no_scent == \"mentioned\") |>\n  ggplot(aes(x = week, y = n, group = 1)) +\n  geom_line()\n\n\n\n\n\nYour turn (3 minutes): Outline how this exercise could be expanded to make a plot like this one that compares number of reviews mentioning no scent/smell and number of COVID cases.\n\nScrape data going further back and join it with weekly COVID cases data from another source and plot both."
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors.html",
    "href": "ae/ae-05-pivoting-statsci-majors.html",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-05-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, Sep 23 at 11:59pm."
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors.html#goal",
    "href": "ae/ae-05-pivoting-statsci-majors.html#goal",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "Goal",
    "text": "Goal\nOur ultimate goal in this application exercise is to make the following data visualization.\n\n\n\n\n\n\nYour turn (3 minutes): Take a close look at the plot and describe what it shows in 2-3 sentences.\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors.html#data",
    "href": "ae/ae-05-pivoting-statsci-majors.html#data",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I’ve put the data exported in a CSV file for you. Let’s load that in.\n\nlibrary(tidyverse)\n\nstatsci <- read_csv(\"data/statsci.csv\")\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 12\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# … with 1 more variable: `2021` <dbl>\n\n\nThe dataset has 4 rows and 12 columns. The first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major). The remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2021.\n\nYour turn (4 minutes): Take a look at the plot we aim to make and sketch the data frame we need to make the plot. Determine what each row and each column of the data frame should be. Hint: We need data to be in columns to map to aesthetic elements of the plot.\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors.html#pivoting",
    "href": "ae/ae-05-pivoting-statsci-majors.html#pivoting",
    "title": "AE 05: Pivoting StatSci Majors",
    "section": "Pivoting",
    "text": "Pivoting\n\nDemo: Pivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\n# add your code here\n\n\nQuestion: What is the type of the year variable? Why? What should it be?\n\nAdd your response here.\n\nDemo: Start over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\n# add your code here\n\n\nQuestion: What does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\nAdd your response here.\n\nDemo: Add on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\n# add your code here\n\n\nDemo: In our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\n# add your code here\n\n\nYour turn (5 minutes): Now we start making our plot, but let’s not get too fancy right away. Create the following plot, which will serve as the “first draft” on the way to our Goal. Do this by adding on to your pipeline from earlier.\n\n\n\n\n\n\n\n# add your code here\n\n\nYour turn (4 minutes): What aspects of the plot need to be updated to go from the draft you created above to the Goal plot at the beginning of this application exercise.\n\nAdd your response here.\n\nDemo: Update x-axis scale such that the years displayed go from 2011 to 2021 in increments of 2 years. Do this by adding on to your pipeline from earlier.\n\n\n# add your code here\n\n\nDemo: Update line colors using the following level / color assignments. Once again, do this by adding on to your pipeline from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\n\n\n# add your code here\n\n\nYour turn (4 minutes): Update the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your pipeline from earlier.\n\n\n# add your code here\n\n\nDemo: Finally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Set fig-width: 7 and fig-height: 5 for your plot in the chunk options.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-12-modelling-fish.html",
    "href": "ae/ae-12-modelling-fish.html",
    "title": "Modelling fish",
    "section": "",
    "text": "For this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish <- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\n\nvariable\ndescription\n\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\n\nVisualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish.\n\nDemo: Create an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\n# add code here\n\n\nYour turn (5 minutes):\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\nAdd response here.\nNow, let R draw the line for you. Refer to the documentation at https://ggplot2.tidyverse.org/reference/geom_smooth.html. Specifically, refer to the method section.\n\n\n# add code here\n\n\nWhat types of questions can this plot help answer?\n\nAdd response here.\nYour turn (3 minutes):\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAdd response here.\n\nWhat is a residual?\n\nAdd response here.\n\n\n\nModel fitting\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\n# add code here\n\n\nYour turn (3 minutes): Predict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\n# add code here\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\n# add code here\n\n\n\nModel summary\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\n# add code here\n\n\nDemo: Write out your model using mathematical notation.\n\nAdd response here.\n\n\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nYour turn (5 minutes):\n\nWhat is correlation? What are values correlation can take?\n\nAdd response here.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between heights and weights of fish?\n\n\n# add code here\n\n\n\nAdding a third variable\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\n# add code here\n\n\n\nFitting other models\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html",
    "href": "ae/ae-20-effective-dataviz.html",
    "title": "Trends instructional staff employees in universities",
    "section": "",
    "text": "The American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains the following image. What trends are apparent in this visualization?"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#packages",
    "href": "ae/ae-20-effective-dataviz.html#packages",
    "title": "Trends instructional staff employees in universities",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggthemes)"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#data",
    "href": "ae/ae-20-effective-dataviz.html#data",
    "title": "Trends instructional staff employees in universities",
    "section": "Data",
    "text": "Data\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n\nstaff <- read_csv(\"data/instructional-staff.csv\")\nstaff\n\n# A tibble: 5 × 12\n  facult…¹ `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Full-Ti…   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8\n2 Full-Ti…   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6\n3 Full-Ti…   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1\n4 Part-Ti…   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1\n5 Graduat…   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4\n# … with 1 more variable: `2011` <dbl>, and abbreviated variable name\n#   ¹​faculty_type"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#recreate",
    "href": "ae/ae-20-effective-dataviz.html#recreate",
    "title": "Trends instructional staff employees in universities",
    "section": "Recreate",
    "text": "Recreate\n\nYour turn (10 minutes): Recreate the visualization above. Try to match as many of the elements as possible. Hint: You might need to reshape your data first.\n\n\n# add code here\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#represent-percentages-as-parts-of-a-whole",
    "href": "ae/ae-20-effective-dataviz.html#represent-percentages-as-parts-of-a-whole",
    "title": "Trends instructional staff employees in universities",
    "section": "Represent percentages as parts of a whole",
    "text": "Represent percentages as parts of a whole\n\nDemo: Recreate the previous visualization where the percentages are represented as parts of a whole.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#place-time-on-x-axis",
    "href": "ae/ae-20-effective-dataviz.html#place-time-on-x-axis",
    "title": "Trends instructional staff employees in universities",
    "section": "Place time on x-axis",
    "text": "Place time on x-axis\n\nDemo: Convert the visualization to a line plot with time on the x-axis.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#pay-attention-to-variable-types",
    "href": "ae/ae-20-effective-dataviz.html#pay-attention-to-variable-types",
    "title": "Trends instructional staff employees in universities",
    "section": "Pay attention to variable types",
    "text": "Pay attention to variable types\n\nQuestion: What is wrong with the x-axis of the plot above? How can you fix it?\n\nAdd response here.\n\nYour turn: Implement the fix for the x-axis of the plot.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#use-an-accessible-color-scale",
    "href": "ae/ae-20-effective-dataviz.html#use-an-accessible-color-scale",
    "title": "Trends instructional staff employees in universities",
    "section": "Use an accessible color scale",
    "text": "Use an accessible color scale\n\nQuestion: What do we mean by an accessible color scale? What types of color vision deficiencies are there?\n\nAdd response here.\n\nDemo: What does the plot look like to people with various color vision deficiencies?\nDemo: Remake the plot with an accessible color scale.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#use-direct-labeling",
    "href": "ae/ae-20-effective-dataviz.html#use-direct-labeling",
    "title": "Trends instructional staff employees in universities",
    "section": "Use direct labeling",
    "text": "Use direct labeling\n\nDemo: Remove the legend and add labels for each line at the end of the line (where x is the max(x) recorded).\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#use-color-to-draw-attention",
    "href": "ae/ae-20-effective-dataviz.html#use-color-to-draw-attention",
    "title": "Trends instructional staff employees in universities",
    "section": "Use color to draw attention",
    "text": "Use color to draw attention\n\nDemo: Redo the line plot where Part-time Faculty is red and the rest are gray.\n\n\n# label: recode\n\n# add code here\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#pick-a-purpose",
    "href": "ae/ae-20-effective-dataviz.html#pick-a-purpose",
    "title": "Trends instructional staff employees in universities",
    "section": "Pick a purpose",
    "text": "Pick a purpose\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#use-labels-to-communicate-the-message",
    "href": "ae/ae-20-effective-dataviz.html#use-labels-to-communicate-the-message",
    "title": "Trends instructional staff employees in universities",
    "section": "Use labels to communicate the message",
    "text": "Use labels to communicate the message\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#simplify",
    "href": "ae/ae-20-effective-dataviz.html#simplify",
    "title": "Trends instructional staff employees in universities",
    "section": "Simplify",
    "text": "Simplify\n\n# add code here"
  },
  {
    "objectID": "ae/ae-20-effective-dataviz.html#summary",
    "href": "ae/ae-20-effective-dataviz.html#summary",
    "title": "Trends instructional staff employees in universities",
    "section": "Summary",
    "text": "Summary\n\nRepresent percentages as parts of a whole\nPlace variables representing time on the x-axis when possible\nPay attention to data types, e.g., represent time as time on a continuous scale, not years as levels of a categorical variable\nPrefer direct labeling over legends\nUse accessible colors\nUse color to draw attention\nPick a purpose and label, color, annotate for that purpose\nCommunicate your main message directly in the plot labels\nSimplify before you call it done (a.k.a. “Before you leave the house, look in the mirror and take one thing off”)"
  },
  {
    "objectID": "ae/ae-04-joining-fisheries.html",
    "href": "ae/ae-04-joining-fisheries.html",
    "title": "AE 04: Joining fisheries",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-04-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Sunday, Sep 18 at 11:59pm."
  },
  {
    "objectID": "ae/ae-04-joining-fisheries.html#working-with-multiple-data-frames",
    "href": "ae/ae-04-joining-fisheries.html#working-with-multiple-data-frames",
    "title": "AE 04: Joining fisheries",
    "section": "Working with multiple data frames",
    "text": "Working with multiple data frames\nOften instead of being provided the data you need for your analysis in a single data frame, you will need to bring information from multiple datasets together into a data frame yourself. These datasets will be linked to each other via a column (usually an identifier, something that links the two datasets together) that you can use to join them together.\nThere are many possible types of joins. All have the format something_join(x, y).\n\nx <- tibble(\n  value = c(1, 2, 3),\n  xcol = c(\"x1\", \"x2\", \"x3\")\n  )\n\ny <- tibble(\n  value = c(1, 2, 4),\n  ycol = c(\"y1\", \"y2\", \"y4\")\n  )\n\nx\n\n# A tibble: 3 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n  value ycol \n  <dbl> <chr>\n1     1 y1   \n2     2 y2   \n3     4 y4   \n\n\nWe will demonstrate each of the joins on these small, toy datasets.\n\ninner_join(): join all rows from x where there are matching values in y\n\ninner_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n\n\n\n\nleft_join(): include all rows from x\n\nleft_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n\n\n\n\nright_join(): include all rows from y\n\nright_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     4 <NA>  y4   \n\n\n\n\nfull_join(): include all rows in x or y (use this one sparingly!!)\n\nfull_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 4 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n4     4 <NA>  y4   \n\n\n\n\nsemi_join(): return all rows from x with match in y\n\nsemi_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n\n\n\n\nanti_join(): return all rows from x without a match in y\n\nanti_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 1 × 2\n  value xcol \n  <dbl> <chr>\n1     3 x3   \n\n\nQuestion: How do the join functions above know to join x and y by value? Hint: Examine the column names to find out.\n\nnames(x)\n\n[1] \"value\" \"xcol\" \n\nnames(y)\n\n[1] \"value\" \"ycol\""
  },
  {
    "objectID": "ae/ae-04-joining-fisheries.html#global-aquaculture-production",
    "href": "ae/ae-04-joining-fisheries.html#global-aquaculture-production",
    "title": "AE 04: Joining fisheries",
    "section": "Global aquaculture production",
    "text": "Global aquaculture production\nThe Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.\nOur goal is to create a visualization of the mean share of aquaculture by continent.\nLet’s start by looking at the fisheries data frame.\n\nglimpse(fisheries)\n\nRows: 82\nColumns: 4\n$ country     <chr> \"Angola\", \"Argentina\", \"Australia\", \"Bangladesh\", \"Brazil\"…\n$ capture     <dbl> 486490, 755226, 174629, 1674770, 705000, 629950, 233190, 8…\n$ aquaculture <dbl> 655, 3673, 96847, 2203554, 581230, 172500, 2315, 200765, 9…\n$ total       <dbl> 487145, 758899, 271476, 3878324, 1286230, 802450, 235505, …\n\n\nWe have the countries, but our goal is to make a visualization by continent. Let’s take a look at the continents data frame.\n\nglimpse(continents)\n\nRows: 245\nColumns: 2\n$ country   <chr> \"Afghanistan\", \"Åland Islands\", \"Albania\", \"Algeria\", \"Ameri…\n$ continent <chr> \"Asia\", \"Europe\", \"Europe\", \"Africa\", \"Oceania\", \"Europe\", \"…\n\n\n\nYour turn (2 minutes):\n\nWhich variable(s) will we use to join the fisheries and continents data frames?\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?\n\nDemo: Join the two data frames and name assign the joined data frame back to fisheries.\n\n\n# add code here\n\n\nDemo: Take a look at the updated fisheries data frame. There are some countries that were not in continents. First, identify which countries these are (they will have NA values for continent). Then, manually update the continent information for these countries using the case_when function. Finally, check that these updates have been made as intended and no countries are left without continent information.\n\n\n# add code here\n\n\nDemo: Add a new column to the fisheries data frame called aq_prop. We will calculate it as aquaculture / total. Save the resulting frame as fisheries.\n\n\n# add code here\n\n\nDemo: Calculate the mean aquaculture proportion (we’ll call it mean_aq_prop) for continents in the fisheries data using the summarize() function in dplyr. Note that the function for calculating the mean is mean() in R.\n\n\n# add code here\n\n\nYour turn (5 minutes): Now expand your calculations to also calculate the minimum and maximum aquaculture proportion for continents in the fisheries data. Note that the functions for calculating minimum and maximum in R are min() and max() respectively.\n\n\n# add code here \n\n\nDemo: Create a new data frame called fisheries_summary that calculates minimum, mean, and maximum aquaculture proportion for each continent in the fisheries data. Then, determine which continent has the largest value of max_ap?\n\n\n# add code here\n\n\nDemo: Take the fisheries_summary data frame and order the results in descending order of mean aquaculture proportion.\n\n\n# add code here\n\n\nDemo: Recreate the following plot using the data frame you have developed so far.\n\n\n\n\n\n\n\n# add code here\n\n\nYour turn (time permitting): Change the theme of the plot and make any other changes you would like to improve it.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-07-data-import-A.html",
    "href": "ae/ae-07-data-import-A.html",
    "title": "AE 07: Data import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-07-data-import-A.html#nobel-winners",
    "href": "ae/ae-07-data-import-A.html#nobel-winners",
    "title": "AE 07: Data import",
    "section": "Nobel winners",
    "text": "Nobel winners\n\nDemo: Load the data from the data folder and assign it to nobel. Confirm that this new object appears in your Environment tab.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nRows: 935 Columns: 26\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (21): firstname, surname, category, affiliation, city, country, gender,...\ndbl   (3): id, year, share\ndate  (2): born_date, died_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nYour turn (4 minutes): Split the data into two – nobel laureates in STEM fields (category should be Physics, Medicine, Chemistry, or Economics) and nobel laureates in non-STEM fields. Name these two new objects appropriately. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\n# define stem fields\nstem_fields <- c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\")\n\n# stem laureates\nnobel_stem <- nobel %>%\n  filter(category %in% stem_fields)\n\n# non-steam laureates\nnobel_nonstem <- nobel %>%\n  filter(!(category %in% stem_fields))\n\nDemo: Write out the two new datasets you created into the data folder:\n\nwrite_csv(nobel_stem, file = \"data/nobel-stem.csv\")\nwrite_csv(nobel_nonstem, file = \"data/nobel-nonstem.csv\")"
  },
  {
    "objectID": "ae/ae-07-data-import-A.html#sales",
    "href": "ae/ae-07-data-import-A.html#sales",
    "title": "AE 07: Data import",
    "section": "Sales",
    "text": "Sales\nSales data are stored in an Excel file that looks like the following:\n\n\n\n\n\n\nDemo: Read in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\nsales <- read_excel(\n  \"data/sales.xlsx\", \n  skip = 3,\n  col_names = c(\"id\", \"n\")\n  )\n\nDemo - Stretch goal: Manipulate the sales data such such that it looks like the following.\n\n\nsales |>\n  mutate(\n    is_brand_name = str_detect(id, \"Brand\"),\n    brand = if_else(is_brand_name, id, NULL)\n  ) |>\n  fill(brand) |>\n  filter(!is_brand_name) |>\n  select(brand, id, n)\n\n# A tibble: 7 × 3\n  brand   id    n    \n  <chr>   <chr> <chr>\n1 Brand 1 1234  8    \n2 Brand 1 8721  2    \n3 Brand 1 1822  3    \n4 Brand 2 3333  1    \n5 Brand 2 2156  3    \n6 Brand 2 3987  6    \n7 Brand 2 3216  5    \n\n\n\n\n\nQuestion: Why should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nBecause the code allows us to struggle once and re-use for future datasets and leaves a transparent trail of our modifications while manipulating the data in Excel directly is neither reproducible nor reusable."
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html",
    "href": "ae/ae-03-wrangling-flights-A.html",
    "title": "AE 03: Wrangling flights",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-03-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, Sep 16 at 11:59pm.\nTo demonstrate data wrangling we will use flights, a tibble in the nycflights13 R package. It includes characteristics of all flights departing from New York City (JFK, LGA, EWR) in 2013.\nThe data frame has over 336,000 observations (rows), 336776 observations to be exact, so we will not view the entire data frame. Instead we’ll use the commands below to help us explore the data.\nThe head() function returns “A tibble: 6 x 19” and then the first six rows of the flights data."
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#select",
    "href": "ae/ae-03-wrangling-flights-A.html#select",
    "title": "AE 03: Wrangling flights",
    "section": "select()",
    "text": "select()\n\nDemo: Make a data frame that only contains the variables dep_delay and arr_delay.\n\n\nflights |>\n  select(dep_delay, arr_delay)\n\n# A tibble: 336,776 × 2\n   dep_delay arr_delay\n       <dbl>     <dbl>\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# … with 336,766 more rows\n\n\n\nDemo: Make a data frame that keeps every variable except dep_delay.\n\n\nflights |>\n  select(-dep_delay)\n\n# A tibble: 336,776 × 18\n    year month   day dep_time sched_dep…¹ arr_t…² sched…³ arr_d…⁴ carrier flight\n   <int> <int> <int>    <int>       <int>   <int>   <int>   <dbl> <chr>    <int>\n 1  2013     1     1      517         515     830     819      11 UA        1545\n 2  2013     1     1      533         529     850     830      20 UA        1714\n 3  2013     1     1      542         540     923     850      33 AA        1141\n 4  2013     1     1      544         545    1004    1022     -18 B6         725\n 5  2013     1     1      554         600     812     837     -25 DL         461\n 6  2013     1     1      554         558     740     728      12 UA        1696\n 7  2013     1     1      555         600     913     854      19 B6         507\n 8  2013     1     1      557         600     709     723     -14 EV        5708\n 9  2013     1     1      557         600     838     846      -8 B6          79\n10  2013     1     1      558         600     753     745       8 AA         301\n# … with 336,766 more rows, 8 more variables: tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​arr_time, ³​sched_arr_time, ⁴​arr_delay\n\n\n\nDemo: Make a data frame that includes all variables between year through dep_delay (inclusive). These are all variables that provide information about the departure of each flight.\n\n\nflights |>\n  select(year:dep_delay)\n\n# A tibble: 336,776 × 6\n    year month   day dep_time sched_dep_time dep_delay\n   <int> <int> <int>    <int>          <int>     <dbl>\n 1  2013     1     1      517            515         2\n 2  2013     1     1      533            529         4\n 3  2013     1     1      542            540         2\n 4  2013     1     1      544            545        -1\n 5  2013     1     1      554            600        -6\n 6  2013     1     1      554            558        -4\n 7  2013     1     1      555            600        -5\n 8  2013     1     1      557            600        -3\n 9  2013     1     1      557            600        -3\n10  2013     1     1      558            600        -2\n# … with 336,766 more rows\n\n\n\nDemo: Use the select helper contains() to make a data frame that includes the variables associated with the arrival, i.e., contains the string \"arr\\_\" in the name.\n\n\nflights |>\n  select(contains(\"arr_\"))\n\n# A tibble: 336,776 × 3\n   arr_time sched_arr_time arr_delay\n      <int>          <int>     <dbl>\n 1      830            819        11\n 2      850            830        20\n 3      923            850        33\n 4     1004           1022       -18\n 5      812            837       -25\n 6      740            728        12\n 7      913            854        19\n 8      709            723       -14\n 9      838            846        -8\n10      753            745         8\n# … with 336,766 more rows"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#the-pipe",
    "href": "ae/ae-03-wrangling-flights-A.html#the-pipe",
    "title": "AE 03: Wrangling flights",
    "section": "The pipe",
    "text": "The pipe\nBefore working with more data wrangling functions, let’s formally introduce the pipe. The pipe, |>, is an operator (a tool) for passing information from one process to another. We will use |> mainly in data pipelines to pass the output of the previous line of code as the first input of the next line of code.\nWhen reading code “in English”, say “and then” whenever you see a pipe.\n\nYour turn (4 minutes): Run the following chunk and observe its output. Then, come up with a different way of obtaining the same output.\n\n\nflights |>\n  select(dep_delay, arr_delay) |>\n  head()\n\n# A tibble: 6 × 2\n  dep_delay arr_delay\n      <dbl>     <dbl>\n1         2        11\n2         4        20\n3         2        33\n4        -1       -18\n5        -6       -25\n6        -4        12"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#slice",
    "href": "ae/ae-03-wrangling-flights-A.html#slice",
    "title": "AE 03: Wrangling flights",
    "section": "slice()",
    "text": "slice()\n\nDemo: Display the first five rows of the flights data frame.\n\n\nflights |>\n  slice(1:5)\n\n# A tibble: 5 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     1      517         515       2     830     819      11 UA     \n2  2013     1     1      533         529       4     850     830      20 UA     \n3  2013     1     1      542         540       2     923     850      33 AA     \n4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n5  2013     1     1      554         600      -6     812     837     -25 DL     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: Display the last two rows of the flights data frame.\n\n\nflights |>\n  slice((n()-1):n())\n\n# A tibble: 2 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     9    30       NA        1159      NA      NA    1344      NA MQ     \n2  2013     9    30       NA         840      NA      NA    1020      NA MQ     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#arrange",
    "href": "ae/ae-03-wrangling-flights-A.html#arrange",
    "title": "AE 03: Wrangling flights",
    "section": "arrange()",
    "text": "arrange()\n\nDemo: Let’s arrange the data by departure delay, so the flights with the shortest departure delays will be at the top of the data frame.\n\nQuestion: What does it mean for the dep_delay to have a negative value?\n\nflights |>\n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013    12     7     2040       2123     -43      40    2352      48 B6     \n 2  2013     2     3     2022       2055     -33    2240    2338     -58 DL     \n 3  2013    11    10     1408       1440     -32    1549    1559     -10 EV     \n 4  2013     1    11     1900       1930     -30    2233    2243     -10 DL     \n 5  2013     1    29     1703       1730     -27    1947    1957     -10 F9     \n 6  2013     8     9      729        755     -26    1002     955       7 MQ     \n 7  2013    10    23     1907       1932     -25    2143    2143       0 EV     \n 8  2013     3    30     2030       2055     -25    2213    2250     -37 MQ     \n 9  2013     3     2     1431       1455     -24    1601    1631     -30 9E     \n10  2013     5     5      934        958     -24    1225    1309     -44 B6     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: Now let’s arrange the data by descending departure delay, so the flights with the longest departure delays will be at the top.\n\n\nflights |>\n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013     6    15     1432       1935    1137    1607    2120    1127 MQ     \n 3  2013     1    10     1121       1635    1126    1239    1810    1109 MQ     \n 4  2013     9    20     1139       1845    1014    1457    2210    1007 AA     \n 5  2013     7    22      845       1600    1005    1044    1815     989 MQ     \n 6  2013     4    10     1100       1900     960    1342    2211     931 DL     \n 7  2013     3    17     2321        810     911     135    1020     915 DL     \n 8  2013     6    27      959       1900     899    1236    2226     850 DL     \n 9  2013     7    22     2257        759     898     121    1026     895 DL     \n10  2013    12     5      756       1700     896    1058    2020     878 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nYour turn (5 minutes): Create a data frame that only includes the plane tail number (tailnum), carrier (carrier), and departure delay for the flight with the longest departure delay. What is the plane tail number (tailnum) for this flight? Share your response on Slack on the relevant thread on #general using code formatting.\n\n\nflights |>\n  select(tailnum, carrier, dep_delay) %>%\n  arrange(dep_delay) |>\n  slice(1)\n\n# A tibble: 1 × 3\n  tailnum carrier dep_delay\n  <chr>   <chr>       <dbl>\n1 N592JB  B6            -43"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#filter",
    "href": "ae/ae-03-wrangling-flights-A.html#filter",
    "title": "AE 03: Wrangling flights",
    "section": "filter()",
    "text": "filter()\n\nDemo: Filter the data frame by selecting the rows where the destination airport is RDU.\n\n\nflights |>\n  filter(dest == \"RDU\")\n\n# A tibble: 8,163 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1240       1235       5    1415    1415       0 MQ     \n 9  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n10  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n# … with 8,153 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: We can also filter using more than one condition. Here we select all rows where the destination airport is RDU and the arrival delay is less than 0.\n\n\nflights |>\n  filter(dest == \"RDU\", arr_delay < 0)\n\n# A tibble: 4,232 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n10  2013     1     1     1800       1800       0    1945    1951      -6 B6     \n# … with 4,222 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nWe can do more complex tasks using logical operators:\n\n\n\noperator\ndefinition\n\n\n\n\n<\nis less than?\n\n\n<=\nis less than or equal to?\n\n\n>\nis greater than?\n\n\n>=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x?\n\n\n\nThe final operator only makes sense if x is logical (TRUE / FALSE).\n\nYour turn (4 minutes): Describe what the code is doing in words. Share your response on Slack on the relevant thread on #general.\n\n\nflights |>\n  filter(\n    dest %in% c(\"RDU\", \"GSO\"),\n    arr_delay < 0 | dep_delay < 0\n    )\n\n# A tibble: 6,203 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n10  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n# … with 6,193 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#count",
    "href": "ae/ae-03-wrangling-flights-A.html#count",
    "title": "AE 03: Wrangling flights",
    "section": "count()",
    "text": "count()\n\nDemo: Create a frequency table of the destination locations for flights from New York.\n\n\nflights |>\n  count(dest)\n\n# A tibble: 105 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# … with 95 more rows\n\n\n\nDemo: In which month was there the fewest number of flights? How many flights were there in that month?\n\n\nflights |>\n  count(month) |>\n  filter(n == min(n))\n\n# A tibble: 1 × 2\n  month     n\n  <int> <int>\n1     2 24951\n\n\n\nYour turn (5 minutes): On which date (month + day) was there the largest number of flights? How many flights were there on that day? Share your response on Slack on the relevant thread on #general using code formatting.\n\n\nflights |>\n  count(month, day) |>\n  filter(n == max(n))\n\n# A tibble: 1 × 3\n  month   day     n\n  <int> <int> <int>\n1    11    27  1014"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#mutate",
    "href": "ae/ae-03-wrangling-flights-A.html#mutate",
    "title": "AE 03: Wrangling flights",
    "section": "mutate()",
    "text": "mutate()\nUse mutate() to create a new variable.\n\nDemo: In the code chunk below, air_time (minutes in the air) is converted to hours, and then new variable mph is created, corresponding to the miles per hour of the flight.\n\n\nflights |>\n  mutate(\n    hours = air_time / 60,\n    mph = distance / hours\n    ) |>\n  select(air_time, distance, hours, mph)\n\n# A tibble: 336,776 × 4\n   air_time distance hours   mph\n      <dbl>    <dbl> <dbl> <dbl>\n 1      227     1400 3.78   370.\n 2      227     1416 3.78   374.\n 3      160     1089 2.67   408.\n 4      183     1576 3.05   517.\n 5      116      762 1.93   394.\n 6      150      719 2.5    288.\n 7      158     1065 2.63   404.\n 8       53      229 0.883  259.\n 9      140      944 2.33   405.\n10      138      733 2.3    319.\n# … with 336,766 more rows\n\n\n\nYour turn (4 minutes): Create a new variable to calculate the percentage of flights in each month. What percentage of flights take place in July?\n\n\nflights |>\n  count(month) |>\n  mutate(perc = n / sum(n) * 100)\n\n# A tibble: 12 × 3\n   month     n  perc\n   <int> <int> <dbl>\n 1     1 27004  8.02\n 2     2 24951  7.41\n 3     3 28834  8.56\n 4     4 28330  8.41\n 5     5 28796  8.55\n 6     6 28243  8.39\n 7     7 29425  8.74\n 8     8 29327  8.71\n 9     9 27574  8.19\n10    10 28889  8.58\n11    11 27268  8.10\n12    12 28135  8.35"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#summarize",
    "href": "ae/ae-03-wrangling-flights-A.html#summarize",
    "title": "AE 03: Wrangling flights",
    "section": "summarize()",
    "text": "summarize()\nsummarize() collapses the rows into summary statistics and removes columns irrelevant to the calculation.\nBe sure to name your columns!\n\nflights |>\n  summarize(mean_dep_delay = mean(dep_delay))\n\n# A tibble: 1 × 1\n  mean_dep_delay\n           <dbl>\n1             NA\n\n\nQuestion: Why did this code return NA?\nLet’s fix it!\n\nflights |>\n  summarize(mean_dep_delay = mean(dep_delay, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_dep_delay\n           <dbl>\n1           12.6"
  },
  {
    "objectID": "ae/ae-03-wrangling-flights-A.html#group_by",
    "href": "ae/ae-03-wrangling-flights-A.html#group_by",
    "title": "AE 03: Wrangling flights",
    "section": "group_by()",
    "text": "group_by()\ngroup_by() is used for grouped operations. It’s very powerful when paired with summarise() to calculate summary statistics by group.\nHere we find the mean and standard deviation of departure delay for each month.\n\nflights |>\n  group_by(month) |>\n  summarize(\n    mean_dep_delay = mean(dep_delay, na.rm = TRUE), \n    sd_dep_delay = sd(dep_delay, na.rm = TRUE)\n    )\n\n# A tibble: 12 × 3\n   month mean_dep_delay sd_dep_delay\n   <int>          <dbl>        <dbl>\n 1     1          10.0          36.4\n 2     2          10.8          36.3\n 3     3          13.2          40.1\n 4     4          13.9          43.0\n 5     5          13.0          39.4\n 6     6          20.8          51.5\n 7     7          21.7          51.6\n 8     8          12.6          37.7\n 9     9           6.72         35.6\n10    10           6.24         29.7\n11    11           5.44         27.6\n12    12          16.6          41.9\n\n\n\nYour turn (4 minutes): What is the median departure delay for each airports around NYC (origin)? Which airport has the shortest median departure delay? Share your response on Slack on the relevant thread.\n\n\nflights |>\n  group_by(origin) |>\n  summarize(\n    med_dep_delay = median(dep_delay, na.rm = TRUE)\n    )\n\n# A tibble: 3 × 2\n  origin med_dep_delay\n  <chr>          <dbl>\n1 EWR               -1\n2 JFK               -1\n3 LGA               -3"
  },
  {
    "objectID": "ae/ae-08-dse-misrepresentation.html",
    "href": "ae/ae-08-dse-misrepresentation.html",
    "title": "AE 08: Data science ethics - Misrepresentation",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-08-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, Oct 7 at 11:59pm.\n\n\n\nPackages\n\nlibrary(tidyverse)\n\n\n\nPart 1 - People’s Poll\nGB News tweeted the following on Aug 26, 2022.\n\n\n\n\n\n\nQuestion: What is wrong with the visualization above?\n\nAdd your response here.\n\nYour turn (5 minutes): The data from this poll are at data/gbpoll.csv. First, load the data and confirm the number of responses match those mentioned in the tweet.\n\n# add code here\n\nThen, confirm that the proportions of intended votes match those mentioned in the tweet.\n\n# add code here\n\nDemo: Recreate the visualization from the tweet. You do not need to worry about matching the colors precisely and your bars should be correctly scaled.\n\n# add code here\n\nYour turn (10 minutes): Improve the visualization. State the improvements you made and why you made them. Discuss how these improvements help make the plot less misleading.\n\n# add code here\n\n\n\n\nPart 2 - Private sector\nThe following chart was shared by @GraphCrimes on Twitter on September 3, 2022.\n\n\n\n\n\n\nQuestion: What is misleading about this graph?\n\nAdd your response here.\n\nYour turn (6 minutes): If you needed to recreate this plot, with improvements to avoid its misleading pitfalls, what data do you need? How many variables? How many observations? Can you find the data online? Try looking for it for at least 3 minutes with a partner.\n\nAdd your response here.\n\nDemo: Load the data for this survey from data/survation.csv. First confirm that the data match the percentages from the visualization. Then, recreate the visualization, and improve it. Does the improved visualization look different than the original? Does it send a different message at a first glance?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-16-spam-filter.html",
    "href": "ae/ae-16-spam-filter.html",
    "title": "Building a spam filter",
    "section": "",
    "text": "Use logistic regression to fit a model for a binary response variable\nFit a logistic regression model in R\nUse a logistic regression model for classification\n\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <int> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         <dttm> 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       <fct> no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  <int> 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       <fct> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       <fct> big, small, small, small, none, none, big, small, small, …\n\n\nThe variables we’ll use in this analysis are\n\nspam: 1 if the email is spam, 0 otherwise\nexclaim_mess: The number of exclamation points in the email message\n\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-1",
    "href": "ae/ae-16-spam-filter.html#exercise-1",
    "title": "Building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nDemo: Fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\n\nlog_fit <- logistic_reg() |>\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  <chr>            <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\nYour turn: How does the code above differ from previous code we’ve used to fit regression models? Compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -1.9114 - 0.1684 \\times exclaim\\_mess\\]\nAdd response here."
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-2",
    "href": "ae/ae-16-spam-filter.html#exercise-2",
    "title": "Building a spam filter",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points?\n\nDemo: Answer the question using R as a calculator\n\n\n# add code here\n\n\nDemo: Answer the question using the predict() function.\n\nWe can use the predict function in R to produce the probability as well.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-3",
    "href": "ae/ae-16-spam-filter.html#exercise-3",
    "title": "Building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nYour turn: What are some trade offs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAdd response here.\n\naugment(log_fit, email) |>\n  select(spam, exclaim_mess, .pred_class) |>\n  ggplot(aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-4",
    "href": "ae/ae-16-spam-filter.html#exercise-4",
    "title": "Building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit a model with all variables in the dataset as predictors and receate the visualization above for this model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-data-import.html",
    "href": "ae/ae-07-data-import.html",
    "title": "AE 07: Data import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-07-data-import.html#nobel-winners",
    "href": "ae/ae-07-data-import.html#nobel-winners",
    "title": "AE 07: Data import",
    "section": "Nobel winners",
    "text": "Nobel winners\n\nDemo: Load the data from the data folder and assign it to nobel. Confirm that this new object appears in your Environment tab.\n\n# add code here\n\nYour turn (4 minutes): Split the data into two – nobel laureates in STEM fields (category should be Physics, Medicine, Chemistry, or Economics) and nobel laureates in non-STEM fields. Name these two new objects appropriately. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\n# define stem fields\n\n# add code here\n\n# stem laureates\n\n# add code here\n\n# non-steam laureates\n\n# add code here\n\nDemo: Write out the two new datasets you created into the data folder:\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-data-import.html#sales",
    "href": "ae/ae-07-data-import.html#sales",
    "title": "AE 07: Data import",
    "section": "Sales",
    "text": "Sales\nSales data are stored in an Excel file that looks like the following:\n\n\n\n\n\n\nDemo: Read in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\n# add code here\n\nDemo - Stretch goal: Manipulate the sales data such such that it looks like the following.\n\n\n# add code here\n\nQuestion: Why should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nAdd your response here."
  },
  {
    "objectID": "ae/ae-04-joining-fisheries-A.html",
    "href": "ae/ae-04-joining-fisheries-A.html",
    "title": "AE 04: Joining fisheries",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\n\nfisheries <- read_csv(\"data/fisheries.csv\")\ncontinents <- read_csv(\"data/continents.csv\")"
  },
  {
    "objectID": "ae/ae-04-joining-fisheries-A.html#working-with-multiple-data-frames",
    "href": "ae/ae-04-joining-fisheries-A.html#working-with-multiple-data-frames",
    "title": "AE 04: Joining fisheries",
    "section": "Working with multiple data frames",
    "text": "Working with multiple data frames\nOften instead of being provided the data you need for your analysis in a single data frame, you will need to bring information from multiple datasets together into a data frame yourself. These datasets will be linked to each other via a column (usually an identifier, something that links the two datasets together) that you can use to join them together.\nThere are many possible types of joins. All have the format something_join(x, y).\n\nx <- tibble(\n  value = c(1, 2, 3),\n  xcol = c(\"x1\", \"x2\", \"x3\")\n  )\n\ny <- tibble(\n  value = c(1, 2, 4),\n  ycol = c(\"y1\", \"y2\", \"y4\")\n  )\n\nx\n\n# A tibble: 3 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n  value ycol \n  <dbl> <chr>\n1     1 y1   \n2     2 y2   \n3     4 y4   \n\n\nWe will demonstrate each of the joins on these small, toy datasets.\n\ninner_join(): join all rows from x where there are matching values in y\n\ninner_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n\n\n\n\nleft_join(): include all rows from x\n\nleft_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n\n\n\n\nright_join(): include all rows from y\n\nright_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     4 <NA>  y4   \n\n\n\n\nfull_join(): include all rows in x or y (use this one sparingly!!)\n\nfull_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 4 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n4     4 <NA>  y4   \n\n\n\n\nsemi_join(): return all rows from x with match in y\n\nsemi_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n\n\n\n\nanti_join(): return all rows from x without a match in y\n\nanti_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 1 × 2\n  value xcol \n  <dbl> <chr>\n1     3 x3   \n\n\nQuestion: How do the join functions above know to join x and y by value? Hint: Examine the column names to find out.\n\nnames(x)\n\n[1] \"value\" \"xcol\" \n\nnames(y)\n\n[1] \"value\" \"ycol\""
  },
  {
    "objectID": "ae/ae-04-joining-fisheries-A.html#global-aquaculture-production",
    "href": "ae/ae-04-joining-fisheries-A.html#global-aquaculture-production",
    "title": "AE 04: Joining fisheries",
    "section": "Global aquaculture production",
    "text": "Global aquaculture production\nThe Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.\nOur goal is to create a visualization of the mean share of aquaculture by continent.\nLet’s start by looking at the fisheries data frame.\n\nglimpse(fisheries)\n\nRows: 82\nColumns: 4\n$ country     <chr> \"Angola\", \"Argentina\", \"Australia\", \"Bangladesh\", \"Brazil\"…\n$ capture     <dbl> 486490, 755226, 174629, 1674770, 705000, 629950, 233190, 8…\n$ aquaculture <dbl> 655, 3673, 96847, 2203554, 581230, 172500, 2315, 200765, 9…\n$ total       <dbl> 487145, 758899, 271476, 3878324, 1286230, 802450, 235505, …\n\n\nWe have the countries, but our goal is to make a visualization by continent. Let’s take a look at the continents data frame.\n\nglimpse(continents)\n\nRows: 245\nColumns: 2\n$ country   <chr> \"Afghanistan\", \"Åland Islands\", \"Albania\", \"Algeria\", \"Ameri…\n$ continent <chr> \"Asia\", \"Europe\", \"Europe\", \"Africa\", \"Oceania\", \"Europe\", \"…\n\n\n\nYour turn (2 minutes):\n\nWhich variable(s) will we use to join the fisheries and continents data frames?\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?\n\nDemo: Join the two data frames and name assign the joined data frame back to fisheries.\n\n\nfisheries <- fisheries |>\n  left_join(continents)\n\nJoining, by = \"country\"\n\n\n\nDemo: Take a look at the updated fisheries data frame. There are some countries that were not in continents. First, identify which countries these are (they will have NA values for continent). Then, manually update the continent information for these countries using the case_when function. Finally, check that these updates have been made as intended and no countries are left without continent information.\n\n\nfisheries |>\n  filter(is.na(continent))\n\n# A tibble: 3 × 5\n  country                          capture aquaculture   total continent\n  <chr>                              <dbl>       <dbl>   <dbl> <chr>    \n1 Democratic Republic of the Congo  237372        3161  240533 <NA>     \n2 Hong Kong                         142775        4258  147033 <NA>     \n3 Myanmar                          2072390     1017644 3090034 <NA>     \n\nfisheries <- fisheries %>%\n  mutate(\n    continent = case_when(\n      country == \"Democratic Republic of the Congo\" ~ \"Africa\",\n      country == \"Hong Kong\" ~ \"Asia\",\n      country == \"Myanmar\" ~ \"Asia\",\n      TRUE ~ continent\n    )\n  )\n\nfisheries |>\n  filter(is.na(continent))\n\n# A tibble: 0 × 5\n# … with 5 variables: country <chr>, capture <dbl>, aquaculture <dbl>,\n#   total <dbl>, continent <chr>\n\n\n\nDemo: Add a new column to the fisheries data frame called aq_prop. We will calculate it as aquaculture / total. Save the resulting frame as fisheries.\n\n\nfisheries <- fisheries |>\n  mutate(aq_prop = aquaculture / total)\n\n\nDemo: Calculate the mean aquaculture proportion (we’ll call it mean_aq_prop) for continents in the fisheries data using the summarize() function in dplyr. Note that the function for calculating the mean is mean() in R.\n\n\nfisheries |>                              # start with fisheries data frame\n  group_by(continent) |>                  # group by continent\n  summarize(mean_aq_prop = mean(aq_prop)) # calculate mean aquaculture\n\n# A tibble: 5 × 2\n  continent mean_aq_prop\n  <chr>            <dbl>\n1 Africa          0.0943\n2 Americas        0.192 \n3 Asia            0.367 \n4 Europe          0.165 \n5 Oceania         0.150 \n\n\n\nYour turn (5 minutes): Now expand your calculations to also calculate the minimum and maximum aquaculture proportion for continents in the fisheries data. Note that the functions for calculating minimum and maximum in R are min() and max() respectively.\n\n\nfisheries |>                              # start with fisheries data frame\n  group_by(continent) |>                  # group by continent\n  summarize(                              # calculate summary stats  \n    min_aq_prop  = min(aq_prop),\n    mean_aq_prop = mean(aq_prop),\n    max_aq_prop  = max(aq_prop)\n    )    \n\n# A tibble: 5 × 4\n  continent min_aq_prop mean_aq_prop max_aq_prop\n  <chr>           <dbl>        <dbl>       <dbl>\n1 Africa        0             0.0943       0.803\n2 Americas      0             0.192        0.529\n3 Asia          0             0.367        0.782\n4 Europe        0.00682       0.165        0.618\n5 Oceania       0.0197        0.150        0.357\n\n\n\nDemo: Create a new data frame called fisheries_summary that calculates minimum, mean, and maximum aquaculture proportion for each continent in the fisheries data. Then, determine which continent has the largest value of max_ap?\n\n\nfisheries_summary <- fisheries |>         # start with fisheries data frame\n  group_by(continent) |>                  # group by continent\n  summarize(                              # calculate summary stats  \n    min_aq_prop  = min(aq_prop),\n    mean_aq_prop = mean(aq_prop),\n    max_aq_prop  = max(aq_prop)\n    )\n\n\nDemo: Take the fisheries_summary data frame and order the results in descending order of mean aquaculture proportion.\n\n\nfisheries_summary |>            # start with fisheries_summary data frame\n  arrange(desc(mean_aq_prop))   # order in descending order of mean_aq_prop\n\n# A tibble: 5 × 4\n  continent min_aq_prop mean_aq_prop max_aq_prop\n  <chr>           <dbl>        <dbl>       <dbl>\n1 Asia          0             0.367        0.782\n2 Americas      0             0.192        0.529\n3 Europe        0.00682       0.165        0.618\n4 Oceania       0.0197        0.150        0.357\n5 Africa        0             0.0943       0.803\n\n\n\nDemo: Recreate the following plot using the data frame you have developed so far.\n\n\n\n\n\n\n\nggplot(fisheries_summary, \n       aes(y = fct_reorder(continent, mean_aq_prop), x = mean_aq_prop)) +\n  geom_col() +\n  scale_x_continuous(labels = label_percent(accuracy = 1)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Average share of aquaculture by continent\",\n    subtitle = \"out of total fisheries harvest, 2016\",\n    caption = \"Source: bit.ly/2VrawTt\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nYour turn (time permitting): Change the theme of the plot and make any other changes you would like to improve it.\n\n\n# add your code here"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in R, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count."
  },
  {
    "objectID": "project-tips-resources.html#suppress-code-and-warnings",
    "href": "project-tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your report.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false"
  },
  {
    "objectID": "project-tips-resources.html#headers",
    "href": "project-tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels."
  },
  {
    "objectID": "project-tips-resources.html#references",
    "href": "project-tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called “References” at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto’s citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that."
  },
  {
    "objectID": "project-tips-resources.html#appendix",
    "href": "project-tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix."
  },
  {
    "objectID": "project-tips-resources.html#resize-figures",
    "href": "project-tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: plot1\n#| fig-height: 3\n#| fig-width: 5\nreplacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-height and fig-width options in the YAML header as shown below:\nexecute:\n  fig-height: 3\n  fig-width: 5\nReplace the height and width values with values appropriate for your write up."
  },
  {
    "objectID": "project-tips-resources.html#arranging-plots",
    "href": "project-tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid.\nMore to be added soon…"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "If this is your first time accessing the containers, click on reserve STA198-199 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA198-199 under My reservations to access the RStudio instance you’ll use for the course."
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Intro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language. No statistical or computing background is necessary. Not open to students who have taken a 100-level Statistical Science course, Statistical Science 210, or a Statistical Science course numbered 300 or above."
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nFrench Science 2231\nTue & Thur 10:15 - 11:30 am\n\n\nLab 01\nPerkins Link 087 (Classroom 3)\nMon 10:15 - 11:30 am\n\n\nLab 02\nPerkins Link 087 (Classroom 3)\nMon 1:45 - 3:00 pm\n\n\nLab 03\nPerkins Link 087 (Classroom 3)\nMon 3:30 - 4:45 pm\n\n\nLab 04\nPerkins Link 087 (Classroom 3)\nMon 5:15 - 6:30 pm\n\n\nLab 05\nPerkins Link 087 (Classroom 3)\nMon 12:00 - 1:15 pm"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199: Introduction to Data Science",
    "section": "",
    "text": "week\n      dow\n      date\n      what\n      topic\n      prepare\n      slides\n      ae\n      hw\n      lab\n      exam\n      project\n      notes\n    \n  \n  \n    1\nW\nJan 11\nLab 0\nHello R!\n\n\n\n\n\n\n\n\n    \nF\nJan 13\nLec 1\nWelcome to STA 199\n\n\n\n\n\n\n\n\n    2\nM\nJan 16\n\nNo class -- Martin Luther King Jr. Day\n\n\n\n\n\n\n\n\n    \nW\nJan 18\nLec 2\n\n\n\n\n\n\n\n\n\n    \nF\nJan 20\nLec 3\n\n\n\n\n\n\n\n\n\n    3\nM\nJan 23\nLab 1\n\n\n\n\n\n\n\n\n\n    \nW\nJan 25\nLec 4\n\n\n\n\n\n\n\n\n\n    \nF\nJan 27\nLec 5\n\n\n\n\n\n\n\n\n\n    4\nM\nJan 30\nLab 2\n\n\n\n\n\n\n\n\n\n    \nW\nFeb 1\nLec 6\n\n\n\n\n\n\n\n\n\n    \nF\nFeb 3\nLec 7\n\n\n\n\n\n\n\n\n\n    5\nM\nFeb 6\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nFeb 8\nLec 8\n\n\n\n\n\n\n\n\n\n    \nF\nFeb 10\nLec 9\n\n\n\n\n\n\n\n\n\n    6\nM\nFeb 13\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nFeb 15\nLec 10\n\n\n\n\n\n\n\n\n\n    \nF\nFeb 17\nLec 11\n\n\n\n\n\n\n\n\n\n    7\nM\nFeb 20\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nFeb 22\nLec 12\n\n\n\n\n\n\n\n\n\n    \nF\nFeb 24\nLec 13\n\n\n\n\n\n\n\n\n\n    8\nM\nFeb 27\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nMar 1\nLec 14\n\n\n\n\n\n\n\n\n\n    \nF\nMar 3\nLec 15\n\n\n\n\n\n\n\n\n\n    9\nM\nMar 6\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nMar 8\nLec 16\n\n\n\n\n\n\n\n\n\n    \nF\nMar 10\nLec 17\n\n\n\n\n\n\n\n\n\n    10\nM\nMar 13\n\nNo class -- Spring Break\n\n\n\n\n\n\n\n\n    \nW\nMar 15\n\nNo class -- Spring Break\n\n\n\n\n\n\n\n\n    \nF\nMar 17\n\nNo class -- Spring Break\n\n\n\n\n\n\n\n\n    11\nM\nMar 20\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nMar 22\nLec 18\n\n\n\n\n\n\n\n\n\n    \nF\nMar 24\nLec 19\n\n\n\n\n\n\n\n\n\n    12\nM\nMar 27\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nMar 29\nLec 20\n\n\n\n\n\n\n\n\n\n    \nF\nMar 31\nLec 21\n\n\n\n\n\n\n\n\n\n    13\nM\nApr 3\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nApr 5\nLec 22\n\n\n\n\n\n\n\n\n\n    \nF\nApr 7\nLec 23\n\n\n\n\n\n\n\n\n\n    14\nM\nApr 10\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nApr 12\nLec 24\n\n\n\n\n\n\n\n\n\n    \nF\nApr 14\nLec 25\n\n\n\n\n\n\n\n\n\n    15\nM\nApr 17\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nApr 19\nLec 26\n\n\n\n\n\n\n\n\n\n    \nF\nApr 21\nLec 27\n\n\n\n\n\n\n\n\n\n    16\nM\nApr 24\nLab\n\n\n\n\n\n\n\n\n\n    \nW\nApr 26\nLec 28"
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine also works with RStudio as a Developer Educator.\n\n\n\nOffice hours\nLocation\n\n\n\n\nTue 2 pm - 4 pm\nOld Chem 213"
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\n\nName\nRole\nLab section\n\n\n\n\nBora Jin\nTA / Course organizer\nM 10:15AM - 11:30AM\n\n\nJordan Bryan\nHead TA\nM 1:45PM - 3:00PM\n\n\nRichard Fremgen\nTA\nM 3:30PM - 4:45PM\n\n\nLeah Johnson\nTA\nM 5:15PM - 6:30PM\n\n\nAlison Reynolds\nTA\nM 12:00PM - 1:15PM\n\n\nFoxx Hart\nTA\n\n\n\nAlonso Guerrero Castaneda\nTA\n\n\n\nJasmine Wen\nTA\n\n\n\nBrooke Harmon\nTA\n\n\n\nAmber Potter\nTA\n\n\n\nOne Chowdhury\nTA\n\n\n\n\nFor office hours, please see STA 199 - Ultimate Office Hours sheet."
  },
  {
    "objectID": "slides/25-quarto.html#course-evaluations",
    "href": "slides/25-quarto.html#course-evaluations",
    "title": "Customizing Quarto reports and presentations",
    "section": "Course evaluations",
    "text": "Course evaluations\n\nYour investment in completing the course and TA evaluation thoughtfully for about 10 minutes today will not only help instructors improve their courses, but their instruction techniques as well.\nMost of the ratings and responses you provide in your evaluations this semester will be shared with future students. The more students that contribute evaluations, the more access every student will have to course evaluation data when making future course enrollment decisions.\nYou can address the evaluation forms through links in email reminders or by logging in to duke.evaluationkit.com (for course evaluations).\nGoal: If we can hit 80% response rate on both course and TA evaluations, everyone in the class will get an additional point on their HW average."
  },
  {
    "objectID": "slides/25-quarto.html#time-for-course-evaluations",
    "href": "slides/25-quarto.html#time-for-course-evaluations",
    "title": "Customizing Quarto reports and presentations",
    "section": "Time for course evaluations",
    "text": "Time for course evaluations\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/25-quarto.html#project-presentations-on-monday",
    "href": "slides/25-quarto.html#project-presentations-on-monday",
    "title": "Customizing Quarto reports and presentations",
    "section": "Project presentations on Monday! 🥳",
    "text": "Project presentations on Monday! 🥳\n\nMake sure your presentation is pushed to your GitHub repo before your lab section.\nGet to lab on time, 5 minutes prior if possible – all team members must be present in class and take part in the presentation + Q&A\nFind out your presentation order when you get there.\nDeliver or play your 5-minute presentation.\nAnswer questions during your own Q&A or ask questions to others.\nFill out feedback forms while you listen to others’ presentations."
  },
  {
    "objectID": "slides/25-quarto.html#project-write-ups-due-thursday",
    "href": "slides/25-quarto.html#project-write-ups-due-thursday",
    "title": "Customizing Quarto reports and presentations",
    "section": "Project write-ups due Thursday",
    "text": "Project write-ups due Thursday\n\nThere’s a good chance you’ll be done with these on Monday as well\nBut you might want to improve your write-up based on inspiration from other teams’ presentations and/or ideas that came up during your Q&A.\nProject repos will close at 11:59pm on Thursday. There is no Gradescope submission, just push your final edits to GitHub."
  },
  {
    "objectID": "slides/25-quarto.html#writing-your-project-report-with-quarto",
    "href": "slides/25-quarto.html#writing-your-project-report-with-quarto",
    "title": "Customizing Quarto reports and presentations",
    "section": "Writing your project report with Quarto",
    "text": "Writing your project report with Quarto\n\nFigure sizing: fig-width, fig-height, etc. in code chunks.\nFigure layout: layout-ncol for placing multiple figures in a chunk.\nFurther control over figure layout with the patchwork package.\nChunk options around what makes it in your final report: message, echo, etc.\nCitations.\nFinalizing your report with echo: false."
  },
  {
    "objectID": "slides/25-quarto.html#building-your-project-website-with-quarto",
    "href": "slides/25-quarto.html#building-your-project-website-with-quarto",
    "title": "Customizing Quarto reports and presentations",
    "section": "Building your project website with Quarto",
    "text": "Building your project website with Quarto\n\nThe docs folder.\nMaking sure your website reflects your latest changes.\nCustomizing the look of your website."
  },
  {
    "objectID": "slides/25-quarto.html#the-presentation",
    "href": "slides/25-quarto.html#the-presentation",
    "title": "Customizing Quarto reports and presentations",
    "section": "The presentation",
    "text": "The presentation\n\nOption 1: Make your slides not in Quarto but make sure they’re available in your Quarto project website.\nOption 2: Make your slides with Quarto.\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/15-language-of-models.html#while-you-wait-for-class-to-begin",
    "href": "slides/15-language-of-models.html#while-you-wait-for-class-to-begin",
    "title": "The language of models",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\nClone your ae-12 project from GitHub, render your document, update your name, and commit and push."
  },
  {
    "objectID": "slides/15-language-of-models.html#announcements",
    "href": "slides/15-language-of-models.html#announcements",
    "title": "The language of models",
    "section": "Announcements",
    "text": "Announcements\n\nProject proposals due Friday"
  },
  {
    "objectID": "slides/15-language-of-models.html#goals",
    "href": "slides/15-language-of-models.html#goals",
    "title": "The language of models",
    "section": "Goals",
    "text": "Goals\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/15-language-of-models.html#setup",
    "href": "slides/15-language-of-models.html#setup",
    "title": "The language of models",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(gt)"
  },
  {
    "objectID": "slides/15-language-of-models.html#modelling-cars",
    "href": "slides/15-language-of-models.html#modelling-cars",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 5000 pounds?"
  },
  {
    "objectID": "slides/15-language-of-models.html#modelling-1",
    "href": "slides/15-language-of-models.html#modelling-1",
    "title": "The language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/15-language-of-models.html#modelling-vocabulary",
    "href": "slides/15-language-of-models.html#modelling-vocabulary",
    "title": "The language of models",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\nCorrelation"
  },
  {
    "objectID": "slides/15-language-of-models.html#predictor-explanatory-variable",
    "href": "slides/15-language-of-models.html#predictor-explanatory-variable",
    "title": "The language of models",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      mpg\n      wt\n    \n  \n  \n    21\n2.62\n    21\n2.875\n    22.8\n2.32\n    21.4\n3.215\n    18.7\n3.44\n    18.1\n3.46\n    ...\n..."
  },
  {
    "objectID": "slides/15-language-of-models.html#outcome-response-variable",
    "href": "slides/15-language-of-models.html#outcome-response-variable",
    "title": "The language of models",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\n  \n  \n    \n      mpg\n      wt\n    \n  \n  \n    21\n2.62\n    21\n2.875\n    22.8\n2.32\n    21.4\n3.215\n    18.7\n3.44\n    18.1\n3.46\n    ...\n..."
  },
  {
    "objectID": "slides/15-language-of-models.html#regression-line",
    "href": "slides/15-language-of-models.html#regression-line",
    "title": "The language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/15-language-of-models.html#regression-line-slope",
    "href": "slides/15-language-of-models.html#regression-line-slope",
    "title": "The language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/15-language-of-models.html#regression-line-intercept",
    "href": "slides/15-language-of-models.html#regression-line-intercept",
    "title": "The language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/15-language-of-models.html#correlation",
    "href": "slides/15-language-of-models.html#correlation",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/15-language-of-models.html#correlation-1",
    "href": "slides/15-language-of-models.html#correlation-1",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/15-language-of-models.html#visualizing-the-model",
    "href": "slides/15-language-of-models.html#visualizing-the-model",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/15-language-of-models.html#ae-12",
    "href": "slides/15-language-of-models.html#ae-12",
    "title": "The language of models",
    "section": "ae-12",
    "text": "ae-12\n\n\n\nGo to the course GitHub org and find your ae-12 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/26-text-analysis.html#while-you-wait",
    "href": "slides/26-text-analysis.html#while-you-wait",
    "title": "Looking further: Text analysis",
    "section": "While you wait",
    "text": "While you wait\n\nFill out course + TA evaluations\nClone ae-21"
  },
  {
    "objectID": "slides/26-text-analysis.html#announcements",
    "href": "slides/26-text-analysis.html#announcements",
    "title": "Looking further: Text analysis",
    "section": "Announcements",
    "text": "Announcements\n\nCourse + TA evaluations – We’re at ~40% only\nAny project questions? Any questions about remaining assessments?"
  },
  {
    "objectID": "slides/26-text-analysis.html#tidytext",
    "href": "slides/26-text-analysis.html#tidytext",
    "title": "Looking further: Text analysis",
    "section": "Tidytext",
    "text": "Tidytext\n\n\n\nUsing tidy data principles can make many text mining tasks easier, more effective, and consistent with tools already in wide use\nLearn more at tidytextmining.com\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidytext)"
  },
  {
    "objectID": "slides/26-text-analysis.html#what-is-tidy-text",
    "href": "slides/26-text-analysis.html#what-is-tidy-text",
    "title": "Looking further: Text analysis",
    "section": "What is tidy text?",
    "text": "What is tidy text?\n\ntext <- c(\"Oh! Get me away from here, I'm dying\",\n          \"Play me a song to set me free\",\n          \"Nobody writes them like they used to\",\n          \"So it may as well be me\",\n          \"Here on my own now after hours\",\n          \"Here on my own now on a bus\",\n          \"Think of it this way\",\n          \"You could either be successful or be us\",\n          \"With our winning smiles, and us\",\n          \"With our catchy tunes or worse\",\n          \"Now we're photogenic\",\n          \"You know, we don't stand a chance\")\ntext\n\n [1] \"Oh! Get me away from here, I'm dying\"   \n [2] \"Play me a song to set me free\"          \n [3] \"Nobody writes them like they used to\"   \n [4] \"So it may as well be me\"                \n [5] \"Here on my own now after hours\"         \n [6] \"Here on my own now on a bus\"            \n [7] \"Think of it this way\"                   \n [8] \"You could either be successful or be us\"\n [9] \"With our winning smiles, and us\"        \n[10] \"With our catchy tunes or worse\"         \n[11] \"Now we're photogenic\"                   \n[12] \"You know, we don't stand a chance\""
  },
  {
    "objectID": "slides/26-text-analysis.html#what-is-tidy-text-1",
    "href": "slides/26-text-analysis.html#what-is-tidy-text-1",
    "title": "Looking further: Text analysis",
    "section": "What is tidy text?",
    "text": "What is tidy text?\n\ntext_df <- tibble(line = 1:12, text = text)\ntext_df |> print(n = 12)\n\n# A tibble: 12 × 2\n    line text                                   \n   <int> <chr>                                  \n 1     1 Oh! Get me away from here, I'm dying   \n 2     2 Play me a song to set me free          \n 3     3 Nobody writes them like they used to   \n 4     4 So it may as well be me                \n 5     5 Here on my own now after hours         \n 6     6 Here on my own now on a bus            \n 7     7 Think of it this way                   \n 8     8 You could either be successful or be us\n 9     9 With our winning smiles, and us        \n10    10 With our catchy tunes or worse         \n11    11 Now we're photogenic                   \n12    12 You know, we don't stand a chance"
  },
  {
    "objectID": "slides/26-text-analysis.html#what-is-tidy-text-2",
    "href": "slides/26-text-analysis.html#what-is-tidy-text-2",
    "title": "Looking further: Text analysis",
    "section": "What is tidy text?",
    "text": "What is tidy text?\n\ntext_df |>\n  unnest_tokens(word, text)\n\n# A tibble: 80 × 2\n    line word \n   <int> <chr>\n 1     1 oh   \n 2     1 get  \n 3     1 me   \n 4     1 away \n 5     1 from \n 6     1 here \n 7     1 i'm  \n 8     1 dying\n 9     2 play \n10     2 me   \n# … with 70 more rows"
  },
  {
    "objectID": "slides/26-text-analysis.html#counting-words",
    "href": "slides/26-text-analysis.html#counting-words",
    "title": "Looking further: Text analysis",
    "section": "Counting words",
    "text": "Counting words\n\ntext_df |>\n  unnest_tokens(word, text) |>\n  count(word, sort = TRUE)\n\n# A tibble: 58 × 2\n   word      n\n   <chr> <int>\n 1 me        4\n 2 a         3\n 3 be        3\n 4 here      3\n 5 now       3\n 6 on        3\n 7 it        2\n 8 my        2\n 9 or        2\n10 our       2\n# … with 48 more rows"
  },
  {
    "objectID": "slides/26-text-analysis.html#ae-21",
    "href": "slides/26-text-analysis.html#ae-21",
    "title": "Looking further: Text analysis",
    "section": "ae-21",
    "text": "ae-21\n\n\n\nGo to the course GitHub org and find your ae-21 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/08-data-types-classes.html#while-you-wait-for-class-to-begin",
    "href": "slides/08-data-types-classes.html#while-you-wait-for-class-to-begin",
    "title": "Data types and classes",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\nOpen your ae-05 project (from last time) in RStudio, render your document, and commit and push. Make sure you have your “first draft” plot ready to go.\nAny questions from prepare materials? Go to slido.com / #sta199. You can also upvote others’ questions."
  },
  {
    "objectID": "slides/08-data-types-classes.html#announcements",
    "href": "slides/08-data-types-classes.html#announcements",
    "title": "Data types and classes",
    "section": "Announcements",
    "text": "Announcements\n\nHW 2 due tonight (11:59 pm)\nLab 2 due tomorrow night (11:59 pm)"
  },
  {
    "objectID": "slides/08-data-types-classes.html#review-logical-operators",
    "href": "slides/08-data-types-classes.html#review-logical-operators",
    "title": "Data types and classes",
    "section": "Review: Logical operators",
    "text": "Review: Logical operators\n\n\n\n\n\n\n\n\n\nx < y\ntest if x less than y\n\n\nx <= y\ntest if x less than or equal to y\n\n\nx > y\ntest if x greater than y\n\n\nx >= y\ntest if x greater than or equal to y\n\n\nx == y\ntest if x is equal to y\n\n\nx != y\ntest if x is not equal to y\n\n\n\n\n\n\n\n\n\n\n\n\n\nis.na(x)\ntest if x is NA\n\n\n!is.na(x)\ntest if x is not NA\n\n\nx %in% y\ntest if x is in y\n\n\n!(x %in% y)\ntest if x is not in y\n\n\n!x\ntest for not x\n\n\nx & y\ntest for x and y\n\n\nx | y\ntest for x or y"
  },
  {
    "objectID": "slides/08-data-types-classes.html#question-from-last-time",
    "href": "slides/08-data-types-classes.html#question-from-last-time",
    "title": "Data types and classes",
    "section": "Question from last time",
    "text": "Question from last time\n\nWhat is the difference between is.na() and na.rm?\n\nis.na() checks for NAs and returns TRUE or FALSE – it’s a function.\n\nx <- c(1, 2, NA)\nis.na(x)\n\n[1] FALSE FALSE  TRUE\n\n\nna.rm removes NAs before applying a function – it’s an argument in a function.\n\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 1.5"
  },
  {
    "objectID": "slides/08-data-types-classes.html#continue-from-last-time-ae-05",
    "href": "slides/08-data-types-classes.html#continue-from-last-time-ae-05",
    "title": "Data types and classes",
    "section": "Continue from last time: ae-05",
    "text": "Continue from last time: ae-05\n\n\nGo to your container and open your ae-05 project.\nRender, commit, and push before getting started again."
  },
  {
    "objectID": "slides/08-data-types-classes.html#recap-of-ae",
    "href": "slides/08-data-types-classes.html#recap-of-ae",
    "title": "Data types and classes",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/08-data-types-classes.html#types-and-classes-1",
    "href": "slides/08-data-types-classes.html#types-and-classes-1",
    "title": "Data types and classes",
    "section": "Types and classes",
    "text": "Types and classes\n\nType is how an object is stored in memory, e.g.,\n\ndouble: a real number stored in double-precision floatint point format.\ninteger: an integer (positive or negative)\n\n\n– Class is metadata about the object that can determine how common functions operate on that object, e.g.,\n\nfactor"
  },
  {
    "objectID": "slides/08-data-types-classes.html#types-of-vectors",
    "href": "slides/08-data-types-classes.html#types-of-vectors",
    "title": "Data types and classes",
    "section": "Types of vectors",
    "text": "Types of vectors\n\n\nYou’ll commonly encounter:\n\nlogical\ninteger\ndouble\ncharacter\n\n\nYou’ll less commonly encounter:\n\nlist\nNULL\ncomplex\nraw"
  },
  {
    "objectID": "slides/08-data-types-classes.html#types-of-functions",
    "href": "slides/08-data-types-classes.html#types-of-functions",
    "title": "Data types and classes",
    "section": "Types of functions",
    "text": "Types of functions\nYes, functions have types too, but you don’t need to worry about the differences in the context of doing data science.\n\ntypeof(mean) # regular function\n\n[1] \"closure\"\n\ntypeof(`$`) # internal function\n\n[1] \"special\"\n\ntypeof(sum) # primitive function\n\n[1] \"builtin\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#factors",
    "href": "slides/08-data-types-classes.html#factors",
    "title": "Data types and classes",
    "section": "Factors",
    "text": "Factors\nA factor is a vector that can contain only predefined values. It is used to store categorical data.\n\n\n\nx <- factor(c(\"a\", \"b\", \"b\", \"a\"))\nx\n\n[1] a b b a\nLevels: a b\n\ntypeof(x)\n\n[1] \"integer\"\n\nattributes(x)\n\n$levels\n[1] \"a\" \"b\"\n\n$class\n[1] \"factor\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#other-classes",
    "href": "slides/08-data-types-classes.html#other-classes",
    "title": "Data types and classes",
    "section": "Other classes",
    "text": "Other classes\nJust a couple of examples…\n\n\nDate:\n\ntoday <- Sys.Date()\ntoday\n\n[1] \"2022-11-09\"\n\ntypeof(today)\n\n[1] \"double\"\n\nattributes(today)\n\n$class\n[1] \"Date\"\n\n\n\nDate-time:\n\nnow <- as.POSIXct(\"2022-09-22 10:15\", tz = \"EST\")\nnow\n\n[1] \"2022-09-22 10:15:00 EST\"\n\ntypeof(now)\n\n[1] \"double\"\n\nattributes(now)\n\n$class\n[1] \"POSIXct\" \"POSIXt\" \n\n$tzone\n[1] \"EST\""
  },
  {
    "objectID": "slides/14-functions-iteration.html#while-you-wait-for-class-to-begin",
    "href": "slides/14-functions-iteration.html#while-you-wait-for-class-to-begin",
    "title": "Functions and iteration",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\nClone your ae-11 project from GitHub, render your document, update your name, and commit and push."
  },
  {
    "objectID": "slides/14-functions-iteration.html#announcements",
    "href": "slides/14-functions-iteration.html#announcements",
    "title": "Functions and iteration",
    "section": "Announcements",
    "text": "Announcements\n\nProject proposals due Friday\nNo in person OH today (but I’ll be at majors fair!). OH on Zoom 8-9pm tonight (Tuesday) and Wednesday. Will email reminder with Zoom link + add to OH sheet.\nMake sure to review the video/reading for Thursday!"
  },
  {
    "objectID": "slides/14-functions-iteration.html#midterm-feedback-followup",
    "href": "slides/14-functions-iteration.html#midterm-feedback-followup",
    "title": "Functions and iteration",
    "section": "Midterm feedback followup",
    "text": "Midterm feedback followup\n\nCan be difficult to catch up on AEs if bits are missed.\n\nWill post AE solutions after class instead of waiting for the deadline. You still need to attempt them to get points."
  },
  {
    "objectID": "slides/14-functions-iteration.html#recap-of-ae-10",
    "href": "slides/14-functions-iteration.html#recap-of-ae-10",
    "title": "Functions and iteration",
    "section": "Recap of ae-10",
    "text": "Recap of ae-10\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/14-functions-iteration.html#a-new-r-workflow",
    "href": "slides/14-functions-iteration.html#a-new-r-workflow",
    "title": "Functions and iteration",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/14-functions-iteration.html#ethics-can-you-vs-should-you",
    "href": "slides/14-functions-iteration.html#ethics-can-you-vs-should-you",
    "title": "Functions and iteration",
    "section": "Ethics: “Can you?” vs “Should you?”",
    "text": "Ethics: “Can you?” vs “Should you?”\n\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/14-functions-iteration.html#can-you-vs-should-you",
    "href": "slides/14-functions-iteration.html#can-you-vs-should-you",
    "title": "Functions and iteration",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”"
  },
  {
    "objectID": "slides/14-functions-iteration.html#challenges-unreliable-formatting",
    "href": "slides/14-functions-iteration.html#challenges-unreliable-formatting",
    "title": "Functions and iteration",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/14-functions-iteration.html#challenges-data-broken-into-many-pages",
    "href": "slides/14-functions-iteration.html#challenges-data-broken-into-many-pages",
    "title": "Functions and iteration",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/14-functions-iteration.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/14-functions-iteration.html#workflow-screen-scraping-vs.-apis",
    "title": "Functions and iteration",
    "section": "Workflow: Screen scraping vs. APIs",
    "text": "Workflow: Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files"
  },
  {
    "objectID": "slides/14-functions-iteration.html#functions-in-r",
    "href": "slides/14-functions-iteration.html#functions-in-r",
    "title": "Functions and iteration",
    "section": "Functions in R",
    "text": "Functions in R\n\nWhat are some functions you’ve learned? What are their inputs, what are their outputs?"
  },
  {
    "objectID": "slides/14-functions-iteration.html#mean",
    "href": "slides/14-functions-iteration.html#mean",
    "title": "Functions and iteration",
    "section": "mean()",
    "text": "mean()\n\nx <- c(1, 2, 3, 4, 5)\nmean(x)\n\n[1] 3"
  },
  {
    "objectID": "slides/14-functions-iteration.html#custom-function-multiply_by_two",
    "href": "slides/14-functions-iteration.html#custom-function-multiply_by_two",
    "title": "Functions and iteration",
    "section": "Custom function: multiply_by_two()",
    "text": "Custom function: multiply_by_two()\n\n\nDecide on a goal: Multiply by two\nDecide on the number and type of inputs: 1 (a numeric vector of length 1)\nDecide on the number and type of outputs: 1 (a numeric vector of length 1)\n\n\n\n\nmultiply_by_two <- function(x){\n  x * 2\n}\n\n\n\n\nmultiply_by_two(1)\n\n[1] 2\n\nmultiply_by_two(2)\n\n[1] 4\n\nmultiply_by_two(3)\n\n[1] 6"
  },
  {
    "objectID": "slides/14-functions-iteration.html#custom-function-multiply",
    "href": "slides/14-functions-iteration.html#custom-function-multiply",
    "title": "Functions and iteration",
    "section": "Custom function: multiply()",
    "text": "Custom function: multiply()\n\n\nDecide on a goal: Multiply by a given value\nDecide on the number and type of inputs: 2 (two numeric vectors of length 1)\nDecide on the number and type of outputs: 1 (a numeric vector of length 1)\n\n\n\n\nmultiply <- function(x, y){\n  x * y\n}\n\n\n\n\nmultiply(1, 3)\n\n[1] 3\n\nmultiply(2, 5)\n\n[1] 10\n\nmultiply(10, 35)\n\n[1] 350"
  },
  {
    "objectID": "slides/14-functions-iteration.html#custom-function-temp_convert",
    "href": "slides/14-functions-iteration.html#custom-function-temp_convert",
    "title": "Functions and iteration",
    "section": "Custom function: temp_convert()",
    "text": "Custom function: temp_convert()\n\nGoal: Convert temperatures in degrees Fahrenheit to Celsius; subtract 32 and multiply by \\(\\frac{5}{9}\\).\nNumber and type of inputs: 1 (a numeric vector of length 1)\nNumber and type of outputs: 1 (a numeric vector of length 1)\n\n\n\ntemp_convert <- function(temp_f){\n  (temp_f - 32) * 5/9\n}"
  },
  {
    "objectID": "slides/14-functions-iteration.html#test-out-the-function",
    "href": "slides/14-functions-iteration.html#test-out-the-function",
    "title": "Functions and iteration",
    "section": "Test out the function",
    "text": "Test out the function\n\ntemp_convert(32)   # freezing point\n\n[1] 0\n\n\n\n\ntemp_convert(360)  # cake baking temperature\n\n[1] 182.2222\n\n\n\n\n\ntemp_convert(98.6) # body temperature\n\n[1] 37"
  },
  {
    "objectID": "slides/14-functions-iteration.html#why-do-we-need-functions",
    "href": "slides/14-functions-iteration.html#why-do-we-need-functions",
    "title": "Functions and iteration",
    "section": "Why do we need functions?",
    "text": "Why do we need functions?\n\n\nRepeat yourself:\n\n# freezing point\n(32 - 32) * (5/9)\n\n[1] 0\n\n# cake baking temperature\n(360 - 32) * (5/9)\n\n[1] 182.2222\n\n# body temperature\n(98.6 - 32) * (5/9)\n\n[1] 37\n\n\n\nDo not repeat yourself (DRY):\n\n# freezing point\ntemp_convert(32)\n\n[1] 0\n\n# cake baking temperature\ntemp_convert(360)\n\n[1] 182.2222\n\n# body temperature\ntemp_convert(98.6)\n\n[1] 37"
  },
  {
    "objectID": "slides/14-functions-iteration.html#seriously-dry",
    "href": "slides/14-functions-iteration.html#seriously-dry",
    "title": "Functions and iteration",
    "section": "Seriously, DRY!",
    "text": "Seriously, DRY!\nLoad package:\n\nlibrary(tidyverse)\n\n\nDefine input vector:\n\nx <- c(32, 360, 98.6)\nx\n\n[1]  32.0 360.0  98.6\n\n\n\n\nMap your function over the elements of the input vector:\n\nmap(x, temp_convert)\n\n[[1]]\n[1] 0\n\n[[2]]\n[1] 182.2222\n\n[[3]]\n[1] 37\n\n\n\nControl the type of your output:\n\nmap_dbl(x, temp_convert)\n\n[1]   0.0000 182.2222  37.0000"
  },
  {
    "objectID": "slides/14-functions-iteration.html#iteration",
    "href": "slides/14-functions-iteration.html#iteration",
    "title": "Functions and iteration",
    "section": "Iteration",
    "text": "Iteration\nTo apply the same function to multiple values (stored in an object like a vector), use map() functions:\n\n\nmap() returns a list\nmap_lgl(), map_int(), map_dbl() and map_chr() return an atomic vector of the indicated type (logical, integer, double, or character, respectively)\nmap_dfr() and map_dfc() return a data frame created by row-binding and column-binding, respectively"
  },
  {
    "objectID": "slides/14-functions-iteration.html#coming-soon",
    "href": "slides/14-functions-iteration.html#coming-soon",
    "title": "Functions and iteration",
    "section": "Coming soon…",
    "text": "Coming soon…\n\n\nUse a function that takes a data frame and names of variables in that data frame\nFits a regression model for predicting one specified variable from the others given\nReports the model results along with measurements on prediction error and other diagnostic values"
  },
  {
    "objectID": "slides/14-functions-iteration.html#coming-now",
    "href": "slides/14-functions-iteration.html#coming-now",
    "title": "Functions and iteration",
    "section": "Coming now",
    "text": "Coming now\n\n\nWrite a function that scrapes data from a single page and outputs a data frame with items of interest from that page\nMap that function over multiple pages to get a bigger data frame with items of interest from all pages\nItems of interest: Amazon reviews of Yankee Candles"
  },
  {
    "objectID": "slides/14-functions-iteration.html#yankee-candle-reviews-and-covid",
    "href": "slides/14-functions-iteration.html#yankee-candle-reviews-and-covid",
    "title": "Functions and iteration",
    "section": "Yankee Candle reviews and COVID",
    "text": "Yankee Candle reviews and COVID\n\n\n\n\n\n\n\nSource: @kate_ptrv on Twitter + GitHub"
  },
  {
    "objectID": "slides/14-functions-iteration.html#goal",
    "href": "slides/14-functions-iteration.html#goal",
    "title": "Functions and iteration",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data from multiple pages and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualize the data"
  },
  {
    "objectID": "slides/14-functions-iteration.html#ae-11",
    "href": "slides/14-functions-iteration.html#ae-11",
    "title": "Functions and iteration",
    "section": "ae-11",
    "text": "ae-11\n\n\n\nGo to the course GitHub org and find your ae-11 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/01-welcome-199.html#meet-the-prof",
    "href": "slides/01-welcome-199.html#meet-the-prof",
    "title": "Welcome to STA 199",
    "section": "Meet the prof",
    "text": "Meet the prof\n\n\nDr. Mine Çetinkaya-Rundel\nProfessor of the Practice\nOld Chem 213"
  },
  {
    "objectID": "slides/01-welcome-199.html#meet-the-course-team",
    "href": "slides/01-welcome-199.html#meet-the-course-team",
    "title": "Welcome to STA 199",
    "section": "Meet the course team",
    "text": "Meet the course team\n\nFoxx Hart - Lecture helper\nBora Jin - Course organizer, lab leader\nJordan Bryan - Head TA, lab leader\nRichard Fremgen - Lab leader\nLeah Johnson - Lab leader\nAlison Reynolds - Lab leader\nBrooke Harmon - Lab helper\nJasmine Wen - Lab helper\nAmber Potter - Lab helper\nShawon (One) Chowdhury - Lab helper\nGaurav Sirdeshmukh - Lab helper"
  },
  {
    "objectID": "slides/01-welcome-199.html#meet-each-other",
    "href": "slides/01-welcome-199.html#meet-each-other",
    "title": "Welcome to STA 199",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/01-welcome-199.html#meet-data-science",
    "href": "slides/01-welcome-199.html#meet-data-science",
    "title": "Welcome to STA 199",
    "section": "Meet data science",
    "text": "Meet data science\n\nData science is an exciting discipline that allows you to turn raw data into understanding, insight, and knowledge.\nWe’re going to learn to do this in a tidy way – more on that later!\nThis is a course on introduction to data science, with an emphasis on statistical thinking."
  },
  {
    "objectID": "slides/01-welcome-199.html#excel---not",
    "href": "slides/01-welcome-199.html#excel---not",
    "title": "Welcome to STA 199",
    "section": "Excel - not…",
    "text": "Excel - not…"
  },
  {
    "objectID": "slides/01-welcome-199.html#r",
    "href": "slides/01-welcome-199.html#r",
    "title": "Welcome to STA 199",
    "section": "R",
    "text": "R"
  },
  {
    "objectID": "slides/01-welcome-199.html#rstudio",
    "href": "slides/01-welcome-199.html#rstudio",
    "title": "Welcome to STA 199",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/01-welcome-199.html#data-science-life-cycle-1",
    "href": "slides/01-welcome-199.html#data-science-life-cycle-1",
    "title": "Welcome to STA 199",
    "section": "Data science life cycle",
    "text": "Data science life cycle"
  },
  {
    "objectID": "slides/01-welcome-199.html#import",
    "href": "slides/01-welcome-199.html#import",
    "title": "Welcome to STA 199",
    "section": "Import",
    "text": "Import"
  },
  {
    "objectID": "slides/01-welcome-199.html#tidy-transform",
    "href": "slides/01-welcome-199.html#tidy-transform",
    "title": "Welcome to STA 199",
    "section": "Tidy + transform",
    "text": "Tidy + transform"
  },
  {
    "objectID": "slides/01-welcome-199.html#visualize",
    "href": "slides/01-welcome-199.html#visualize",
    "title": "Welcome to STA 199",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/01-welcome-199.html#model",
    "href": "slides/01-welcome-199.html#model",
    "title": "Welcome to STA 199",
    "section": "Model",
    "text": "Model"
  },
  {
    "objectID": "slides/01-welcome-199.html#understand",
    "href": "slides/01-welcome-199.html#understand",
    "title": "Welcome to STA 199",
    "section": "Understand",
    "text": "Understand"
  },
  {
    "objectID": "slides/01-welcome-199.html#section",
    "href": "slides/01-welcome-199.html#section",
    "title": "Welcome to STA 199",
    "section": "",
    "text": "# A tibble: 5 × 2\n  date             season\n  <chr>            <chr> \n1 23 January 2017  winter\n2 4 March 2017     spring\n3 14 June 2017     summer\n4 1 September 2017 fall  \n5 ...              ..."
  },
  {
    "objectID": "slides/01-welcome-199.html#communicate",
    "href": "slides/01-welcome-199.html#communicate",
    "title": "Welcome to STA 199",
    "section": "Communicate",
    "text": "Communicate"
  },
  {
    "objectID": "slides/01-welcome-199.html#understand-communicate",
    "href": "slides/01-welcome-199.html#understand-communicate",
    "title": "Welcome to STA 199",
    "section": "Understand + communicate",
    "text": "Understand + communicate"
  },
  {
    "objectID": "slides/01-welcome-199.html#program",
    "href": "slides/01-welcome-199.html#program",
    "title": "Welcome to STA 199",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "slides/01-welcome-199.html#application-exercise",
    "href": "slides/01-welcome-199.html#application-exercise",
    "title": "Welcome to STA 199",
    "section": "Application exercise",
    "text": "Application exercise\n\nOr more like demo for today…\n📋 github.com/sta199-f22-1/ae-0-unvotes"
  },
  {
    "objectID": "slides/01-welcome-199.html#homepage",
    "href": "slides/01-welcome-199.html#homepage",
    "title": "Welcome to STA 199",
    "section": "Homepage",
    "text": "Homepage\nhttps://sta199-f22-1.github.io/\n\nAll course materials\nLinks to Sakai, GitHub, RStudio containers, etc.\nLet’s take a tour!"
  },
  {
    "objectID": "slides/01-welcome-199.html#course-toolkit",
    "href": "slides/01-welcome-199.html#course-toolkit",
    "title": "Welcome to STA 199",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta199-f22-1\nRStudio containers: cmgr.oit.duke.edu/containers\nCommunication: Slack\nAssignment submission and feedback: Gradescope\n\n\n\n\n\n\n\nImportant\n\n\nReserve an RStudio Container (titled STA 198-199) before lab on Monday!"
  },
  {
    "objectID": "slides/01-welcome-199.html#activities-prepare-participate-practice-perform",
    "href": "slides/01-welcome-199.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 199",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by watching the videos and completing the readings\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you’ve learned to analyze real-world data\n\nLab assignments x 7 (first individual, later team-based)\nHomework assignments x 5 (individual)\nThree take-home exams x 2\nTerm project presented in the last lab session"
  },
  {
    "objectID": "slides/01-welcome-199.html#cadence",
    "href": "slides/01-welcome-199.html#cadence",
    "title": "Welcome to STA 199",
    "section": "Cadence",
    "text": "Cadence\n\n\nLabs: Start and make large progress on Monday in lab section, finish up by Friday 5pm of that week\nHWs: Posted Thursday morning, due following Thursday\nExams: Exam released Thursday morning, no lab on Monday of following week, due Monday 2pm\nProject: Deadlines throughout the semester, with some lab and lecture time dedicated to working on them, and most work done in teams outside of class"
  },
  {
    "objectID": "slides/01-welcome-199.html#teams",
    "href": "slides/01-welcome-199.html#teams",
    "title": "Welcome to STA 199",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nAssigned by me\nApplication exercises, labs, and project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/01-welcome-199.html#grading",
    "href": "slides/01-welcome-199.html#grading",
    "title": "Welcome to STA 199",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30% (5% x 6)\n\n\nLabs\n14% (2% x 7)\n\n\nProject\n15%\n\n\nExam 01\n18%\n\n\nExam 02\n18%\n\n\nApplication Exercises\n2.5%\n\n\nTeamwork\n2.5%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/01-welcome-199.html#support",
    "href": "slides/01-welcome-199.html#support",
    "title": "Welcome to STA 199",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/01-welcome-199.html#announcements",
    "href": "slides/01-welcome-199.html#announcements",
    "title": "Welcome to STA 199",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Sakai (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/01-welcome-199.html#diversity-inclusion",
    "href": "slides/01-welcome-199.html#diversity-inclusion",
    "title": "Welcome to STA 199",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nPlease let me know your preferred name and pronouns on the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisors and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome-199.html#accessibility",
    "href": "slides/01-welcome-199.html#accessibility",
    "title": "Welcome to STA 199",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome-199.html#covid-policies",
    "href": "slides/01-welcome-199.html#covid-policies",
    "title": "Welcome to STA 199",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times!\nRead and follow university guidance"
  },
  {
    "objectID": "slides/01-welcome-199.html#late-work-waivers-regrades-policy",
    "href": "slides/01-welcome-199.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 199",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/01-welcome-199.html#collaboration-policy",
    "href": "slides/01-welcome-199.html#collaboration-policy",
    "title": "Welcome to STA 199",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/01-welcome-199.html#sharing-reusing-code-policy",
    "href": "slides/01-welcome-199.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 199",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/01-welcome-199.html#academic-integrity",
    "href": "slides/01-welcome-199.html#academic-integrity",
    "title": "Welcome to STA 199",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/01-welcome-199.html#most-importantly",
    "href": "slides/01-welcome-199.html#most-importantly",
    "title": "Welcome to STA 199",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/01-welcome-199.html#this-weeks-tasks",
    "href": "slides/01-welcome-199.html#this-weeks-tasks",
    "title": "Welcome to STA 199",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\nComplete the Getting to know you survey if you haven’t yet done so!\nRead the syllabus"
  },
  {
    "objectID": "slides/01-welcome-199.html#midori-says",
    "href": "slides/01-welcome-199.html#midori-says",
    "title": "Welcome to STA 199",
    "section": "Midori says…",
    "text": "Midori says…"
  },
  {
    "objectID": "slides/01-welcome-199.html#its-the-r-community",
    "href": "slides/01-welcome-199.html#its-the-r-community",
    "title": "Welcome to STA 199",
    "section": "It’s the R community! 💛",
    "text": "It’s the R community! 💛\n\n\n\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/07-tidying-data.html#while-you-wait-for-class-to-begin",
    "href": "slides/07-tidying-data.html#while-you-wait-for-class-to-begin",
    "title": "Tidying data",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\nOpen your ae-05 project in RStudio, render your document, and commit and push.\nAny questions from prepare materials? Go to slido.com / #sta199. You can also upvote others’ questions."
  },
  {
    "objectID": "slides/07-tidying-data.html#announcements",
    "href": "slides/07-tidying-data.html#announcements",
    "title": "Tidying data",
    "section": "Announcements",
    "text": "Announcements\n\nMy office hours this week 2-3 pm on Tuesday or by appointment\nHW 2 typo fix\nComment on masking in class starting Thursday\nSSMU Welcome Back event: Wed, Sep 21, 7:30 - 8:30 pm at Old Chem 201 (with food & refreshments at the Old Chem porch)"
  },
  {
    "objectID": "slides/07-tidying-data.html#questions-from-last-time-1",
    "href": "slides/07-tidying-data.html#questions-from-last-time-1",
    "title": "Tidying data",
    "section": "Questions from last time 1",
    "text": "Questions from last time 1\n\nCan you explain the difference between primary and foreign keys?\n\nA primary key is a variable that uniquely identifies an observation. A foreign key is the corresponding variable in another table. These keys might have the same name, but they don’t have to, e.g. by = c(\"student_email\" = \"student_id\").\n\n\nWill we be able to log into containers while not on duke WiFi?\n\nYes, you don’t have to be on Duke WiFi to connect to the containers.\n\n\n\nHow do you code “and/or”?\n\nand is & and or is |."
  },
  {
    "objectID": "slides/07-tidying-data.html#questions-from-last-time-2",
    "href": "slides/07-tidying-data.html#questions-from-last-time-2",
    "title": "Tidying data",
    "section": "Questions from last time 2",
    "text": "Questions from last time 2\n\nWhat is the difference between rendering and saving a document?\n\nWhen you edit your Quarto file and you save it, your changes are saved but they’re not reflected in your output HTML or PDF file. When you render the document, the output is also updated to reflect those changes. When you hit render, RStudio automatically first saves your Quarto file, and then renders it. So I recommend you render early and often, both to save your changes, and also to make sure your changes did not introduce any errors into the document.\n\n\nWhat does it mean to commit and push something?\n\nWe “commit” to take a snapshot of the files in our local repository, i.e. the files that are saved on the university servers you’re using. We “push” to get those changes to the remote repository, i.e. your repository on GitHub."
  },
  {
    "objectID": "slides/07-tidying-data.html#tidying-datasets",
    "href": "slides/07-tidying-data.html#tidying-datasets",
    "title": "Tidying data",
    "section": "Tidying datasets",
    "text": "Tidying datasets\n\nWhat makes a dataset “tidy”?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/07-tidying-data.html#ae-05",
    "href": "slides/07-tidying-data.html#ae-05",
    "title": "Tidying data",
    "section": "ae-05",
    "text": "ae-05\n\n\nGo to the course GitHub org and find your ae-05 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/07-tidying-data.html#recap-of-ae",
    "href": "slides/07-tidying-data.html#recap-of-ae",
    "title": "Tidying data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate.\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/23-exam-2-review.html#announcements",
    "href": "slides/23-exam-2-review.html#announcements",
    "title": "Exam 2 review",
    "section": "Announcements",
    "text": "Announcements\n\nExam 2 is released on today at noon and is due at 2pm on Monday.\n\nNo TA OH during the exam.\nI will have OH 4-5pm on Friday (on Zoom).\nAny clarification questions must be emailed to me only.\nNo Slack use during the exam, even about non-exam related questions.\n\nAnswer keys:\n\nHW 4 and HW 5 feedback: Keys both posted, feedback coming soon.\nAll lab keys also posted.\nAE 16 key missing complete answers, will post after class."
  },
  {
    "objectID": "slides/23-exam-2-review.html#questions-grouping",
    "href": "slides/23-exam-2-review.html#questions-grouping",
    "title": "Exam 2 review",
    "section": "Questions: Grouping",
    "text": "Questions: Grouping\n\nDoes order of variables in group_by() matter?\n\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\n\n\n\npenguins |>\n  group_by(species, sex) |>\n  summarize(mean_bm = mean(body_mass_g))\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    mean_bm\n  <fct>     <fct>    <dbl>\n1 Adelie    female   3369.\n2 Adelie    male     4043.\n3 Adelie    <NA>       NA \n4 Chinstrap female   3527.\n5 Chinstrap male     3939.\n6 Gentoo    female   4680.\n7 Gentoo    male     5485.\n8 Gentoo    <NA>       NA \n\n\n\n\npenguins |>\n  group_by(sex, species) |>\n  summarize(mean_bm = mean(body_mass_g))\n\n# A tibble: 8 × 3\n# Groups:   sex [3]\n  sex    species   mean_bm\n  <fct>  <fct>       <dbl>\n1 female Adelie      3369.\n2 female Chinstrap   3527.\n3 female Gentoo      4680.\n4 male   Adelie      4043.\n5 male   Chinstrap   3939.\n6 male   Gentoo      5485.\n7 <NA>   Adelie        NA \n8 <NA>   Gentoo        NA"
  },
  {
    "objectID": "slides/23-exam-2-review.html#questions-factors",
    "href": "slides/23-exam-2-review.html#questions-factors",
    "title": "Exam 2 review",
    "section": "Questions: Factors",
    "text": "Questions: Factors\n\n\nWhen will we use factors and how does that make a difference in the data?\nWhen do you use fct_relevel() versus fct_reorder()?\nHow to use case_when() function and the proper use of forcats functions like fct_relevel() , fct_reorder(), fct_other()?\n\n\nReview: https://r4ds.hadley.nz/factors.html."
  },
  {
    "objectID": "slides/23-exam-2-review.html#questions-latex-equations",
    "href": "slides/23-exam-2-review.html#questions-latex-equations",
    "title": "Exam 2 review",
    "section": "Questions: LaTeX / equations",
    "text": "Questions: LaTeX / equations\n\n\nWhat is the name of the math symbol text we use to write equations? Is there a cheat sheet with the shortcuts for each symbol?\nDo we have to use LaTeX for our equations?\n\n\n\n\n\\(H_0:\\mu_1 - \\mu_2 = 0\\)\n\\(H_A: \\mu_1 - \\mu_2 \\ne 0\\)\n$H_0:\\mu_1 - \\mu_2 = 0$\n\n$H_A: \\mu_1 - \\mu_2 \\ne 0$\n\nH0: mu1 - mu2 = 0\nHA: mu1 - mu2 ≠ 0"
  },
  {
    "objectID": "slides/23-exam-2-review.html#questions-ethics",
    "href": "slides/23-exam-2-review.html#questions-ethics",
    "title": "Exam 2 review",
    "section": "Questions: Ethics",
    "text": "Questions: Ethics\n\nWould love to review data ethics and how to answer questions about ethical issues with any dataset.\n\nReview: The videos from the Ethics module."
  },
  {
    "objectID": "slides/23-exam-2-review.html#questions-miscellaneous",
    "href": "slides/23-exam-2-review.html#questions-miscellaneous",
    "title": "Exam 2 review",
    "section": "Questions: Miscellaneous",
    "text": "Questions: Miscellaneous\n\nWhat does geom_smooth(method = “loess”) do?\n\n\nFits a non-linear model to the data, a smooth curve.\n\n\n\nHow do we know how much to round by?\n\n\n\nRound as much as it makes sense in the context of the data. Avoid rounding in interim steps."
  },
  {
    "objectID": "slides/23-exam-2-review.html#question-inference",
    "href": "slides/23-exam-2-review.html#question-inference",
    "title": "Exam 2 review",
    "section": "Question: Inference",
    "text": "Question: Inference\n\nHow do we decide whether to use bootstrap, simulate, or permute in the generate() step of inference?\n\n\nBootstrap: For constructing bootstrap intervals or for testing for a single mean (\\(H0: \\mu_0 = 5\\))\nSimulate: For testing for a single proportion (\\(H_0: p_0 = 0.3\\))\nPermute: For testing for independence, i.e., for testing for differences in means or proportions across groups (or whether one is less/greater than the other)"
  },
  {
    "objectID": "slides/23-exam-2-review.html#ae-19",
    "href": "slides/23-exam-2-review.html#ae-19",
    "title": "Exam 2 review",
    "section": "ae-19",
    "text": "ae-19\n\n\nGo to the course GitHub org and find your ae-19 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nYou should have already pushed updates on Tuesday, so you should be good for submission.\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#while-you-wait-for-class-to-begin",
    "href": "slides/12-dse-bias-privacy.html#while-you-wait-for-class-to-begin",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\n\n\n\n\n\nImportant\n\n\nStudy participation + exam extra credit opportunity:\n\n\n\nOptional! But the researchers would appreciate your participation!\nGo to bit.ly/sta199-learning-study-1 to fill out the survey.\nI won’t see your responses, answer freely and honestly.\nI will get a list of who filled out the survey from Duke Learning Innovations and use that to award +4 points extra credit for Exam 1.\nIRB Protocol #2022-0545."
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#announcements",
    "href": "slides/12-dse-bias-privacy.html#announcements",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Announcements",
    "text": "Announcements\n\nHW 3 posted later today, due one week from now\nNo OH over Fall break (weekend, Mon, Tue)\nMidterm evaluation - due Wed, Oct 12, 9am"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#from-last-time-ae-08",
    "href": "slides/12-dse-bias-privacy.html#from-last-time-ae-08",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "From last time: ae-08",
    "text": "From last time: ae-08\nLet’s tidy up our plot a bit more!"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#your-data",
    "href": "slides/12-dse-bias-privacy.html#your-data",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "“Your” data",
    "text": "“Your” data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#privacy-of-your-data",
    "href": "slides/12-dse-bias-privacy.html#privacy-of-your-data",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you’ve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it’s shared with others?"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#sharing-your-data",
    "href": "slides/12-dse-bias-privacy.html#sharing-your-data",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#what-does-google-thinkknow-about-you",
    "href": "slides/12-dse-bias-privacy.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you’re seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized.\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#your-browing-history",
    "href": "slides/12-dse-bias-privacy.html#your-browing-history",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Your browing history",
    "text": "Your browing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#who-else-gets-to-use-your-data",
    "href": "slides/12-dse-bias-privacy.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#ok-cupid-data-breach",
    "href": "slides/12-dse-bias-privacy.html#ok-cupid-data-breach",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames\n\n\n\n\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#gettysburg-address",
    "href": "slides/12-dse-bias-privacy.html#gettysburg-address",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Gettysburg address",
    "text": "Gettysburg address\n\n\n\nRandomly select 10 words from the Gettysburg Address and calculate the mean number of letters in these 10 words. Submit your answer at bit.ly/gburg199."
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#your-responses",
    "href": "slides/12-dse-bias-privacy.html#your-responses",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Your responses",
    "text": "Your responses"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#comparison-to-truth",
    "href": "slides/12-dse-bias-privacy.html#comparison-to-truth",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Comparison to “truth”",
    "text": "Comparison to “truth”"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#garbage-in-garbage-out",
    "href": "slides/12-dse-bias-privacy.html#garbage-in-garbage-out",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Garbage in, garbage out",
    "text": "Garbage in, garbage out\n\nIn statistical modeling and inference we talk about “garbage in, garbage out” – if you don’t have good (random, representative) data, results of your analysis will not be reliable or generalizable.\nCorollary: Bias in, bias out."
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#google-translate",
    "href": "slides/12-dse-bias-privacy.html#google-translate",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Google translate",
    "text": "Google translate\n\nWhat might be the reason for Google’s gendered translation? How do ethics play into this situation?\n\n\n\n\n\n\n\n\nSource: Engadget - Google is working to remove gender bias in its translations"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#ae-09---part-1",
    "href": "slides/12-dse-bias-privacy.html#ae-09---part-1",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "ae-09 - Part 1",
    "text": "ae-09 - Part 1\n\n\nGo to the course GitHub org and find your ae-09 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nWork on Part 1 - Stochastic Parrots\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#machine-bias",
    "href": "slides/12-dse-bias-privacy.html#machine-bias",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Machine Bias",
    "text": "Machine Bias\n2016 ProPublica article on algorithm used for rating a defendant’s risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#risk-score-errors",
    "href": "slides/12-dse-bias-privacy.html#risk-score-errors",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Risk score errors",
    "text": "Risk score errors\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#risk-scores",
    "href": "slides/12-dse-bias-privacy.html#risk-scores",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "Risk scores",
    "text": "Risk scores\n\n\n\nHow can an algorithm that doesn’t use race as input data be racist?"
  },
  {
    "objectID": "slides/12-dse-bias-privacy.html#ae-09---part-2",
    "href": "slides/12-dse-bias-privacy.html#ae-09---part-2",
    "title": "Data science ethics: Algorithmic bias + Data privacy",
    "section": "ae-09 - Part 2",
    "text": "ae-09 - Part 2\n\n\nGo to the course GitHub org and find your ae-09 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nWork on Part 2 - Predicting ethnicity\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#announcements",
    "href": "slides/04-visualizing-various-types-of-data.html#announcements",
    "title": "Visualizing various types of data",
    "section": "Announcements",
    "text": "Announcements\n\nHW 1 posted this evening, due 11:59pm on Thursday, Sep 15"
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#wrap-up-ae-01",
    "href": "slides/04-visualizing-various-types-of-data.html#wrap-up-ae-01",
    "title": "Visualizing various types of data",
    "section": "Wrap up ae-01",
    "text": "Wrap up ae-01\n\nAny questions from Part 1?\nDemo: Part 2"
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#identifying-variable-types",
    "href": "slides/04-visualizing-various-types-of-data.html#identifying-variable-types",
    "title": "Visualizing various types of data",
    "section": "Identifying variable types",
    "text": "Identifying variable types\n\nIdentify the type of each of the following variables.\n\nFavorite food\nNumber of classes you’re taking this semester\nZip code\nFull name\nAge\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#questions-from-the-prepare-materials",
    "href": "slides/04-visualizing-various-types-of-data.html#questions-from-the-prepare-materials",
    "title": "Visualizing various types of data",
    "section": "Questions from the prepare materials?",
    "text": "Questions from the prepare materials?"
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#the-way-data-is-displayed-matters",
    "href": "slides/04-visualizing-various-types-of-data.html#the-way-data-is-displayed-matters",
    "title": "Visualizing various types of data",
    "section": "The way data is displayed matters",
    "text": "The way data is displayed matters\n\nWhat do these three plots show?\n\n\nSource: #barbarplots"
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#ae-02",
    "href": "slides/04-visualizing-various-types-of-data.html#ae-02",
    "title": "Visualizing various types of data",
    "section": "ae-02",
    "text": "ae-02\n\n\nGo to the course GitHub org and find your ae-02 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/04-visualizing-various-types-of-data.html#recap-of-ae",
    "href": "slides/04-visualizing-various-types-of-data.html#recap-of-ae",
    "title": "Visualizing various types of data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nPick geoms based on data types.\nSet appropriate binwidths for histograms.\nTurn off legends when they provide redundant information with show.legend = FALSE.\nCreate plots with multiple geoms, and pay attention to order.\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/18-more-models-multiple-predictors.html#while-you-wait-for-class-to-begin",
    "href": "slides/18-more-models-multiple-predictors.html#while-you-wait-for-class-to-begin",
    "title": "Models with multiple predictors",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\nClone your ae-15 project from GitHub, render your document, update your name, and commit and push.\nPost any questions you have about the material so far at sli.do / #sta199."
  },
  {
    "objectID": "slides/18-more-models-multiple-predictors.html#announcements",
    "href": "slides/18-more-models-multiple-predictors.html#announcements",
    "title": "Models with multiple predictors",
    "section": "Announcements",
    "text": "Announcements\n\nMy OH today: On Zoom at bit.ly/minezoom\nJasmine’s OH moved to 4-5pm"
  },
  {
    "objectID": "slides/18-more-models-multiple-predictors.html#goals",
    "href": "slides/18-more-models-multiple-predictors.html#goals",
    "title": "Models with multiple predictors",
    "section": "Goals",
    "text": "Goals\n\nReview prediction and interpretation of model results\nReview main and interaction effects models\nDiscuss model selection further"
  },
  {
    "objectID": "slides/18-more-models-multiple-predictors.html#ae-15",
    "href": "slides/18-more-models-multiple-predictors.html#ae-15",
    "title": "Models with multiple predictors",
    "section": "ae-15",
    "text": "ae-15\n\n\n\nGo to the course GitHub org and find your ae-15 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/18-more-models-multiple-predictors.html#recap",
    "href": "slides/18-more-models-multiple-predictors.html#recap",
    "title": "Models with multiple predictors",
    "section": "Recap",
    "text": "Recap\n\n\nWhat is the practical difference between a model with parallel and non-parallel lines?\nWhat is the definition of R-squared?\nWhy do we choose models based on adjusted R-squared and not R-squared?\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/17-models-multiple-predictors.html#while-you-wait-for-class-to-begin",
    "href": "slides/17-models-multiple-predictors.html#while-you-wait-for-class-to-begin",
    "title": "Models with multiple predictors",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\nClone your ae-14 project from GitHub, render your document, update your name, and commit and push."
  },
  {
    "objectID": "slides/17-models-multiple-predictors.html#announcements",
    "href": "slides/17-models-multiple-predictors.html#announcements",
    "title": "Models with multiple predictors",
    "section": "Announcements",
    "text": "Announcements\n\nMy OH going forward: Zoom option will be available\nProject proposal feedback: Incorporate more variables into your analysis\nUpcoming:\n\nHW 4 to be posted soon\nLab 4 due tomorrow evening"
  },
  {
    "objectID": "slides/17-models-multiple-predictors.html#goals",
    "href": "slides/17-models-multiple-predictors.html#goals",
    "title": "Models with multiple predictors",
    "section": "Goals",
    "text": "Goals\n\nRecap modeling with a single predictor\nFit and interpret models with multiple predictors\nDistinguish between additive and interaction models"
  },
  {
    "objectID": "slides/17-models-multiple-predictors.html#ae-14",
    "href": "slides/17-models-multiple-predictors.html#ae-14",
    "title": "Models with multiple predictors",
    "section": "ae-14",
    "text": "ae-14\n\n\n\nGo to the course GitHub org and find your ae-14 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/13-web-scraping.html#while-you-wait-for-class-to-begin",
    "href": "slides/13-web-scraping.html#while-you-wait-for-class-to-begin",
    "title": "Web scraping",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\n\nIf you haven’t yet done so: Install a Chrome browser and the SelectorGadget extension:\n\nChrome\nSelectorGadget\n\nClone your ae-10 project from GitHub, render your document, update your name, and commit and push."
  },
  {
    "objectID": "slides/13-web-scraping.html#announcements",
    "href": "slides/13-web-scraping.html#announcements",
    "title": "Web scraping",
    "section": "Announcements",
    "text": "Announcements\n\nWatch out for announcement on team assignments before Monday’s lab\nStart thinking about project ideas to bring to your team\nHW 3 is due at 11:59 on Thursday"
  },
  {
    "objectID": "slides/13-web-scraping.html#midterm-feedback-i",
    "href": "slides/13-web-scraping.html#midterm-feedback-i",
    "title": "Web scraping",
    "section": "Midterm feedback I",
    "text": "Midterm feedback I\n\n\nThank you to the 49 of you who filled it out!\nHow would you change the class: Overwhelming response: More live coding\nPace:\n\n78% About right\n6% Too fast\n4% Too slow\n12% No response\n\nNumber of hours spent outside of class:\n\nAvg 5.5 hours (Expected ~6.25 hours)\nIf you’re consistently spending less and not doing well, you should be putting more time in\nIf you’re consistently spending more and feel like it’s not working, reach out for help"
  },
  {
    "objectID": "slides/13-web-scraping.html#midterm-feedback-ii",
    "href": "slides/13-web-scraping.html#midterm-feedback-ii",
    "title": "Web scraping",
    "section": "Midterm feedback II",
    "text": "Midterm feedback II\n\n\nHow are you learning best:\n\nAEs during class\nAssignments\nVideos\n\nTAs:\n\nOverwhelmingly positive!\nIf you’re not making use of the TA resources, your peers think you should!"
  },
  {
    "objectID": "slides/13-web-scraping.html#midterm-feedback-iii",
    "href": "slides/13-web-scraping.html#midterm-feedback-iii",
    "title": "Web scraping",
    "section": "Midterm feedback III",
    "text": "Midterm feedback III\nGeneral feedback:\n\n\nPositive: Generally, people like the interactive nature of the class, the live coding aspect, and the topics\nConstructive:\n\nLessen overlap between prep materials – Can’t lessen since people learn differently, but I can annotate the overlap. You should also feel free to go through pieces at a faster pace if they feel redundant.\nCan be difficult to catch up on AEs if bits are missed – Ask on Slack or come by office hours, no need to wait for answer keys to be posted.\nSometimes grading feels harsh – Ask for clarification on points taken if not provided and don’t hesitate to ask for a regrade if errors are made in grading.\nWe haven’t done any statistics – All of this is (modern) statistics!"
  },
  {
    "objectID": "slides/13-web-scraping.html#scraping-the-web-what-why",
    "href": "slides/13-web-scraping.html#scraping-the-web-what-why",
    "title": "Web scraping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it’s time-consuming and prone to errors\nWeb scraping is the process of extracting this information automatically and transform it into a structured dataset\nTwo different scenarios:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files."
  },
  {
    "objectID": "slides/13-web-scraping.html#hypertext-markup-language",
    "href": "slides/13-web-scraping.html#hypertext-markup-language",
    "title": "Web scraping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\n\nMost of the data on the web is still largely available as HTML\nIt is structured (hierarchical / tree based), but it’s often not available in a form useful for analysis (flat / tidy).\n\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n  </body>\n</html>"
  },
  {
    "objectID": "slides/13-web-scraping.html#rvest",
    "href": "slides/13-web-scraping.html#rvest",
    "title": "Web scraping",
    "section": "rvest",
    "text": "rvest\n\n\n\nThe rvest package makes basic processing and manipulation of HTML data straight forward\nIt’s designed to work with pipelines built with |>\nrvest.tidyverse.org"
  },
  {
    "objectID": "slides/13-web-scraping.html#core-rvest-functions",
    "href": "slides/13-web-scraping.html#core-rvest-functions",
    "title": "Web scraping",
    "section": "Core rvest functions",
    "text": "Core rvest functions\n\nread_html() - Read HTML data from a url or character string (actually from the xml2 package, but most often used along with other rvest functions)\nhtml_element() / html_elements() - Select a specified element(s) from HTML document\nhtml_table() - Parse an HTML table into a data frame\nhtml_text() - Extract text from an element\nhtml_text2() - Extract text from an element and lightly format it to match how text looks in the browser\nhtml_name() - Extract elements’ names\nhtml_attr() / html_attrs() - Extract a single attribute or all attributes"
  },
  {
    "objectID": "slides/13-web-scraping.html#opinion-articles-in-the-chronicle",
    "href": "slides/13-web-scraping.html#opinion-articles-in-the-chronicle",
    "title": "Web scraping",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\n\nGo to https://www.dukechronicle.com/section/opinion\nScroll to the bottom and choose page 1\n\n\n\n\nHow many articles are on the page?\nTake a look at the URL. How can you change the number of articles displayed by modifying the URL? Try displaying 100 articles."
  },
  {
    "objectID": "slides/13-web-scraping.html#goal",
    "href": "slides/13-web-scraping.html#goal",
    "title": "Web scraping",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualze the data"
  },
  {
    "objectID": "slides/13-web-scraping.html#ae-10",
    "href": "slides/13-web-scraping.html#ae-10",
    "title": "Web scraping",
    "section": "ae-10",
    "text": "ae-10\n\n\n\nGo to the course GitHub org and find your ae-10 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/13-web-scraping.html#recap",
    "href": "slides/13-web-scraping.html#recap",
    "title": "Web scraping",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/13-web-scraping.html#a-new-r-workflow",
    "href": "slides/13-web-scraping.html#a-new-r-workflow",
    "title": "Web scraping",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/13-web-scraping.html#ethics-can-you-vs-should-you",
    "href": "slides/13-web-scraping.html#ethics-can-you-vs-should-you",
    "title": "Web scraping",
    "section": "Ethics: “Can you?” vs “Should you?”",
    "text": "Ethics: “Can you?” vs “Should you?”\n\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/13-web-scraping.html#can-you-vs-should-you",
    "href": "slides/13-web-scraping.html#can-you-vs-should-you",
    "title": "Web scraping",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”"
  },
  {
    "objectID": "slides/13-web-scraping.html#challenges-unreliable-formatting",
    "href": "slides/13-web-scraping.html#challenges-unreliable-formatting",
    "title": "Web scraping",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/13-web-scraping.html#challenges-data-broken-into-many-pages",
    "href": "slides/13-web-scraping.html#challenges-data-broken-into-many-pages",
    "title": "Web scraping",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/13-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/13-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scraping",
    "section": "Workflow: Screen scraping vs. APIs",
    "text": "Workflow: Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#while-you-wait-for-class-to-begin",
    "href": "slides/16-models-single-predictor.html#while-you-wait-for-class-to-begin",
    "title": "Models with a single predictor",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\nClone your ae-13 project from GitHub, render your document, update your name, and commit and push."
  },
  {
    "objectID": "slides/16-models-single-predictor.html#announcements",
    "href": "slides/16-models-single-predictor.html#announcements",
    "title": "Models with a single predictor",
    "section": "Announcements",
    "text": "Announcements\n\nMy office hours on Zoom today (2-4pm): bit.ly/minezoom\nAdvising / info session on Zoom 1-2pm today. Will send link along with OH info as Sakai announcement."
  },
  {
    "objectID": "slides/16-models-single-predictor.html#goals",
    "href": "slides/16-models-single-predictor.html#goals",
    "title": "Models with a single predictor",
    "section": "Goals",
    "text": "Goals\n\nModeling with a single predictor\nModel parameters, estimates, and error terms\nInterpreting slopes and intercepts"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#setup",
    "href": "slides/16-models-single-predictor.html#setup",
    "title": "Models with a single predictor",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(fivethirtyeight) # for the fandango dataset"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#spurious-correlations",
    "href": "slides/16-models-single-predictor.html#spurious-correlations",
    "title": "Models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#spurious-correlations-1",
    "href": "slides/16-models-single-predictor.html#spurious-correlations-1",
    "title": "Models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#data-prep",
    "href": "slides/16-models-single-predictor.html#data-prep",
    "title": "Models with a single predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores <- fandango %>%\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#data-overview",
    "href": "slides/16-models-single-predictor.html#data-overview",
    "title": "Models with a single predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |>\n  select(critics, audience)\n\n# A tibble: 146 × 2\n   critics audience\n     <int>    <int>\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# … with 136 more rows"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#data-visualization",
    "href": "slides/16-models-single-predictor.html#data-visualization",
    "title": "Models with a single predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#regression-model-1",
    "href": "slides/16-models-single-predictor.html#regression-model-1",
    "title": "Models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#regression-model",
    "href": "slides/16-models-single-predictor.html#regression-model",
    "title": "Models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n$$\n\\[\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#simple-linear-regression",
    "href": "slides/16-models-single-predictor.html#simple-linear-regression",
    "title": "Models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationthip between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#simple-linear-regression-1",
    "href": "slides/16-models-single-predictor.html#simple-linear-regression-1",
    "title": "Models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\nThese \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/16-models-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "title": "Models with a single predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#residuals",
    "href": "slides/16-models-single-predictor.html#residuals",
    "title": "Models with a single predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#least-squares-line",
    "href": "slides/16-models-single-predictor.html#least-squares-line",
    "title": "Models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#least-squares-line-1",
    "href": "slides/16-models-single-predictor.html#least-squares-line-1",
    "title": "Models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nmovies_fit <- linear_reg() |>\n  fit(audience ~ critics, data = movie_scores)\n\ntidy(movies_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#properties-of-least-squares-regression",
    "href": "slides/16-models-single-predictor.html#properties-of-least-squares-regression",
    "title": "Models with a single predictor",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#interpreting-the-slope",
    "href": "slides/16-models-single-predictor.html#interpreting-the-slope",
    "title": "Models with a single predictor",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\nslido.com / #sta199\n\nPoll: The slope of the model for predicting audience score from critics score is 0.519. Which of the following is the best interpretation of this value?\n\n\nFor every one point increase in the critics score, the audience score goes up by 0.519 points, on average.\nFor every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nFor every one point increase in the critics score, the audience score goes up by 0.519 points.\nFor every one point increase in the audience score, the critics score goes up by 0.519 points, on average."
  },
  {
    "objectID": "slides/16-models-single-predictor.html#interpreting-slope-intercept",
    "href": "slides/16-models-single-predictor.html#interpreting-slope-intercept",
    "title": "Models with a single predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/16-models-single-predictor.html#is-the-intercept-meaningful",
    "href": "slides/16-models-single-predictor.html#is-the-intercept-meaningful",
    "title": "Models with a single predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/16-models-single-predictor.html#ae-13",
    "href": "slides/16-models-single-predictor.html#ae-13",
    "title": "Models with a single predictor",
    "section": "ae-13",
    "text": "ae-13\n\n\n\nGo to the course GitHub org and find your ae-13 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/22-inference-overview.html#while-you-wait-for-class-to-begin",
    "href": "slides/22-inference-overview.html#while-you-wait-for-class-to-begin",
    "title": "Inference overview",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\n\n\n\n\n\nImportant\n\n\nCome up with at least one question you’d like to see answered in the Exam 1 review on Thursday.\nGo to slido.com and submit your question with the code #sta199exam2.\nYou can also upvote others’ questions."
  },
  {
    "objectID": "slides/22-inference-overview.html#announcements",
    "href": "slides/22-inference-overview.html#announcements",
    "title": "Inference overview",
    "section": "Announcements",
    "text": "Announcements\n\nMy office hours today 3:30-5pm on Zoom: bit.ly/minezoom.\nLab 6 due Friday night (11:59 pm) – but I strongly recommend you finish and submit it before the exam begins!\nExam 2 is released on Thursday at noon and is due at 2pm on Monday.\n\nNo TA OH during the exam.\nI will have OH 4-5pm on Friday (on Zoom).\nAny clarification questions must be emailed to me only.\nNo Slack use during the exam, even about non-exam related questions."
  },
  {
    "objectID": "slides/22-inference-overview.html#exam-study-tips",
    "href": "slides/22-inference-overview.html#exam-study-tips",
    "title": "Inference overview",
    "section": "Exam study tips",
    "text": "Exam study tips\n\nTake notes that you can reference\nReview feedback given to you on graded work\nRevisit AEs\nReview suggested solutions\nAsk questions"
  },
  {
    "objectID": "slides/22-inference-overview.html#topics-for-review",
    "href": "slides/22-inference-overview.html#topics-for-review",
    "title": "Inference overview",
    "section": "Topics for review",
    "text": "Topics for review\n\nCome up with at least one question you’d like to see answered in the Exam 2 review on Thursday.\nGo to slido.com and submit your question with the code #sta199exam2.\nYou can also upvote others’ questions.\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/22-inference-overview.html#recap-of-inference-ideas",
    "href": "slides/22-inference-overview.html#recap-of-inference-ideas",
    "title": "Inference overview",
    "section": "Recap of inference ideas",
    "text": "Recap of inference ideas\n\nA hypothesis test is a statistical technique used to evaluate competing claims (null and alternative hypotheses) using data.\nWe simulate a null distribution using our original data.\nWe use our sample statistic and direction of the alternative hypothesis to calculate the p-value.\nWe use the p-value to determine conclusions about the alternative hypotheses."
  },
  {
    "objectID": "slides/22-inference-overview.html#ae-19",
    "href": "slides/22-inference-overview.html#ae-19",
    "title": "Inference overview",
    "section": "ae-19",
    "text": "ae-19\n\n\nGo to the course GitHub org and find your ae-19 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/10-exam-1-review.html#while-you-wait-for-class-to-begin",
    "href": "slides/10-exam-1-review.html#while-you-wait-for-class-to-begin",
    "title": "Exam 1 Review",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\nOpen your ae-07 project in RStudio, render your document, and commit and push."
  },
  {
    "objectID": "slides/10-exam-1-review.html#announcements",
    "href": "slides/10-exam-1-review.html#announcements",
    "title": "Exam 1 Review",
    "section": "Announcements",
    "text": "Announcements\n\nExam 1 is released on today at noon and is due at 2pm on Monday.\n\nNo TA OH during the exam.\nI will have OH 4-5pm on Friday on Zoom: bit.ly/minezoom\nAny clarification questions must be emailed to me only.\nNo Slack use during the exam, even about non-exam related questions."
  },
  {
    "objectID": "slides/10-exam-1-review.html#continue-from-last-time-ae-07",
    "href": "slides/10-exam-1-review.html#continue-from-last-time-ae-07",
    "title": "Exam 1 Review",
    "section": "Continue from last time: ae-07",
    "text": "Continue from last time: ae-07\n\n\nGo to your container and open your ae-07 project.\nRender, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\nYou might see an error. Read it and do as it says!\n\n\n\n\nPull.\nOnce again, render, commit, and push."
  },
  {
    "objectID": "slides/10-exam-1-review.html#logistics-questions",
    "href": "slides/10-exam-1-review.html#logistics-questions",
    "title": "Exam 1 Review",
    "section": "Logistics questions",
    "text": "Logistics questions\n\nCan we use outside sources for our code on the exam as long as we cite where it’s from.\n\nYes! However, you should be striving the solve the questions in the style that we learned. For example, ggplot2 is not the only plotting package in R. But we expect you to use ggplot2 when making plots, not another system.\n\n\nWill content on lab 3 be on the exam? If so, will we be able to access an answer key at some point during the exam period?\n\nYes, will be posted Friday at midnight.\n\n\n\nWhen asked to replicate a graph, should we also adjust fig height/width?\n\nYes, though you shouldn’t worry about matching it exactly. More that it should be legible and if the plot you’re replicating is wider than taller, the plot you’re submitting should be as well."
  },
  {
    "objectID": "slides/10-exam-1-review.html#packages",
    "href": "slides/10-exam-1-review.html#packages",
    "title": "Exam 1 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/10-exam-1-review.html#operators-in-r---vs.",
    "href": "slides/10-exam-1-review.html#operators-in-r---vs.",
    "title": "Exam 1 Review",
    "section": "Operators in R: <- vs. =",
    "text": "Operators in R: <- vs. =\n\n<-: assignment\n=: equals\n\n\n# good\nx <- 2\n\n# works, but bad\nx = 2\n\n# doesn't work\ndf <- df |>\n  mutate(x <- 2)\n\n# good\ndf <- df |>\n  mutate(x = 2)"
  },
  {
    "objectID": "slides/10-exam-1-review.html#operators-in-r-vs.-vs.-in",
    "href": "slides/10-exam-1-review.html#operators-in-r-vs.-vs.-in",
    "title": "Exam 1 Review",
    "section": "Operators in R: = vs. == vs. %in%",
    "text": "Operators in R: = vs. == vs. %in%\n\n==: is equal to\n%in%: in\n\n\nx = c(1, 2, 3)\ny = c(3, 4, 5)\n\n# do elements in x equal those in y?\n# check if each element in x is equal to the \n# corresponding element in y\nx == y\n\n[1] FALSE FALSE FALSE\n\n\n\n\n# are any elements in x also in y?\n# check if any element in x is equal to any element in y\nx %in% y\n\n[1] FALSE FALSE  TRUE\n\n\n\n\n\n# set x equal to y\nx = y\nx\n\n[1] 3 4 5"
  },
  {
    "objectID": "slides/10-exam-1-review.html#in-vs",
    "href": "slides/10-exam-1-review.html#in-vs",
    "title": "Exam 1 Review",
    "section": "%in% vs ==",
    "text": "%in% vs ==\n\ndf <- tibble(\n  x = c(1, 2, 3, 4),\n  y = c(\"a\", \"b\", \"c\", \"d\")\n  )\ndf\n\n# A tibble: 4 × 2\n      x y    \n  <dbl> <chr>\n1     1 a    \n2     2 b    \n3     3 c    \n4     4 d    \n\n# Filter for x is 2\ndf |>\n  filter(x == 2)\n\n# A tibble: 1 × 2\n      x y    \n  <dbl> <chr>\n1     2 b"
  },
  {
    "objectID": "slides/10-exam-1-review.html#in-vs-1",
    "href": "slides/10-exam-1-review.html#in-vs-1",
    "title": "Exam 1 Review",
    "section": "%in% vs ==",
    "text": "%in% vs ==\n\n# Filter for x is 2 or 3\ndf |>\n  filter(x == c(2, 3))\n\n# A tibble: 0 × 2\n# … with 2 variables: x <dbl>, y <chr>\n\n# Filter for x is 2 or 3\ndf |>\n  filter(x %in% c(2, 3))\n\n# A tibble: 2 × 2\n      x y    \n  <dbl> <chr>\n1     2 b    \n2     3 c"
  },
  {
    "objectID": "slides/10-exam-1-review.html#operators-in-r-vs.",
    "href": "slides/10-exam-1-review.html#operators-in-r-vs.",
    "title": "Exam 1 Review",
    "section": "Operators in R: |> vs. %>%",
    "text": "Operators in R: |> vs. %>%\n\n|>: pipe operator (newer – what we’ve been using in class)\n%>%: pipe operator (older – what you see in the videos)\nThey effectively do the same thing"
  },
  {
    "objectID": "slides/10-exam-1-review.html#interpreting-data-visualizations-i",
    "href": "slides/10-exam-1-review.html#interpreting-data-visualizations-i",
    "title": "Exam 1 Review",
    "section": "Interpreting data visualizations I",
    "text": "Interpreting data visualizations I\n\nProvide a 1-2 sentence interpretation of the relationship between city and highway mileage of cars.\n\n\n\nggplot(\n  mpg,\n  aes(x = cty, y = hwy)\n) +\n  geom_jitter(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    x = \"City MPG\", \n    y = \"Highway MPG\"\n  )"
  },
  {
    "objectID": "slides/10-exam-1-review.html#interpreting-data-visualizations-ii",
    "href": "slides/10-exam-1-review.html#interpreting-data-visualizations-ii",
    "title": "Exam 1 Review",
    "section": "Interpreting data visualizations II",
    "text": "Interpreting data visualizations II\n\nProvide a 1-2 sentence interpretation of the relationship between city and highway mileage of cars, taking into consideration whether they’re 4 wheel drive, front wheel drive, or rear wheel drive.\n\n\n\nggplot(\n  mpg,\n  aes(x = cty, y = hwy, color = drv)\n) +\n  geom_jitter(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    x = \"City MPG\", \n    y = \"Highway MPG\"\n  )"
  },
  {
    "objectID": "slides/10-exam-1-review.html#geom_jitter-vs.-geom_point",
    "href": "slides/10-exam-1-review.html#geom_jitter-vs.-geom_point",
    "title": "Exam 1 Review",
    "section": "geom_jitter() vs. geom_point()",
    "text": "geom_jitter() vs. geom_point()\n\nThe same dataset is plotted with geom_jitter() and geom_point() below. Why do the two plots look different?"
  },
  {
    "objectID": "slides/10-exam-1-review.html#distinct",
    "href": "slides/10-exam-1-review.html#distinct",
    "title": "Exam 1 Review",
    "section": "distinct()",
    "text": "distinct()\n\n\n\nmpg |>\n  select(cty, hwy)\n\n# A tibble: 234 × 2\n     cty   hwy\n   <int> <int>\n 1    18    29\n 2    21    29\n 3    20    31\n 4    21    30\n 5    16    26\n 6    18    26\n 7    18    27\n 8    18    26\n 9    16    25\n10    20    28\n# … with 224 more rows\n\n\n\n\nmpg |>\n  distinct(cty, hwy)\n\n# A tibble: 78 × 2\n     cty   hwy\n   <int> <int>\n 1    18    29\n 2    21    29\n 3    20    31\n 4    21    30\n 5    16    26\n 6    18    26\n 7    18    27\n 8    16    25\n 9    20    28\n10    19    27\n# … with 68 more rows"
  },
  {
    "objectID": "slides/10-exam-1-review.html#working-with-categorical-data",
    "href": "slides/10-exam-1-review.html#working-with-categorical-data",
    "title": "Exam 1 Review",
    "section": "Working with categorical data",
    "text": "Working with categorical data\n\ntshirts <- tibble(\n  size = c(\"Large\", \"Medium\", \"Large\", \"Small\", \"Small\", \"Medium\", \"Small\", \"X-Large\", \"X-Small\"),\n  price = c(10, 15, 12, 18, 22, 13, 67, 12, 10)\n)\n\nggplot(tshirts, aes(x = size)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/10-exam-1-review.html#fct_relevel",
    "href": "slides/10-exam-1-review.html#fct_relevel",
    "title": "Exam 1 Review",
    "section": "fct_relevel()",
    "text": "fct_relevel()\nReorder levels based on an order you provide\n\ntshirts |>\n  mutate(size = fct_relevel(size, \"X-Small\", \"Small\", \"Medium\", \"Large\", \"X-Large\")) |>\n  ggplot(aes(x = size)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/10-exam-1-review.html#fct_reorder",
    "href": "slides/10-exam-1-review.html#fct_reorder",
    "title": "Exam 1 Review",
    "section": "fct_reorder()",
    "text": "fct_reorder()\nReorder levels based on another variable\n\ntshirts |>\n  mutate(size = fct_reorder(size, price, mean)) |>\n  ggplot(aes(x = size)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/10-exam-1-review.html#fct_other",
    "href": "slides/10-exam-1-review.html#fct_other",
    "title": "Exam 1 Review",
    "section": "fct_other()",
    "text": "fct_other()\nLump some levels to “Other”\n\ntshirts |>\n  mutate(size = fct_other(size, keep = c(\"Small\", \"Medium\", \"Large\"))) |>\n  ggplot(aes(x = size)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/10-exam-1-review.html#pivoting-and-joining",
    "href": "slides/10-exam-1-review.html#pivoting-and-joining",
    "title": "Exam 1 Review",
    "section": "Pivoting and joining",
    "text": "Pivoting and joining\nLet’s visit https://www.garrickadenbuie.com/project/tidyexplain!\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/24-communicate.html#announcements",
    "href": "slides/24-communicate.html#announcements",
    "title": "Communicating data science results effectively",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours today 2:45 - 4:45pm in person or on Zoom\nRemaining due dates:\n\n\nPeer eval 2 due tonight by 11pm. Late submission is not possible!\nSurvey on Sakai for topics requested for next week.\nProject presentations next Monday in lab – all team members must be present.\nProject write-up and final repo due 11:59pm Thur, Dec 8 – you will lose access to your repo at this time.\nHW 6 due 11:59pm Friday, Dec 9.\nRemaining application exercises due on the usual schedule.\n(Optional) Exam retake – due 11:59 pm Thur, Dec 15 – absolutely no late submissions, extensions, etc. for any reason."
  },
  {
    "objectID": "slides/24-communicate.html#exam-retake",
    "href": "slides/24-communicate.html#exam-retake",
    "title": "Communicating data science results effectively",
    "section": "Exam retake",
    "text": "Exam retake\n\nReleased after Exam 2 grades are released, by next week.\nWeighted average between your lowest exam score and what you earn on the retake\nIf you earned a 0% on Exam 2 and earn 100% on Exam Retake, you will earn an 85%.\nOverall task: Create a six question assessment covering specific topics from the course, write a key and a grading rubric for each, as well as a justification."
  },
  {
    "objectID": "slides/24-communicate.html#project",
    "href": "slides/24-communicate.html#project",
    "title": "Communicating data science results effectively",
    "section": "Project",
    "text": "Project\n\nReview peer evaluations left by your peers, implement updates as you see fit, close the issue once you review them.\nHave a clear plan for who is doing what, open issues on your repo, and assign them to individuals who can then close the issues as they finish a task.\nSchedule at least one team meting between today and your presentation to practice your presentation together."
  },
  {
    "objectID": "slides/24-communicate.html#whats-going-on-in-this-plot",
    "href": "slides/24-communicate.html#whats-going-on-in-this-plot",
    "title": "Communicating data science results effectively",
    "section": "What’s going on in this plot?",
    "text": "What’s going on in this plot?"
  },
  {
    "objectID": "slides/24-communicate.html#take-a-sad-plot-make-it-better",
    "href": "slides/24-communicate.html#take-a-sad-plot-make-it-better",
    "title": "Communicating data science results effectively",
    "section": "Take A Sad Plot & Make It Better",
    "text": "Take A Sad Plot & Make It Better\n\nSource: https://alison.netlify.app/rlm-sad-plot-better"
  },
  {
    "objectID": "slides/24-communicate.html#ae-20",
    "href": "slides/24-communicate.html#ae-20",
    "title": "Communicating data science results effectively",
    "section": "ae-20",
    "text": "ae-20\n\n\nGo to the course GitHub org and find your ae-20 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nYou should have already pushed updates on Tuesday, so you should be good for submission."
  },
  {
    "objectID": "slides/24-communicate.html#recap",
    "href": "slides/24-communicate.html#recap",
    "title": "Communicating data science results effectively",
    "section": "Recap",
    "text": "Recap\n\n\nRepresent percentages as parts of a whole\nPlace variables representing time on the x-axis when possible\nPay attention to data types, e.g., represent time as time on a continuous scale, not years as levels of a categorical variable\nPrefer direct labeling over legends\nUse accessible colors\nUse color to draw attention\nPick a purpose and label, color, annotate for that purpose\nCommunicate your main message directly in the plot labels\nSimplify before you call it done (a.k.a. “Before you leave the house, look in the mirror and take one thing off”)\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/03-grammar-of-graphics.html#announcements",
    "href": "slides/03-grammar-of-graphics.html#announcements",
    "title": "Grammar of graphics",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week\n“Graded” AEs also start this week – commit and push to your repo within 3 days of AE"
  },
  {
    "objectID": "slides/03-grammar-of-graphics.html#examining-data-visualization",
    "href": "slides/03-grammar-of-graphics.html#examining-data-visualization",
    "title": "Grammar of graphics",
    "section": "Examining data visualization",
    "text": "Examining data visualization\n\n\nDiscuss the following for the visualization.\n\nWhat is the visualization trying to show?\nWhat is effective, i.e. what is done well?\nWhat is ineffective, i.e. what could be improved?\nWhat are you curious about after looking at the visualization?\n\n\n\n\n−+\n04:00\n\n\n\n\n\n\n\nSource: Twitter"
  },
  {
    "objectID": "slides/03-grammar-of-graphics.html#questions-from-the-prepare-materials",
    "href": "slides/03-grammar-of-graphics.html#questions-from-the-prepare-materials",
    "title": "Grammar of graphics",
    "section": "Questions from the prepare materials?",
    "text": "Questions from the prepare materials?"
  },
  {
    "objectID": "slides/03-grammar-of-graphics.html#ae-01",
    "href": "slides/03-grammar-of-graphics.html#ae-01",
    "title": "Grammar of graphics",
    "section": "ae-01",
    "text": "ae-01\n\n\nGo to the course GitHub org and find your ae-01 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/03-grammar-of-graphics.html#recap-of-ae",
    "href": "slides/03-grammar-of-graphics.html#recap-of-ae",
    "title": "Grammar of graphics",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()\n\n\nAesthetic attributes of a geometries (color, size, transparency, etc.) can be mapped to variables in the data or set by the user, e.g. color = binary vs. color = \"pink\".\nUse facet_wrap() when faceting (creating small multiples) by one variable and facet_grid() when faceting by two variables.\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/20-bootstrap.html#checklist",
    "href": "slides/20-bootstrap.html#checklist",
    "title": "Bootstrap",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-17"
  },
  {
    "objectID": "slides/20-bootstrap.html#announcements",
    "href": "slides/20-bootstrap.html#announcements",
    "title": "Bootstrap",
    "section": "Announcements",
    "text": "Announcements\n– HW 5 (Due Thursday)\n– Project Proposal (Due Friday)"
  },
  {
    "objectID": "slides/20-bootstrap.html#project-hints",
    "href": "slides/20-bootstrap.html#project-hints",
    "title": "Bootstrap",
    "section": "Project Hints",
    "text": "Project Hints\n– Reference the AEs and Videos for example research questions\n– Make sure your variable is not an id\n– Write yourself a project outline\n\nWhat is the topic?\nWhy do we care?\nWhat are we interested in?"
  },
  {
    "objectID": "slides/20-bootstrap.html#goals",
    "href": "slides/20-bootstrap.html#goals",
    "title": "Bootstrap",
    "section": "Goals",
    "text": "Goals\n– What is bootstrapping\n– What is a confidence interval"
  },
  {
    "objectID": "slides/20-bootstrap.html#warm-up-remember-the-penguins",
    "href": "slides/20-bootstrap.html#warm-up-remember-the-penguins",
    "title": "Bootstrap",
    "section": "Warm Up: Remember the Penguins",
    "text": "Warm Up: Remember the Penguins\n\n\\(\\widehat{body.mass} = -5781 + 49.7 \\times flipper.length\\)\n– What does this line tell us?"
  },
  {
    "objectID": "slides/20-bootstrap.html#section",
    "href": "slides/20-bootstrap.html#section",
    "title": "Bootstrap",
    "section": "",
    "text": "\\(body.mass = \\beta_o + \\beta_1 \\times flipper.length\\)\nWhat is \\(\\beta_1\\)?\nDoes our estimated line tell us what \\(\\beta_1\\) is?"
  },
  {
    "objectID": "slides/20-bootstrap.html#population-parameters",
    "href": "slides/20-bootstrap.html#population-parameters",
    "title": "Bootstrap",
    "section": "Population Parameters",
    "text": "Population Parameters\n– \\(\\beta_1\\)\n– \\(\\mu\\)\n– \\(\\pi\\) or p\n. . ."
  },
  {
    "objectID": "slides/20-bootstrap.html#this-week",
    "href": "slides/20-bootstrap.html#this-week",
    "title": "Bootstrap",
    "section": "This week",
    "text": "This week\n– Is all about concepts\n– Main goal is to develop a fundamental understanding about bootstrapping, confidence intervals, and hypothesis testing.\nWe will put our understanding into more practice starting next week."
  },
  {
    "objectID": "slides/20-bootstrap.html#in-summary",
    "href": "slides/20-bootstrap.html#in-summary",
    "title": "Bootstrap",
    "section": "In Summary",
    "text": "In Summary\n\nBootstrap methods are simulation methods\nVariability - Uncertainty: How spread out your data are\nWe can use this to guess plausible values around our parameter of interest\nThis is called a confidence interval, and it’s different than probability\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/19-logistic-regression.html#while-you-wait-for-class-to-begin",
    "href": "slides/19-logistic-regression.html#while-you-wait-for-class-to-begin",
    "title": "Models with multiple predictors",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\nClone your ae-18 project from GitHub, render your document, update your name, and commit and push.\nPost any questions you have about the material so far at sli.do / #sta199."
  },
  {
    "objectID": "slides/19-logistic-regression.html#announcements",
    "href": "slides/19-logistic-regression.html#announcements",
    "title": "Models with multiple predictors",
    "section": "Announcements",
    "text": "Announcements\n\nTeam evaluations open – due Sat night, 11:59pm (so we can review before Monday’s lab)\nHW 5 will be posted soon\nHW 6"
  },
  {
    "objectID": "slides/19-logistic-regression.html#questions-from-last-time",
    "href": "slides/19-logistic-regression.html#questions-from-last-time",
    "title": "Models with multiple predictors",
    "section": "Questions from last time",
    "text": "Questions from last time\nQ: What is a two-way table?\nA: A table of frequencies for two categorical variables.\n\n\nHow do we go from what’s on the left to what’s on the right?\n\n\n\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\npenguins |>\n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  <fct>     <fct>  <int>\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    <NA>       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    <NA>       5\n\n\n\n\n\n# A tibble: 3 × 4\n  species   female  male  `NA`\n  <fct>      <int> <int> <int>\n1 Adelie        73    73     6\n2 Chinstrap     34    34    NA\n3 Gentoo        58    61     5"
  },
  {
    "objectID": "slides/19-logistic-regression.html#questions-from-last-time-1",
    "href": "slides/19-logistic-regression.html#questions-from-last-time-1",
    "title": "Models with multiple predictors",
    "section": "Questions from last time",
    "text": "Questions from last time\nQ: How do we build a two-way table in a pipeline?\n\n\npenguins |>\n  count(species, sex) |>\n  pivot_wider(names_from = sex, values_from = n)\n\n# A tibble: 3 × 4\n  species   female  male  `NA`\n  <fct>      <int> <int> <int>\n1 Adelie        73    73     6\n2 Chinstrap     34    34    NA\n3 Gentoo        58    61     5"
  },
  {
    "objectID": "slides/19-logistic-regression.html#questions-from-last-time-2",
    "href": "slides/19-logistic-regression.html#questions-from-last-time-2",
    "title": "Models with multiple predictors",
    "section": "Questions from last time",
    "text": "Questions from last time\nQ: How do we know whether we can scrape data from a website?\n\nA: Technically, with robotstxt::paths_allowed(), but that doesn’t address ethical considerations which are just as important, if not more.\n\nrobotstxt::paths_allowed(\"https://www.duke.edu/\")\n\n[1] TRUE"
  },
  {
    "objectID": "slides/19-logistic-regression.html#questions-from-last-time-3",
    "href": "slides/19-logistic-regression.html#questions-from-last-time-3",
    "title": "Models with multiple predictors",
    "section": "Questions from last time",
    "text": "Questions from last time\nQ: What is the proper notation for writing out a model?\n\n\nPopulation models (truth):\n\n\\[\ny = \\beta_0 + \\beta_1 \\times x + \\epsilon\n\\]\n\nSample models (estimated):\n\n\\[\n\\hat{y} = b_0 + b_1 \\times x\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#goals",
    "href": "slides/19-logistic-regression.html#goals",
    "title": "Models with multiple predictors",
    "section": "Goals",
    "text": "Goals\n\nFit and interpret models for predicting binary outcomes\nIntroduce over fitting and mitigating it by splitting the data into training and testing sets"
  },
  {
    "objectID": "slides/19-logistic-regression.html#what-is-logistic-regression",
    "href": "slides/19-logistic-regression.html#what-is-logistic-regression",
    "title": "Models with multiple predictors",
    "section": "What is logistic regression?",
    "text": "What is logistic regression?\n\n\n\nSimilar to linear regression…. but\nModeling tool when our response is categorical"
  },
  {
    "objectID": "slides/19-logistic-regression.html#modelling-binary-outcomes",
    "href": "slides/19-logistic-regression.html#modelling-binary-outcomes",
    "title": "Models with multiple predictors",
    "section": "Modelling binary outcomes",
    "text": "Modelling binary outcomes\n\nVariables with binary outcomes follow the Bernouilli distribution:\n\n\\(y_i \\sim Bern(p)\\)\n\\(p\\): Probability of success\n\\(1-p\\): Probability of failure\n\nWe can’t model \\(y\\) directly, so instead we model \\(p\\)"
  },
  {
    "objectID": "slides/19-logistic-regression.html#linear-model",
    "href": "slides/19-logistic-regression.html#linear-model",
    "title": "Models with multiple predictors",
    "section": "Linear model",
    "text": "Linear model\n\\[\np_i = \\beta_o + \\beta_1 \\times X_1 + \\cdots + \\epsilon\n\\]\n\nBut remember that \\(p\\) must be between 0 and 1\nWe need a link function that transforms the linear model to have an appropriate range"
  },
  {
    "objectID": "slides/19-logistic-regression.html#logit-link-function",
    "href": "slides/19-logistic-regression.html#logit-link-function",
    "title": "Models with multiple predictors",
    "section": "Logit link function",
    "text": "Logit link function\nThe logit function take values between 0 and 1 (probabilities) and maps them to values in the range negative infinity to positive infinity:\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg)\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#this-isnt-exactly-what-we-need-though..",
    "href": "slides/19-logistic-regression.html#this-isnt-exactly-what-we-need-though..",
    "title": "Models with multiple predictors",
    "section": "This isn’t exactly what we need though…..",
    "text": "This isn’t exactly what we need though…..\n\nRecall, the goal is to take values between -\\(\\infty\\) and \\(\\infty\\) and map them to probabilities.\nWe need the opposite of the link function… or the inverse\nTaking the inverse of the logit function will map arbitrary real values back to the range [0, 1]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#generalized-linear-model",
    "href": "slides/19-logistic-regression.html#generalized-linear-model",
    "title": "Models with multiple predictors",
    "section": "Generalized linear model",
    "text": "Generalized linear model\n\nWe model the logit (log-odds) of \\(p\\) :\n\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg) = \\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon\n\\]\n\nThen take the inverse to obtain the predicted \\(p\\):\n\n\\[\np_i = \\frac{e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}{1 + e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#a-logistic-model-visualized",
    "href": "slides/19-logistic-regression.html#a-logistic-model-visualized",
    "title": "Models with multiple predictors",
    "section": "A logistic model visualized",
    "text": "A logistic model visualized"
  },
  {
    "objectID": "slides/19-logistic-regression.html#takeaways",
    "href": "slides/19-logistic-regression.html#takeaways",
    "title": "Models with multiple predictors",
    "section": "Takeaways",
    "text": "Takeaways\n\nGeneralized linear models allow us to fit models to predict non-continuous outcomes\nPredicting binary outcomes requires modeling the log-odds of success, where p = probability of success"
  },
  {
    "objectID": "slides/19-logistic-regression.html#review-questions",
    "href": "slides/19-logistic-regression.html#review-questions",
    "title": "Models with multiple predictors",
    "section": "Review questions",
    "text": "Review questions\n\nWhat is a training data set?\n\n\n“Sandbox” for model building. Build the model on these data.\n\n\n\nWhat is a testing data set?\n\n\n\nHeld in reserve to test one or two chosen models and to evaluate their performance.\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#while-you-wait-for-class-to-begin",
    "href": "slides/05-grammar-of-data-wrangling.html#while-you-wait-for-class-to-begin",
    "title": "Grammar of data wrangling",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\n\nClone your ae-03 repo.\nAny questions from prepare materials? Go to slido.com / #sta199. You can also upvote others’ questions."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#announcements",
    "href": "slides/05-grammar-of-data-wrangling.html#announcements",
    "title": "Grammar of data wrangling",
    "section": "Announcements",
    "text": "Announcements\n\nRequest videos for missed classes via the video request form\nAsk course questions on Slack\n\nUsing code formatting and proper indentation\nTaking screenshots\nChecking for previous questions"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#questions-from-last-time",
    "href": "slides/05-grammar-of-data-wrangling.html#questions-from-last-time",
    "title": "Grammar of data wrangling",
    "section": "Questions from last time",
    "text": "Questions from last time\n\nHow come I had to load my packages each session before basic functions like ggplot() become available?\nWill we spend time learning more of the actual fundamental statistics needed to understand how the different graphs work and which ones are most useful for different data sets?"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#coding-style-workflow",
    "href": "slides/05-grammar-of-data-wrangling.html#coding-style-workflow",
    "title": "Grammar of data wrangling",
    "section": "Coding style + workflow",
    "text": "Coding style + workflow\n\n\nAvoid long lines of code.\n\nWe should be able to see all of your code in the PDF document you submit.\n\nLabel code chunks.\n\nDo not put spaces in the code-chunk labels.\n\nRender, commit, and push regularly.\n\nThink about it like clicking to save regularly as you type a report."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#ae-03",
    "href": "slides/05-grammar-of-data-wrangling.html#ae-03",
    "title": "Grammar of data wrangling",
    "section": "ae-03",
    "text": "ae-03\n\n\nGo to the course GitHub org and find your ae-03 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline (3 days from today)."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#recap-of-ae",
    "href": "slides/05-grammar-of-data-wrangling.html#recap-of-ae",
    "title": "Grammar of data wrangling",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nThe pipe operator, |>, can be read as “and then”.\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\nsum(1, 2)\n\n[1] 3\n\n1 |> \n  sum(2)\n\n[1] 3\n\n\n\nAlways use a line break after the pipe, and indent the next line of code.\n\nJust like always use a line break between layers of ggplots, after +, and indent the next line.\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/09-data-import.html#while-you-wait-for-class-to-begin",
    "href": "slides/09-data-import.html#while-you-wait-for-class-to-begin",
    "title": "Data import",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\n\n\n\n\n\nImportant\n\n\nCome up with at least one question you’d like to see answered in the Exam 1 review on Thursday.\nGo to slido.com and submit your question with the code #sta199exam1.\nYou can also upvote others’ questions."
  },
  {
    "objectID": "slides/09-data-import.html#announcements",
    "href": "slides/09-data-import.html#announcements",
    "title": "Data import",
    "section": "Announcements",
    "text": "Announcements\n\nLab 3 due Friday night (11:59 pm) – but I strongly recommend you finish and submit it before the exam begins!\nExam 1 is released on Thursday at noon and is due at 2pm on Monday.\n\nNo TA OH during the exam.\nI will have OH 4-5pm on Friday (on Zoom).\nAny clarification questions must be emailed to me only.\nNo Slack use during the exam, even about non-exam related questions."
  },
  {
    "objectID": "slides/09-data-import.html#exam-study-tips",
    "href": "slides/09-data-import.html#exam-study-tips",
    "title": "Data import",
    "section": "Exam study tips",
    "text": "Exam study tips\n\nTake notes that you can reference\nReview feedback given to you on graded work\nRevisit AEs\nReview suggested solutions\nAsk questions"
  },
  {
    "objectID": "slides/09-data-import.html#new-resources",
    "href": "slides/09-data-import.html#new-resources",
    "title": "Data import",
    "section": "New resources",
    "text": "New resources\nOn the course website:\n\nMore links to package documentation on the useful links page: https://sta199-f22-1.github.io/course-links.html\nNew page with links to cheatsheets: https://sta199-f22-1.github.io/computing-cheatsheets.html"
  },
  {
    "objectID": "slides/09-data-import.html#continue-from-last-time-ae-06",
    "href": "slides/09-data-import.html#continue-from-last-time-ae-06",
    "title": "Data import",
    "section": "Continue from last time: ae-06",
    "text": "Continue from last time: ae-06\n\n\nGo to your container and open your ae-06 project.\nRender, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\nYou will see an error. Read it and do as it says!\n\n\n\n\nPull.\nOnce again, render, commit, and push."
  },
  {
    "objectID": "slides/09-data-import.html#recap-of-ae",
    "href": "slides/09-data-import.html#recap-of-ae",
    "title": "Data import",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nA vector can only have one type of elements in it. Placing elements with different types into a vector cases type coercion.\nFactor is a class that R uses for categorical data and factors allow us to customize order and behaviour of levels."
  },
  {
    "objectID": "slides/09-data-import.html#reading-rectangular-data",
    "href": "slides/09-data-import.html#reading-rectangular-data",
    "title": "Data import",
    "section": "Reading rectangular data",
    "text": "Reading rectangular data\n\nUsing readr:\n\nMost commonly: read_csv()\nMaybe also: read_tsv(), read_delim(), etc.\n\nUsing readxl: read_excel()\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/09-data-import.html#ae-07",
    "href": "slides/09-data-import.html#ae-07",
    "title": "Data import",
    "section": "ae-07",
    "text": "ae-07\n\n\nGo to the course GitHub org and find your ae-07 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today.\n\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#while-you-wait-for-class-to-begin",
    "href": "slides/11-dse-misrepresentation.html#while-you-wait-for-class-to-begin",
    "title": "Data science ethics: Misrepresentation",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\nClone your ae-08 repo.\nAny questions from prepare materials? Go to slido.com / #sta199. You can also upvote others’ questions."
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#announcements",
    "href": "slides/11-dse-misrepresentation.html#announcements",
    "title": "Data science ethics: Misrepresentation",
    "section": "Announcements",
    "text": "Announcements\n\nSlight change of plans for this week – dedicating entire week to data science ethics\nMake sure to catch up with reading and (required) videos by Thursday\nHighly recommend watching thew optional videos as well – if not by Thursday, over the break"
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#stand-your-ground",
    "href": "slides/11-dse-misrepresentation.html#stand-your-ground",
    "title": "Data science ethics: Misrepresentation",
    "section": "Stand your ground",
    "text": "Stand your ground\n\nIn 2005, the Florida legislature passed the controversial “Stand Your Ground” law that broadened the situations in which citizens can use lethal force to protect themselves against perceived threats. Advocates believed that the new law would ultimately reduce crime; opponents feared an increase in the use of lethal force.\n\n\n\n\nWhat does the visualization, published by Reuters on February 16, 2014, say about the number of firearm murders in Florida over the years?\n\n\n\n−+\n03:00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: MDSR, Chp 8."
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#covid-cases",
    "href": "slides/11-dse-misrepresentation.html#covid-cases",
    "title": "Data science ethics: Misrepresentation",
    "section": "COVID cases",
    "text": "COVID cases\n\nIn May 2020, the state of Georgia published the following visualization. What does this plot say about the number of COVID cases in the most impacted counties?\n\n\n\n\nWhat changes need to be made to this graph to fix it and make it less misleading?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#another-one-on-covid-cases",
    "href": "slides/11-dse-misrepresentation.html#another-one-on-covid-cases",
    "title": "Data science ethics: Misrepresentation",
    "section": "Another one on COVID cases",
    "text": "Another one on COVID cases\n\nWhat is misleading about the following two visualizations (from here) that are presented together to show the trajectory of COVID?\n\n\n\nHow it started (Jan 3, 2022)\n\n\n\n\n\n\nHow it’s going (Feb 10, 2022)"
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#redistributive-taxes",
    "href": "slides/11-dse-misrepresentation.html#redistributive-taxes",
    "title": "Data science ethics: Misrepresentation",
    "section": "Redistributive taxes",
    "text": "Redistributive taxes\n\nWhat is misleading about the following visualization (shared here) about Americans’ views on redistributive taxes?"
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#ae-08",
    "href": "slides/11-dse-misrepresentation.html#ae-08",
    "title": "Data science ethics: Misrepresentation",
    "section": "ae-08",
    "text": "ae-08\n\n\nGo to the course GitHub org and find your ae-08 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/11-dse-misrepresentation.html#recap-of-ae",
    "href": "slides/11-dse-misrepresentation.html#recap-of-ae",
    "title": "Data science ethics: Misrepresentation",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nNot all visualizations are equally informative. But, perhaps more importantly, some might be misleading.\nAlways be cautious of a visualization, particularly one with an agenda, at the first glance. Look closely to check if it might be put together to mislead, instead of clarify.\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#announcements",
    "href": "slides/21-hypothesis-testing.html#announcements",
    "title": "Hypothesis testing",
    "section": "Announcements",
    "text": "Announcements\n\nHW 5 due tonight\nProject draft due tomorrow night"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#goals",
    "href": "slides/21-hypothesis-testing.html#goals",
    "title": "Hypothesis testing",
    "section": "Goals",
    "text": "Goals\n\nReview constructing confidence intervals via bootstrapping\nHypothesis testing, p-values, and making conclusions\n\nTest a claim about a population parameter\nUse simulation-based methods to generate the null distribution\nCalculate and interpret the p-value\nUse the p-value to draw conclusions in the context of the data and the research question"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#review-bootstrap-intervals",
    "href": "slides/21-hypothesis-testing.html#review-bootstrap-intervals",
    "title": "Hypothesis testing",
    "section": "Review: Bootstrap intervals",
    "text": "Review: Bootstrap intervals\n\n\nWhy do we construct confidence intervals?\nWhat is bootstrapping?\nWhat does each dot on the plot represent? Note: The plot is of a bootstrap distribution of a sample mean.\n\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#why-do-we-construct-confidence-intervals",
    "href": "slides/21-hypothesis-testing.html#why-do-we-construct-confidence-intervals",
    "title": "Hypothesis testing",
    "section": "Why do we construct confidence intervals?",
    "text": "Why do we construct confidence intervals?\nTo estimate plausible values of a parameter of interest, e.g., a slope (\\(\\beta_1\\)), a mean (\\(\\mu\\)), a proportion (\\(p\\))."
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#what-is-bootstrapping",
    "href": "slides/21-hypothesis-testing.html#what-is-bootstrapping",
    "title": "Hypothesis testing",
    "section": "What is bootstrapping?",
    "text": "What is bootstrapping?\n\nBootstrapping is a statistical procedure that resamples(with replacement) a single data set to create many simulated samples.\nWe then use these simulated samples to quantify the uncertainty around the sample statistic we’re interested in, e.g., a slope (\\(\\b_1\\)), a mean (\\(\\bar{x}\\)), a proportion (\\(\\hat{p}\\))."
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#what-does-each-dot-on-the-plot-represent",
    "href": "slides/21-hypothesis-testing.html#what-does-each-dot-on-the-plot-represent",
    "title": "Hypothesis testing",
    "section": "What does each dot on the plot represent?",
    "text": "What does each dot on the plot represent?\nNote: The plot is of a bootstrap distribution of a sample mean.\n\nResample, with replacement, from the original data\nDo this 20 times (since there are 20 dots on the plot)\nCalculate the summary statistic of interest in each of these samples"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#hypothesis-testing-1",
    "href": "slides/21-hypothesis-testing.html#hypothesis-testing-1",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\n\nNull hypothesism \\(H_0\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\nNote: Hypotheses are always at the population level!"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#writing-hypotheses",
    "href": "slides/21-hypothesis-testing.html#writing-hypotheses",
    "title": "Hypothesis testing",
    "section": "Writing hypotheses",
    "text": "Writing hypotheses\n\nAs a researcher, you are interested in the average number of cups of coffee Duke students drink in a day. An article on The Chronicle suggests that the Duke students drink, on average, 1.2 cups of coffee. You are interested in evaluating if The Chronicle’s claim is too high. What are your hypotheses?\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#writing-hypotheses-1",
    "href": "slides/21-hypothesis-testing.html#writing-hypotheses-1",
    "title": "Hypothesis testing",
    "section": "Writing hypotheses",
    "text": "Writing hypotheses\n\n= As a researcher, you are interested in the average number of cups of coffee Duke students drink in a day.\n\nAn article on The Chronicle suggests that the Duke students drink, on average, 1.2 cups of coffee. \\(\\rightarrow H_0: \\mu = 1.2\\)\nYou are interested in evaluating if The Chronicle’s too high. \\(\\rightarrow H_0: \\mu < 1.2\\)"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#collecting-data",
    "href": "slides/21-hypothesis-testing.html#collecting-data",
    "title": "Hypothesis testing",
    "section": "Collecting data",
    "text": "Collecting data\nLet’s suppose you manage to take a random sample of 100 Duke students and ask them how many cups of coffee they drink and calculate the sample average to be \\(\\bar{x} = 1\\)."
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#hypothesis-testing-mindset",
    "href": "slides/21-hypothesis-testing.html#hypothesis-testing-mindset",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing “mindset”",
    "text": "Hypothesis testing “mindset”\n\nAssume yoi live in a world where null hypothesis is true: \\(\\mu = 1.2\\).\nAsk yourself how likely you are to observe the sample statistic, or something even more extreme, in this world: \\(P(\\bar{x} < 1 | \\mu = 1.2)\\) = ?"
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#ae-18",
    "href": "slides/21-hypothesis-testing.html#ae-18",
    "title": "Hypothesis testing",
    "section": "ae-18",
    "text": "ae-18\n\n\nGo to the course GitHub org and find your ae-18 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/21-hypothesis-testing.html#recap-of-ae",
    "href": "slides/21-hypothesis-testing.html#recap-of-ae",
    "title": "Hypothesis testing",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nA hypothesis test is a statistical technique used to evaluate competing claims (null and alternative hypotheses) using data.\nWe simulate a null distribution using our original data.\nWe use our sample statistic and direction of the alternative hypothesis to calculate the p-value.\nWe use the p-value to determine conclusions about the alternative hypotheses.\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#five-tips-for-success",
    "href": "slides/02-meet-the-toolkit.html#five-tips-for-success",
    "title": "Meet the toolkit",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings and watch the videos.\nDo the homework and lab.\nDon’t procrastinate and don’t let a week pass by with lingering questions."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#learning-during-a-pandemic",
    "href": "slides/02-meet-the-toolkit.html#learning-during-a-pandemic",
    "title": "Meet the toolkit",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#course-faq",
    "href": "slides/02-meet-the-toolkit.html#course-faq",
    "title": "Meet the toolkit",
    "section": "Course FAQ",
    "text": "Course FAQ\nQ - What data science background does this course assume?\nA - None.\n\nQ - Is this an intro stat course?\nA - While statistics \\(\\ne\\) data science, they are very closely related and have tremendous of overlap. Hence, this course is a great way to get started with statistics. However this course is not your typical high school statistics course.\n\n\nQ - Will we be doing computing?\nA - Yes."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#course-faq-1",
    "href": "slides/02-meet-the-toolkit.html#course-faq-1",
    "title": "Meet the toolkit",
    "section": "Course FAQ",
    "text": "Course FAQ\nQ - Is this an intro CS course?\nA - No, but many themes are shared.\n\nQ - What computing language will we learn?\nA - R.\n\n\nQ: Why not language X?\nA: We can discuss that over ☕."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#course-toolkit",
    "href": "slides/02-meet-the-toolkit.html#course-toolkit",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: sta199-f22-1.github.io\nSubmission: Gradescope\nDiscussion: Slack\nGradebook: Sakai\n\n\nDoing data science\n\nComputing:\n\nR\nRStudio\ntidyverse\nQuarto\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#learning-goals",
    "href": "slides/02-meet-the-toolkit.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n\n\ngain insight from data\ngain insight from data, reproducibly\ngain insight from data, reproducibly, using modern programming tools and techniques\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#reproducibility-checklist",
    "href": "slides/02-meet-the-toolkit.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be “reproducible”?\n\n\nNear-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#toolkit-for-reproducibility",
    "href": "slides/02-meet-the-toolkit.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#r-and-rstudio-1",
    "href": "slides/02-meet-the-toolkit.html#r-and-rstudio-1",
    "title": "Meet the toolkit",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\n\nR is an open-source statistical programming language\nR is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g. “I write R code in the RStudio IDE”\nRStudio is not a requirement for programming with R, but it’s very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#r-vs.-rstudio",
    "href": "slides/02-meet-the-toolkit.html#r-vs.-rstudio",
    "title": "Meet the toolkit",
    "section": "R vs. RStudio",
    "text": "R vs. RStudio\n\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#r-packages",
    "href": "slides/02-meet-the-toolkit.html#r-packages",
    "title": "Meet the toolkit",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data1\nAs of September 2022, there are over 18,000 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\n1 Wickham and Bryan, R Packages.\n2 CRAN contributed packages."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#tour-r-and-rstudio",
    "href": "slides/02-meet-the-toolkit.html#tour-r-and-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour: R and RStudio",
    "text": "Tour: R and RStudio"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#a-short-list-for-now-of-r-essentials",
    "href": "slides/02-meet-the-toolkit.html#a-short-list-for-now-of-r-essentials",
    "title": "Meet the toolkit",
    "section": "A short list (for now) of R essentials",
    "text": "A short list (for now) of R essentials\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\n\ndo_this(to_this)\ndo_that(to_this, to_that, with_those)\n\n\n\nPackages are installed with the install.packages() function and loaded with the library function, once per session:\n\n\ninstall.packages(\"package_name\")\nlibrary(package_name)"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#r-essentials-continued",
    "href": "slides/02-meet-the-toolkit.html#r-essentials-continued",
    "title": "Meet the toolkit",
    "section": "R essentials (continued)",
    "text": "R essentials (continued)\n\nColumns (variables) in data frames are accessed with $:\n\n\ndataframe$var_name\n\n\n\nObject documentation can be accessed with ?\n\n\n?mean"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#tidyverse",
    "href": "slides/02-meet-the-toolkit.html#tidyverse",
    "title": "Meet the toolkit",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#quarto-1",
    "href": "slides/02-meet-the-toolkit.html#quarto-1",
    "title": "Meet the toolkit",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports – each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#tour-quarto",
    "href": "slides/02-meet-the-toolkit.html#tour-quarto",
    "title": "Meet the toolkit",
    "section": "Tour: Quarto",
    "text": "Tour: Quarto"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#environments",
    "href": "slides/02-meet-the-toolkit.html#environments",
    "title": "Meet the toolkit",
    "section": "Environments",
    "text": "Environments\n\n\n\n\n\n\nImportant\n\n\nThe environment of your Quarto document is separate from the Console!\n\n\n\nRemember this, and expect it to bite you a few times as you’re learning to work with Quarto!"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#environments-1",
    "href": "slides/02-meet-the-toolkit.html#environments-1",
    "title": "Meet the toolkit",
    "section": "Environments",
    "text": "Environments\n\n\nFirst, run the following in the console:\n\nx <- 2\nx * 3\n\n\n\nAll looks good, eh?\n\n\nThen, add the following in an R chunk in your Quarto document\n\nx * 3\n\n\n\nWhat happens? Why the error?"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#how-will-we-use-quarto",
    "href": "slides/02-meet-the-toolkit.html#how-will-we-use-quarto",
    "title": "Meet the toolkit",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery assignment / report / project / etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#whats-with-all-the-hexes",
    "href": "slides/02-meet-the-toolkit.html#whats-with-all-the-hexes",
    "title": "Meet the toolkit",
    "section": "What’s with all the hexes?",
    "text": "What’s with all the hexes?"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#your-turn",
    "href": "slides/02-meet-the-toolkit.html#your-turn",
    "title": "Meet the toolkit",
    "section": "Your turn!",
    "text": "Your turn!\n\nae-0-bechdel-quarto\n\nThe Bechdel test asks whether a work of fiction features at least two women who talk to each other about something other than a man, and there must be two women named characters.\nGo to the course GitHub organization and clone ae-0-bechdel-quarto to your container.\nOpen and render the Quarto document bechdel.qmd, review the document, and fill in the blanks."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#git-and-github",
    "href": "slides/02-meet-the-toolkit.html#git-and-github",
    "title": "Meet the toolkit",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\n\nGit is a version control system – like “Track Changes” features from Microsoft Word, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet – like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#versioning",
    "href": "slides/02-meet-the-toolkit.html#versioning",
    "title": "Meet the toolkit",
    "section": "Versioning",
    "text": "Versioning"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#versioning-1",
    "href": "slides/02-meet-the-toolkit.html#versioning-1",
    "title": "Meet the toolkit",
    "section": "Versioning",
    "text": "Versioning\nwith human readable messages"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "href": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub",
    "text": "How will we use Git and GitHub"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "href": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "href": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "href": "slides/02-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#git-and-github-tips",
    "href": "slides/02-meet-the-toolkit.html#git-and-github-tips",
    "title": "Meet the toolkit",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and R: happygitwithr.com. Some of the content in there is beyond the scope of this course, but it’s a good place to look for help."
  },
  {
    "objectID": "slides/02-meet-the-toolkit.html#tour-git-github",
    "href": "slides/02-meet-the-toolkit.html#tour-git-github",
    "title": "Meet the toolkit",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\nIn Lab 0 next Monday!\nMake sure to create a GitHub account and fill out the Getting to know you survey!\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#while-you-wait-for-class-to-begin",
    "href": "slides/06-working-with-multiple-data-frames.html#while-you-wait-for-class-to-begin",
    "title": "Working with multiple data frames",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\nOpen your ae-03 project in RStudio (that you already started on Tuesday), render your document, and commit and push.\nAny questions from prepare materials? Go to slido.com / #sta199. You can also upvote others’ questions."
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#announcements",
    "href": "slides/06-working-with-multiple-data-frames.html#announcements",
    "title": "Working with multiple data frames",
    "section": "Announcements",
    "text": "Announcements\n\nRecap: Asking code related questions on Slack\n\nIdeally: Code formatted text, not screenshots\nIf need be: Screenshots, not photos of screens\nAlways include code along with the error\n\nTroubleshooting 101: Read your error messages in full, out loud if need be\nCode formatting 101:\n\nAlways line breaks after + and |>\nAdd line breaks as needed after , to help fit code on rendered PDF\nThink poetry (short lines), not novellas (long sentences)"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#ae-03",
    "href": "slides/06-working-with-multiple-data-frames.html#ae-03",
    "title": "Working with multiple data frames",
    "section": "ae-03",
    "text": "ae-03\nContinue work from Tuesday…"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#joining-datasets",
    "href": "slides/06-working-with-multiple-data-frames.html#joining-datasets",
    "title": "Working with multiple data frames",
    "section": "Joining datasets",
    "text": "Joining datasets\n\nDescribe a scenario where two datasets that contain information about students from this class may need to be joined. What might the analysis be about? What column (information) could be used to join the datasets?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#goal",
    "href": "slides/06-working-with-multiple-data-frames.html#goal",
    "title": "Working with multiple data frames",
    "section": "Goal",
    "text": "Goal\nJoin data from multiple data frames, summarize it, and create this plot."
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#ae-04",
    "href": "slides/06-working-with-multiple-data-frames.html#ae-04",
    "title": "Working with multiple data frames",
    "section": "ae-04",
    "text": "ae-04\n\n\nGo to the course GitHub org and find your ae-04 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#recap-of-ae",
    "href": "slides/06-working-with-multiple-data-frames.html#recap-of-ae",
    "title": "Working with multiple data frames",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nTBD…\n\n\n\n\n🔗 sta199-f22-1.github.io"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder)."
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nYou are welcome to, but you will need to install specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.2.1: https://cran.r-project.org/\nDownload and install the preview build of RStudio: https://www.rstudio.com/products/rstudio/download/preview/\nInstall git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "computing-cheatsheets.html",
    "href": "computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#slack",
    "href": "course-support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Slack is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on Slack before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Slack), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Mine Çetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times.  Duke encourages all students to access these resources.\n\nCAPS: Duke Counseling & Pyschological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu.\nTwo-Click Support: Duke Student Government and DukeReach partnership that connects students to help in just two clicks: https://bit.ly/TwoClickSupport."
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission will take place on GitHub and conversation on Slack.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Project details will be posted as the semester progresses."
  },
  {
    "objectID": "project-description.html#criteria-for-datasets",
    "href": "project-description.html#criteria-for-datasets",
    "title": "Project description",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 8 columns\nAt least 6 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nWe strongly recommend curating at least one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements."
  },
  {
    "objectID": "project-description.html#resources-for-datasets",
    "href": "project-description.html#resources-for-datasets",
    "title": "Project description",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)"
  },
  {
    "objectID": "project-description.html#proposal-components",
    "href": "project-description.html#proposal-components",
    "title": "Project description",
    "section": "Proposal components",
    "text": "Proposal components\nFor each data set, include the following:\n\nIntroduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.\n\n\n\nResearch question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\n\n\nGlimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set."
  },
  {
    "objectID": "project-description.html#proposal-grading",
    "href": "project-description.html#proposal-grading",
    "title": "Project description",
    "section": "Proposal grading",
    "text": "Proposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction and data\n3\n\n\nResearch question\n3\n\n\nGlimpse of data\n3\n\n\nWorkflow and formatting\n1\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description.html#draft-components",
    "href": "project-description.html#draft-components",
    "title": "Project description",
    "section": "Draft components",
    "text": "Draft components\n\nIntroduction and data\nThe introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and hypotheses.\nThen identify the source of the data, when and how it was collected, the cases, a general description of relevant variables.\n\n\nMethodology\nThe methodology section should include visualizations and summary statistics relevant to your research question. You should also justify the choice of statistical method(s) used to answer your research question.\n\n\nResults\nShowcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not better."
  },
  {
    "objectID": "project-description.html#draft-grading",
    "href": "project-description.html#draft-grading",
    "title": "Project description",
    "section": "Draft grading",
    "text": "Draft grading\nYour first draft will be reviewed and graded by your TAs. We recommend you incorporate their suggestions into your second (optional) draft before the second round of feedback by your peers."
  },
  {
    "objectID": "project-description.html#report-components",
    "href": "project-description.html#report-components",
    "title": "Project description",
    "section": "Report components",
    "text": "Report components\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\nResults\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\nDiscussion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#report-grading",
    "href": "project-description.html#report-grading",
    "title": "Project description",
    "section": "Report grading",
    "text": "Report grading\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project-description.html#slides",
    "href": "project-description.html#slides",
    "title": "Project description",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and deliver presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project-description.html#presentation",
    "href": "project-description.html#presentation",
    "title": "Project description",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during the last lab of the semester. The presentation must be no longer than 5 minutes. You can choose to present live in class (recommended) or pre-record a video to be shown in class. Either way you must attend the lab session for the Q&A following your presentation.\nIf you choose to pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum."
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#teamwork",
    "href": "project-description.html#teamwork",
    "title": "Project description",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#grading-summary",
    "href": "project-description.html#grading-summary",
    "title": "Project description",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-description.html#late-work-policy",
    "href": "project-description.html#late-work-policy",
    "title": "Project description",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus.\nOur course coordinator, Edric Tam, will handle all inquiries about late work, extensions and absences in accordance with the late policy described in the syllabus below. Please send emails to sta199@duke.edu."
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office hours",
    "text": "Office hours\nClick here for the instructor and TA office hours locations and Zoom links. You are welcome to attend the office hours for any member of the teaching team, regardless of section."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nAll books are freely available online.\n\n\n\nR for Data Science, 2e\nGrolemund, Wickham\nO’Reilly, 2nd edition, 2022\nHard copy only available of 1st edition\n\n\nIntroduction to Modern Statistics\nÇetinkaya-Rundel, Hardin\nOpenIntro Inc., 1st Edition, 2021\nHard copy available on Amazon"
  },
  {
    "objectID": "course-syllabus.html#course-learning-objectives",
    "href": "course-syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will…\n\nlearn to explore, visualize, and analyze data in a reproducible manner\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to effectively communicate results through written assignments and project presentation\ndevelop your own question about a data set of your choosing and use techniques from this class to answer the question"
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website: sta199-f22-1.github.io.\nAnnouncements will be emailed through Sakai Announcements periodically. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question posted on Slack, I encourage you to respond!\n\nCheck out the Help tab for more resources."
  },
  {
    "objectID": "course-syllabus.html#activities-assessment",
    "href": "course-syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. They are designed to follow the Prepare, Practice, Perform format.\n\nPrepare: Includes short videos, reading assignments, and lectures to introduce new concepts and ensure a basic comprehension of the material. The goal is to help you prepare for the in-class activities during lecture.\nPractice: Includes in-class application exercises where you will begin to the concepts and methods introduced in the prepare assignment. the activities will graded for completion, as they are designed for you to gain experience with the statistical and computing techniques before working on graded assignments.\nPerform: Includes labs, homework, exams, and the project. These assignments build upon the prepare and practice assignments and are the opportunity for you to demonstrate your understanding of the course material and how it is applied to analyze real-world data.\n\n\nLectures (Prepare)\nPart of the class time will be lectures that introduce new concepts or review topics from the preparation videos. Lectures will not repeat everything in the videos, they will instead highlight important and known to be complex concepts and will be supplemented with live coding activities. You are expected to attend every lecture. Lectures will be recorded and made available to students with an excused absence upon request.\n\n\nApplication exercises (Practice)\nA majority of the in-class lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Tuesday lectures are due Friday by 11:59p ET, and AEs from Thursday lectures are due Sunday by 11:59p ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\nIn addition to AEs will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\n\n\nLabs (Perform)\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nLabs are due 11:59p ET on the indicated due date.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework (Perform)\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nHomework assignments are due 11:59p ET on the indicated due date.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams (Perform)\nThere will be two, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analysis and computational tasks related to the content in the prepare, practice, and perform assignments. More details about the content and structure of the exams will be discussed during the semester.\n\n\nProject (Perform)\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nLabs\n15%\n\n\nProject\n15%\n\n\nExam 01\n18%\n\n\nExam 02\n18%\n\n\nApplication Exercises\n4%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\nInclusive community: It is my intent that students from all backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nAcademic honesty: You should be familiar with Duke’s community standard: https://studentaffairs.duke.edu/conduct/about-us/duke-community-standard\nBy enrolling in this course, you commit to upholding Duke’s community standard reproduced as follows:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\nPlease abide by the following as you work on assignments in this course: - You may discuss lab assignments with other students; however, you may not directly share (or copy) code or write up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write up with another team. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved. - You may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date. - Reusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. Stack- Overflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nLate policy:\nHomeworks and labs can be turned in within 72 hours of the deadline for grade penalty (5% off per day, stacks to 15% by the third day). Exams cannot be turned in late and can only be excused under exceptional circumstances. The Duke policy for illness requires a short-term illness report or a letter from the Dean; except in emergencies, all other absenteeism must be approved in advance (e.g., an athlete who must miss class may be excused by prior arrangement for specific days). For emergencies, email notification is needed at the first reasonable time.\nProcedures for Requesting a Regrade\nEvery effort will be made to mark your work accurately. We are on your side, and want you to receive every point you have worked to earn. However, sometimes grading mistakes happen. If you believe that an error has been made, return the paper to the instructor within four days, stating your claim in writing.\nThe following claims will be considered for re-grading:\n\npoints are not totaled correctly;\nthe grader did not see a correct answer that is on your paper;\nyour answer is the same as the correct answer, but in a different form (e.g., you wrote a correct answer as 1/3 and the grader was looking for .333);\nyour answer to a free response question is essentially correct but stated slightly differently than the grader’s expectation.\n\nThe following claims will not be considered for re-grading:\n\narguments about the number of points lost;\n\n\n\narguments about question wording.\n\nConsidering re-grades consumes time and resources that TAs and the instructor would rather spend helping you understand material. Please bring only claims of type (i), (ii), (iii), or (iv) to our attention.\nCommunication: All lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website. Announcements will be emailed to the class through sakai. Please check your email regularly to ensure you have the latest announcements for the course. For quick communication with your peers and the teaching team, see the course slack for general questions and discussion.\nAccessibility: If there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations. The Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu."
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAug 29: Classes begin\nSep 9: Drop/add ends\nSep 29: Exam 1 released\nOct 3: Exam 1 due (at 2pm)\nOct 10-11: Fall break\nNov 11: Last day to withdraw with W\nNov 17: Exam 2 released\nNov 21: Exam 2 due (at 2pm)\nNov 23-25: Thanksgiving recess\nDec 9: Classes end\nDec 10-13: Reading period\nDec 14-19: Final exams\n\nFor more important dates, see the full Duke Academic Calendar."
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course Slack to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\n\nAnother approach is to request a restart of your container. To do so, select your container as you usually do and then, instead of Login, click on Request Restart. Read the warning in the next page, and then click once more to restart your container."
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. They are designed to follow the Prepare, Practice, Perform format.\n\nPrepare: Includes short videos, reading assignments, and lectures to introduce new concepts and ensure a basic comprehension of the material. The goal is to help you prepare for the in-class activities during lecture.\nPractice: In-class application exercises where you will begin to master the concepts and methods introduced in the prepare assignment. The activities will graded for completion, as they are designed for you to gain experience with the statistical and computing techniques before working on graded assignments.\nPerform: Includes labs, homework, exams, and the project. These assignments build upon the prepare and practice assignments and are the opportunity for you to demonstrate your understanding of the course material and how it is applied to analyze real-world data.\n\n\nTeam work policy\nThe final project and several labs will be completed in teams. GitHub commits will be used to measure individual contribution to the assignment. All group members are expected to participate equally. Commit history may be used to give individual team members different grades. Your grade may differ from the rest of your group.\n\n\nApplication exercises (practice)\nEach lecture, we will work through application exercise (AEs). These serve as notes you will fill in during class mixed with practice exercises. Exercises which give you an opportunity to practice statistical concepts and code introduced in the prepare assignment.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade. To submit an AE, you simply need to push your completed AE to the designated repo in GitHub.\n\n\nLabs (perform)\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Some lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, see team work policy above. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and be submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework (perform)\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nHomework assignments are due at 5:00 PM ET on the indicated due date.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams (perform)\nThere will be two, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analysis and computational tasks related to the content in the prepare, practice, and perform assignments. More details about the content and structure of the exams will be discussed during the semester.\n\n\nProject (perform)\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#location",
    "href": "course-syllabus.html#location",
    "title": "Syllabus",
    "section": "Location",
    "text": "Location\n\n\n\n\n\n\n\n\nLecture\nW/F: 10:15-11:30 AM\nLSRC B101\n\n\nLab 1\nM: 10:15-11:30 AM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 2\nM: 12:00-1:15 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 3\nM: 1:45-3:00 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 4\nM: 3:30-4:35 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 5\nM: 5:15-6:30 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 11\nM: 5:15 - 6:30 PM\nPerkins LINK 071 (Classroom 5)"
  },
  {
    "objectID": "course-syllabus.html#class-time-and-location",
    "href": "course-syllabus.html#class-time-and-location",
    "title": "Syllabus",
    "section": "Class time and location",
    "text": "Class time and location\n\n\n\n\n\n\n\n\nLecture\nW/F: 10:15-11:30 AM\nLSRC B101\n\n\nLab 1\nM: 10:15-11:30 AM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 2\nM: 12:00-1:15 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 3\nM: 1:45-3:00 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 4\nM: 3:30-4:35 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 5\nM: 5:15-6:30 PM\nPerkins LINK 087 (Classroom 3)\n\n\nLab 11\nM: 5:15 - 6:30 PM\nPerkins LINK 071 (Classroom 5)"
  },
  {
    "objectID": "course-syllabus.html#additional-resources",
    "href": "course-syllabus.html#additional-resources",
    "title": "Syllabus",
    "section": "Additional resources",
    "text": "Additional resources\nStudent mental health and wellness are of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu. The Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, and more. ARC services are available free to any Duke undergraduate student, studying any discipline.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach. Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: https://students.duke.edu/wellness/dukereach/\nCounseling and Psychological Services (CAPS). CAPS services include individual and group counseling services, psychiatric services, and workshops. To initiate services, walk-in/call-in 9-4 M,W,Th,F and 9-6 Tuesdays. CAPS also provides referral to off- campus resources for specialized care.\n\n660-1000 or https://students.duke.edu/wellness/caps/\n\nTimelyCare (formerly known as Blue Devils Care). An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu"
  }
]