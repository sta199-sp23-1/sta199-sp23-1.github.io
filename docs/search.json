[
  {
    "objectID": "ae/ae-15.html",
    "href": "ae/ae-15.html",
    "title": "Model selection",
    "section": "",
    "text": "this ae is due for grade. Push your completed ae to GitHub within 48 hours to receive credit\nhomework 03 due next Wednesday\nfinal project instructions"
  },
  {
    "objectID": "ae/ae-15.html#getting-started",
    "href": "ae/ae-15.html#getting-started",
    "title": "Model selection",
    "section": "Getting started",
    "text": "Getting started\nClone your ae15-username repo from the GitHub organization."
  },
  {
    "objectID": "ae/ae-15.html#today",
    "href": "ae/ae-15.html#today",
    "title": "Model selection",
    "section": "Today",
    "text": "Today\nBy the end of today you will…\n\nselect between linear models with different numbers of predictors"
  },
  {
    "objectID": "ae/ae-15.html#load-packages-and-data",
    "href": "ae/ae-15.html#load-packages-and-data",
    "title": "Model selection",
    "section": "Load packages and data",
    "text": "Load packages and data\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-15.html#notes",
    "href": "ae/ae-15.html#notes",
    "title": "Model selection",
    "section": "Notes",
    "text": "Notes\n\nThe problem with \\(R^2\\)\n\\(R^2\\) tell us the proportion of variability in the data our model explains. If we add predictors to our model, we will always improve \\(R^2\\) (regardless of whether the predictor is good or not).\nTo see this…\n\noffline example\ntake away: a line can go through any two points, a plane can go through any three points, etc. In general an \\(n\\) dimensional object can go through \\(n\\) points.\n\nFor this reason, \\(R^2\\) is not a good way to select between two models that have a different number of predictors. Instead, we prefer to use Akaike Information Criterion (AIC).\n\n\nAIC\n\\[\n\\text{AIC} = 2k - 2 \\log (\\text{likelihood})\n\\]\nwhere \\(k\\) is the number of estimated parameters (\\(\\beta\\)s) in the model. Notice this will be 1 + the number of predictors. and \\(\\hat{L}\\) is “likelihood” of the data given the fitted model.\nThe likelihood is a measure of how well a given model fits the data. Specifically, higher likelihoods imply better fits. Since the AIC score has a negative in front of the log likelihood, lower scores are better fits. However, \\(k\\) penalizes adding new predictors to the model.\nTake-away: lower AIC is better fit.\nYou can find AIC using glance(fitted-model). (Assuming you named your fitted model fitted-model)"
  },
  {
    "objectID": "ae/ae-15.html#building-a-model",
    "href": "ae/ae-15.html#building-a-model",
    "title": "Model selection",
    "section": "Building a model",
    "text": "Building a model\nScenario: you have an outcome \\(y\\) you want to predict. You have several variables you’ve measured that you could use as predictors in your linear model. Each predictor is expensive to collect future measurements of. You want your model to only include the most useful predictors.\n\nBackward elimination\nBackward elimination starts with the full model (the model that includes all potential predictor variables). Variables are eliminated one-at-a-time from the model until we cannot improve the model any further.1\nProcedure:\n\nStart with a model that has all predictors under study and compute the AIC.\nNext fit every possible model with 1 less predictor.\nCompare AIC scores to select the best model with 1 less predictor.\nRepeat steps 2 and 3 until you can no longer improve the model.\n\n\n\nForward selection\nForward selection is the reverse of the backward elimination technique. Instead, of eliminating variables one-at-a-time, we add variables one-at-a-time until we cannot find any variables that improve the model any further.\nProcedure:\n\nStart with a model that has no predictors.\nNext fit every possible model with 1 additional predictor and score each model.\nCompare AIC scores to select the best model with 1 additional predictor.\nRepeat steps 2 and 3 until you can no longer improve the model."
  },
  {
    "objectID": "ae/ae-15.html#example",
    "href": "ae/ae-15.html#example",
    "title": "Model selection",
    "section": "Example",
    "text": "Example\n\nExercise\n\nWill forward selection and backward elimination always yield the same model? Type your answer below before running any code.\nNext, see if you are right using the data set below.\n\nSolution below\n\ntest_df = read_csv(\"https://sta101-fa22.netlify.app/static/appex/data/test_df.csv\")\n\nIn the following two examples, we will use stepwise selection to build a main effects model.\nPerform 1 step of forward selection. What variable will be in the final forward selection model?\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(y ~ x1, data = test_df) %>%\n  glance() %>%\n  pull(AIC)\n\n[1] 93.08637\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(y ~ x2, data = test_df) %>%\n  glance() %>%\n  pull(AIC)\n\n[1] 131.8917\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(y ~ x3, data = test_df) %>%\n  glance() %>%\n  pull(AIC)\n\n[1] 152.9043\n\n\nNext, perform 1 step of backward elimination. Which variable will not be in the final backward elimination model?\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(y ~ x2 + x3, data = test_df) %>%\n  glance() %>%\n  pull(AIC)\n\n[1] 35.25949\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(y ~ x1 + x3, data = test_df) %>%\n  glance() %>%\n  pull(AIC)\n\n[1] 94.2536\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(y ~ x1 + x2, data = test_df) %>%\n  glance() %>%\n  pull(AIC)\n\n[1] 87.1686"
  },
  {
    "objectID": "hw/hw-3.html",
    "href": "hw/hw-3.html",
    "title": "HW 3 - Do you even lift?",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Wednesday, March 8 at 5:00pm."
  },
  {
    "objectID": "hw/hw-3.html#getting-started",
    "href": "hw/hw-3.html#getting-started",
    "title": "HW 3 - Do you even lift?",
    "section": "Getting Started",
    "text": "Getting Started\n\nGo to the Github Organization page and open your hw3-username repo\nClone the repository, open a new project in RStudio. It contains the starter documents you need to complete the homework assignment."
  },
  {
    "objectID": "hw/hw-3.html#exercises",
    "href": "hw/hw-3.html#exercises",
    "title": "HW 3 - Do you even lift?",
    "section": "Exercises",
    "text": "Exercises\nFor all of the following exercises, you should include units on axes labels, e.g. “Bench press (lbs)” or “Bench press (kg)”. “Age (years)” etc. This is good practice.\n\nLet’s begin by taking a look at the squat powerlifting records. To begin, remove any observations that are negative for squat. Next, create a new column called best3_squat_lbs that converts the record from kg to lbs (you may have to google the conversion). Save your data frame as ipf_squat.\n\n\nUsing ipf_squat, create a scatter plot to investigate the relationship between squat (in lbs) and age. Age should be on the x-axis. Add a linear trend-line. Remove the standard error. Be sure to label all axes and give the plot a title. Comment on what you observe.\n\n\nWrite down the full linear model to predict lift squat lbs from age in \\(x\\), \\(y\\), \\(\\beta\\) notation. What is \\(x\\)? What is \\(y\\)? Next, fit the linear model. Use the ipf_squat data frame. Re-write your previous equation replacing \\(\\beta\\) with the numeric estimates. This is called the “fitted” linear model. Interpret each estimate of \\(\\beta\\). Are the interpretations reasonable?\nBuilding on your ipf_squat data frame, create a new column called age2 that takes the age of each lifter and squares it. Save your data frame with an appropriate name. Next, plot squat in lbs vs age2 and add a linear best fit line. Does this model look like it fits the data better? Is this still a linear model?\nOne metric to assess the fit of a model is the correlation squared, also known as \\(R^2\\). Fit the age\\(^2\\) model and save the object as age2Fit. Subsequently report the \\(R^2\\). Compare \\(R^2\\) of the age\\(^2\\) model to the model from exercise 2. Which model do you prefer?\n\n\nIf you were to add body weight as a second predictor to the age\\(^2\\) model, would \\(R^2\\) increase or decrease? Explain.\n\n\nStarting with the original ipf dataframe, filter and mutate the data as we did in exercise 1, but this time filtering for best3bench_kg \\(>0\\) and creating a best3_bench_lbs variable, a bodyweight_lbs variable, and a sex variable that is a factor rather than a character. Fit an interaction effects model with bodywieght (in lbs) and sex as predictors of best bench press (in lbs). Write down the fitted model equation only, replacing \\(\\hat{\\beta}\\) with the fitted estimates. Interpret the \\(\\hat{\\beta}\\).\nVisualize the interaction effects model we built in exercise 5. Hint: there should be two lines with different slopes. Bodyweight should be on the x-axis. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.\nDo lifters who fail a drug test perform better or worse at bench press than other lifters? Does this vary across sexes? We’ll answer this question in two parts. First, remove all observations from the data frame that have NA listed under bench press. Next, create a new column called doping_status that takes value doping if the lifter failed a drug test and not doping otherwise. Save this data frame as ipf_dope.\n\n\n\n\n\n\n\nHint\n\n\n\nCheck the data dictionary at the top to figure out what variables will help you build the doping_status column.\n\n\n\nUsing ipf_dope from the previous exercise, compute the 5%, 50%, 95% quantiles for bench press across both sex and doping_status. You can use either bench press in kg or lbs here. With this information, answer the question “Do lifters who fail a drug test perform better or worse at bench press than other lifters? Is this consistent across sex and quantiles?”"
  },
  {
    "objectID": "hw/hw-3.html#reminder",
    "href": "hw/hw-3.html#reminder",
    "title": "HW 3 - Do you even lift?",
    "section": "Reminder:",
    "text": "Reminder:\n\nAll plots should follow the best visualization practices: include an informed title, label axes, and carefully consider aesthetic choices.\nAll code should follow the tidyverse style guidelines, including not exceeding the 80 character limit."
  },
  {
    "objectID": "hw/hw-3.html#submission",
    "href": "hw/hw-3.html#submission",
    "title": "HW 3 - Do you even lift?",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect all pages of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-3.html#rubric",
    "href": "hw/hw-3.html#rubric",
    "title": "HW 3 - Do you even lift?",
    "section": "Rubric",
    "text": "Rubric\n\nEx 1: 6 pts.\nEx 2: 7 pts.\nEx 3: 6 pts.\nEx 4: 5 pts.\nEx 5: 8 pts.\nEx 6: 4 pts.\nEx 7: 4 pts\nEx 8: 5 pts\nWorkflow and formatting - 5 pts\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow. This includes:\n\nlinking all pages appropriately on Gradescope\nputting your name in the YAML at the top of the document\ncommitting the submitted version of your .qmd to GitHub\nAre you under the 80 character code limit? (You shouldn’t have to scroll to see all your code).\nPipes %>%, |> and ggplot layers + should be followed by a new line\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs <- and %>% vs |>\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not."
  }
]